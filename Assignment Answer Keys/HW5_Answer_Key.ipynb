{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RP-UWLMS0qML",
        "QzFBHtFHRBkH",
        "1-M5G2ryQRSe",
        "AGkXmgmNsFfo",
        "T8J9g4TFGCTj",
        "cDbFDeF2JFAe",
        "8qJdsy4_Mfd8",
        "7mV9LXUKJt95",
        "9DPdhTJ1J9Ix",
        "gZy303cNLHad",
        "K-nzeiXvm05T",
        "B9G1r1WtWftI",
        "JGIVx5DOXXoU",
        "M1axK8yxMb7k",
        "8GMz7Q6hNSeJ",
        "svtie6bdO-cs",
        "tBnvY3H2PlgN",
        "YvYHpn0KQ0nK",
        "APZ9UPmA8g5m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nw1ncs6ri2t"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbtXaxl9XvIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5e109b-8eaf-4c62-b6d3-e591da4800b8"
      },
      "source": [
        "# You are going to need to run this cell, restart the runtime after running this command,\n",
        "# then start over before you can run the code in this notebook.\n",
        "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 95 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==2.2.0) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (4.64.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->en-core-web-md==2.2.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->en-core-web-md==2.2.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->en-core-web-md==2.2.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.4)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.0-py3-none-any.whl size=98072934 sha256=e0dbf41bc9add21d8a89ee9e8ecd92557e6fab7644d0d81abcad5c77856be286\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/e8/f9/fd0d324ec96ab55e0a8ae395183c22260a4eeaf166ade7ad22\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ9wmEaMc9Tq",
        "outputId": "6ca43eef-edd6-4dd2-8cee-1072bc3aacbe"
      },
      "source": [
        "import sklearn\n",
        "estimators = sklearn.utils.all_estimators(type_filter=None)\n",
        "for name, class_ in estimators:\n",
        "    if hasattr(class_, 'predict_proba'):\n",
        "        print(name)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoostClassifier\n",
            "BaggingClassifier\n",
            "BayesianGaussianMixture\n",
            "BernoulliNB\n",
            "CalibratedClassifierCV\n",
            "CategoricalNB\n",
            "ClassifierChain\n",
            "ComplementNB\n",
            "DecisionTreeClassifier\n",
            "DummyClassifier\n",
            "ExtraTreeClassifier\n",
            "ExtraTreesClassifier\n",
            "GaussianMixture\n",
            "GaussianNB\n",
            "GaussianProcessClassifier\n",
            "GradientBoostingClassifier\n",
            "GridSearchCV\n",
            "HalvingGridSearchCV\n",
            "HalvingRandomSearchCV\n",
            "HistGradientBoostingClassifier\n",
            "KNeighborsClassifier\n",
            "LabelPropagation\n",
            "LabelSpreading\n",
            "LinearDiscriminantAnalysis\n",
            "LogisticRegression\n",
            "LogisticRegressionCV\n",
            "MLPClassifier\n",
            "MultiOutputClassifier\n",
            "MultinomialNB\n",
            "NuSVC\n",
            "OneVsRestClassifier\n",
            "Pipeline\n",
            "QuadraticDiscriminantAnalysis\n",
            "RFE\n",
            "RFECV\n",
            "RadiusNeighborsClassifier\n",
            "RandomForestClassifier\n",
            "RandomizedSearchCV\n",
            "SGDClassifier\n",
            "SVC\n",
            "SelfTrainingClassifier\n",
            "StackingClassifier\n",
            "VotingClassifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVhbDjn513OF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a63999d-b2b5-4b91-f954-b0c611f5dded"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from matplotlib import dates\n",
        "from datetime import datetime\n",
        "import re\n",
        "import calendar\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB, GaussianNB, MultinomialNB \n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import jieba\n",
        "from sklearn.utils._testing import ignore_warnings\n",
        "from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIga8B1D1xrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99b5aa3-2d46-4cd7-a6a7-6278adab1269"
      },
      "source": [
        "!pip install textstat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 13.1 MB/s \n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 35.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.12.0 textstat-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzFBHtFHRBkH"
      },
      "source": [
        "# Upload your data\n",
        "To upload your own files for access in Google Colab:\n",
        "\n",
        "1. Save the file in Google Drive.\n",
        "\n",
        "2. Once it's saved, find it in your drive, right-click, and click `Get Shareable Link`.\n",
        "\n",
        "3. Flip the toggle in the pop-up to `Link Sharing On`, then click `Sharing Settings`.\n",
        "\n",
        "4. In the dropdown menu, choose `Anyone with the link can view`, then click `Copy Link`.\n",
        "\n",
        "5. Paste that link in the code field below. \n",
        "\n",
        "6. Alter the link to the format below. Specifically, the link provided by Google Drive is written by default as:\n",
        "\n",
        "`https://docs.google.com/document/d/ABCDEFG`\n",
        "\n",
        "Replace this with:\n",
        "\n",
        "`https://docs.google.com/uc?export=download&id=ABCDEFG`\n",
        "\n",
        "Make sure that the unique identifier (`ABCDEFG`) above is identical to what you copied from Google Drive. Once you have saved the file to the Google Colab server, you can now open that file in Python, as in the next cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI8PnTc1szRm"
      },
      "source": [
        "#https://drive.google.com/file/d/1gAbdQaJOhjqLIfubpvCjG399TroHGvsg/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otmviiiLttva",
        "outputId": "d5e0f2d2-43cd-4f45-ca14-b3b7785d4aca"
      },
      "source": [
        "!gdown --id 1gAbdQaJOhjqLIfubpvCjG399TroHGvsg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gAbdQaJOhjqLIfubpvCjG399TroHGvsg\n",
            "To: /content/training_labeled.csv\n",
            "100% 30.2k/30.2k [00:00<00:00, 11.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-M5G2ryQRSe"
      },
      "source": [
        "# Homework 5 Part Two\n",
        "\n",
        "Last week you annotated a set of at least 200 microblog posts (your Training Set) with a supervised learning task designed by you and your partner, with your own annotation manual. \n",
        "\n",
        "By now, you should have two columns of labels for each post, and you should know the approximate upper bound of machine learning performance on this data, equal to your inter-rater reliability.\n",
        "\n",
        "Save your work to a CSV file with the two annotator's labels (name the columns `labels_A` and `labels_B`), and a third column with the original text of the annotated post. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFVMYg2vmoh7"
      },
      "source": [
        "# Task 2.1\n",
        "\n",
        "Divide your data into a training set and a test set made up of 20% of the data. If you have 200 rows, your training set should have 160 examples, and your test set should have 40 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxpGlAKXZuUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8024d9d2-af79-48ff-fb9c-0ca5af3f9eb6"
      },
      "source": [
        "# create dataframe for the dataset\n",
        "df=pd.read_csv(\"training_labeled.csv\")\n",
        "df=df.drop('Unnamed: 0', axis=1)\n",
        "df=df.dropna()\n",
        "df=df.loc[:,[\"text\",\"labels_A\",\"labels_B\"]]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  labels_A  labels_B\n",
              "0  &gt;Falling for the Onion picking John Cena fo...  Positive  Positive\n",
              "1  Sunday morning at the First Church of George H...   Neutral  Positive\n",
              "2  Paper Towns is released in the UK tomorrow and...  Negative  Negative\n",
              "3  Remember when Pain was a just shadowy figure? ...   Neutral   Neutral\n",
              "4  Tomorrow Shawn is going to be an hour away fro...  Positive  Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cbd8d33-4ee1-4502-9f3d-809acf69ea85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels_A</th>\n",
              "      <th>labels_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&amp;gt;Falling for the Onion picking John Cena fo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sunday morning at the First Church of George H...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Paper Towns is released in the UK tomorrow and...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Remember when Pain was a just shadowy figure? ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tomorrow Shawn is going to be an hour away fro...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cbd8d33-4ee1-4502-9f3d-809acf69ea85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cbd8d33-4ee1-4502-9f3d-809acf69ea85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cbd8d33-4ee1-4502-9f3d-809acf69ea85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsVG6MH5uyPq",
        "outputId": "8865f2bb-4a5c-4576-c806-6d10a3b2bdeb"
      },
      "source": [
        "# divide the dataset to 80% train, 20% test. \n",
        "df_training=df.sample(frac=0.8, random_state=333)\n",
        "df_testing=df.drop(df_training.index)\n",
        "len(df_training)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ZEWAqydB47"
      },
      "source": [
        "# Task 2.2\n",
        "\n",
        "Use 10-fold cross-validation on your training set. Each fold should contain 8% of the original training data (if you had 200 rows originally and use an 80% training set, each fold for optimization will contain 16 examples). \n",
        "\n",
        "Optimize a machine learning classifier predicting `labels_A`, using features you extract from the microblog texts. \n",
        "\n",
        "Choose and perform **THREE** of the following optimizations:\n",
        "\n",
        "   - a) Compare Naïve Bayes, Logistic Regression, and SVMs on a unigram feature space.\n",
        "   - b) Compare a unigram feature space with a feature space that also includes longer N-grams.\n",
        "   - c) Compare a unigram feature space with a feature space that removes stopwords.\n",
        "   - d) Vary the vocabulary size of your n-gram feature space and evaluate how performance changes.\n",
        "\n",
        "If you are working with English data, additional options include:\n",
        "   - e) Compare an n-gram feature space with a feature space that also includes part-of-speech n-grams.\n",
        "   - f) Compare an n-gram feature space to a word embedding feature space.\n",
        "   - g) Compare a standard n-gram feature space with a lemmatized feature space.\n",
        "   - h) For the one most accurate model so far, tune your hyperparameters.\n",
        "   - i) For Naive Bayes, evaluate different implementations: ComplementNB, MultinomialNB, BernoulliNB\n",
        "   - j) For Support Vector Machines, evaluate different kernels including a polynomial kernel and a radial basis function kernel.\n",
        "   - k) For Logistic Regression, try L1 and L2 regularization, as well as unregularized features.\n",
        "\n",
        "Report the performance of your best-tuned model on the cross-validated training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6xVucD8hlia"
      },
      "source": [
        "# useful functions from example notebook\n",
        "\"\"\"\n",
        "Options for noisy: \"loud\", \"quiet\", and other. Any other value prints nothing (silent).\n",
        "\"\"\"\n",
        "\n",
        "# Start by defining a function to evaluate a classifier's predictions\n",
        "def evaluate(y_pred, y_actual, metrics, model_name = 'model'):\n",
        "    # Compute Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "\n",
        "    # Compute and store each metric\n",
        "    model_metrics = {}\n",
        "    for (metric_name, metric) in metrics.items():\n",
        "        result = metric(y_actual, y_pred)\n",
        "        model_metrics[metric_name] = result\n",
        "\n",
        "    return conf_matrix, model_metrics\n",
        "\n",
        "# Then define a function that trains a classifier and evaluates it on one fold\n",
        "def evaluate_one_fold(classifier_name, classifier, X_train, y_train, X_test, y_test, metrics, fold_num, noisy = 'loud', labels=[]):\n",
        "\n",
        "    # Train and Evaluate Model\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    conf_matrix, model_metrics = evaluate(y_pred, y_test, metrics, model_name = classifier_name)\n",
        "\n",
        "    # Display Results appropriately when noisy is set to 'loud' or 'quiet'\n",
        "    if noisy == 'quiet' and fold_num == 0:\n",
        "        print(f\"{classifier_name}: Fold {fold_num}\", end = '')\n",
        "    elif noisy == 'quiet':\n",
        "        print(f'...{fold_num}', end ='')\n",
        "    elif noisy == 'loud':\n",
        "        print(f\"{classifier_name}: Fold {fold_num} Results\")\n",
        "        ConfusionMatrixDisplay(conf_matrix, labels).plot(values_format='.4g')\n",
        "        plt.show()\n",
        "        print(model_metrics)\n",
        "        print(\"------------------------\")\n",
        "\n",
        "    return model_metrics\n",
        "\n",
        "# Then define a function to evaluate over all folds\n",
        "def evaluate_all_folds(classifier_name, classifier, X, y, kf, metrics, noisy = 'loud', labels=[]):\n",
        "\n",
        "    # Initialize tracking variables\n",
        "    all_fold_metrics = {metric_name: [] for metric_name in metrics}\n",
        "\n",
        "    # Iterate over each fold\n",
        "    for fold_num, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "        # Get the data subset for the current fold\n",
        "        X_train = X.iloc[train_index]\n",
        "        X_test = X.iloc[test_index]\n",
        "        y_train = y.iloc[train_index]\n",
        "        y_test = y.iloc[test_index]\n",
        "\n",
        "        # Train and Evaluate the Model\n",
        "        model_metrics =  evaluate_one_fold(classifier_name, classifier, X_train, y_train, X_test, y_test, metrics, fold_num, noisy, labels=labels)\n",
        "\n",
        "        # Update our tracking variables\n",
        "        [all_fold_metrics[metric_name].append(metric_val) for metric_name, metric_val in model_metrics.items()]\n",
        "\n",
        "    return all_fold_metrics\n",
        "\n",
        "#Dont worry about these two lines\n",
        "@ignore_warnings(category=ConvergenceWarning)\n",
        "@ignore_warnings(category=UndefinedMetricWarning)\n",
        "# Then define a function to compare different classifiers\n",
        "def compare_classifiers(classifiers, metrics, metric_to_optimize, df, feature_set,\n",
        "                        target, folds = 10, shuffle = True, noisy='loud', labels=[]):\n",
        "    # Initialize tracking variables\n",
        "    best = 0\n",
        "    best_name = None\n",
        "    classifier_comparison = {}\n",
        "\n",
        "    # Set up dataset and cross validation\n",
        "    X = df.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "    y = df[target]\n",
        "    kf = StratifiedKFold(n_splits=folds, shuffle=shuffle, random_state=123)\n",
        "\n",
        "\n",
        "    # For each classifier\n",
        "    for classifier_name, classifier in classifiers.items():\n",
        "        # Evaluate on all metrics for all folds\n",
        "        all_fold_metrics = evaluate_all_folds(classifier_name, classifier, X, y, kf, metrics, noisy = noisy, labels=labels)\n",
        "\n",
        "        # Compute average performance on metric to optimize over\n",
        "        optimization_metric_avg = np.mean(all_fold_metrics[metric_to_optimize])\n",
        "\n",
        "        # Update Tracking Variables\n",
        "        if optimization_metric_avg > best:\n",
        "            best = optimization_metric_avg\n",
        "            best_name = classifier_name\n",
        "        classifier_comparison[classifier_name] = all_fold_metrics\n",
        "        if noisy == 'quiet': \n",
        "            print()\n",
        "            print(f\"Average {metric_to_optimize}: {optimization_metric_avg:.3f}\")\n",
        "            print('-------------')\n",
        "    # Return our results\n",
        "    return best, best_name, classifier_comparison\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGkXmgmNsFfo"
      },
      "source": [
        "#### **(a). Compare Naïve Bayes, Logistic Regression, and SVMs on a unigram feature space.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcM0BnSubMfV"
      },
      "source": [
        "# consulted the example notebook \n",
        "\n",
        "# define X\n",
        "vocab_size = 1000\n",
        "# By default we can build a unigram model - capturing individual words only\n",
        "vectorizer = CountVectorizer(max_features=vocab_size)\n",
        "X = vectorizer.fit_transform(df_training[\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ynPElbzwL8ip",
        "outputId": "7c99d059-985b-4711-d731-1e211bc2de41"
      },
      "source": [
        "# Now lets make a DataFrame with our BOW model representations for each message\n",
        "bow_df = pd.DataFrame(X.toarray())\n",
        "column_names = [str(i) for i in range(vocab_size)]\n",
        "# Make the column names the words\n",
        "for k, v in vectorizer.vocabulary_.items():\n",
        "  column_names[v] = k\n",
        "bow_df.columns = column_names\n",
        "# Add our Y labels to our DataFrame\n",
        "bow_df[\"labels_A\"] = df_training[\"labels_A\"].values\n",
        "# Take a look at our DataFrame\n",
        "bow_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     00  00pm  04  0915  0ffsxzymap  10  100  11  11th  12  ...  yfoa4i09ex  \\\n",
              "0     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "1     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "2     0     0   0     0           0   0    0   0     0   1  ...           0   \n",
              "3     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "4     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "..   ..   ...  ..   ...         ...  ..  ...  ..   ...  ..  ...         ...   \n",
              "155   0     0   0     0           0   1    0   0     0   0  ...           0   \n",
              "156   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "157   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "158   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "159   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "\n",
              "     yoga  york  you  your  yrr3b  ytncrtupl2  yts  zachkleinwsb  labels_A  \n",
              "0       0     0    0     0      0           0    0             0  Positive  \n",
              "1       0     0    0     0      0           0    0             0  Positive  \n",
              "2       0     0    0     0      0           0    0             0  Positive  \n",
              "3       0     0    0     0      0           0    0             0  Negative  \n",
              "4       0     0    0     0      0           0    0             0  Positive  \n",
              "..    ...   ...  ...   ...    ...         ...  ...           ...       ...  \n",
              "155     0     0    0     1      0           0    0             0   Neutral  \n",
              "156     0     0    0     0      0           0    0             0   Neutral  \n",
              "157     0     0    0     0      0           0    0             0   Neutral  \n",
              "158     0     0    1     0      0           0    0             0  Positive  \n",
              "159     0     0    0     0      0           0    0             0   Neutral  \n",
              "\n",
              "[160 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f0163d8-fb56-4cd1-8ed7-f6c3b8f318e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>00pm</th>\n",
              "      <th>04</th>\n",
              "      <th>0915</th>\n",
              "      <th>0ffsxzymap</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>11th</th>\n",
              "      <th>12</th>\n",
              "      <th>...</th>\n",
              "      <th>yfoa4i09ex</th>\n",
              "      <th>yoga</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yrr3b</th>\n",
              "      <th>ytncrtupl2</th>\n",
              "      <th>yts</th>\n",
              "      <th>zachkleinwsb</th>\n",
              "      <th>labels_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f0163d8-fb56-4cd1-8ed7-f6c3b8f318e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f0163d8-fb56-4cd1-8ed7-f6c3b8f318e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f0163d8-fb56-4cd1-8ed7-f6c3b8f318e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5fj48dyMFlX",
        "outputId": "0ea39f42-d54c-4a16-9a83-e73b460895b2"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifiers = {\n",
        "    \"Bernoulli NB\": BernoulliNB(),\n",
        "    \"Linear SVM\": LinearSVC(),\n",
        "    \"RBF SVM\": SVC(kernel='rbf'),\n",
        "    \"Poly SVM\": SVC(kernel='poly'),\n",
        "    \"Complement NB\": ComplementNB(), \n",
        "    \"Multinomial NB\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", multi_class='ovr', max_iter=10000, random_state=123),\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "sorted_sentiments=[\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_A\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.021\n",
            "-------------\n",
            "Linear SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.093\n",
            "-------------\n",
            "RBF SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: -0.010\n",
            "-------------\n",
            "Poly SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.014\n",
            "-------------\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.037\n",
            "-------------\n",
            "Multinomial NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.063\n",
            "-------------\n",
            "Logistic Regression: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.120\n",
            "-------------\n",
            "Best classifier is: Logistic Regression \n",
            "With K=0.120.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-WHLo1wkjEA"
      },
      "source": [
        "Among Naïve Bayes, Logistic Regression, and SVMs, the **Logistic Regression** performs the best, and its kappa value eqauls 0.12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sT8Xi5xbHO7"
      },
      "source": [
        "#### **(b). Compare a unigram feature space with a feature space that also includes longer N-grams.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMEiylXYbLBB"
      },
      "source": [
        "# Create a vocab of n-grams from the dataframe\n",
        "def ngrams(df, vocab_size = 1000, max_n=1):\n",
        "  vectorizer = CountVectorizer(max_features=vocab_size, ngram_range=(1,max_n))\n",
        "  X = vectorizer.fit_transform(df[\"text\"])\n",
        "\n",
        "  bow_df = pd.DataFrame(X.toarray())\n",
        "  column_names = [str(i) for i in range(vocab_size)]\n",
        "  for k, v in vectorizer.vocabulary_.items():\n",
        "    column_names[v] = k\n",
        "  bow_df.columns = column_names\n",
        "\n",
        "  bow_df[\"labels_A\"] = df[\"labels_A\"].reset_index()['labels_A']\n",
        "  return bow_df\n",
        "# create unigram and bigrams DataFrame\n",
        "unigram_df = ngrams(df_training, max_n=1)\n",
        "bigram_df = ngrams(df_training, max_n=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAIE87rNJfqx",
        "outputId": "3985ea6e-0661-48b5-dc96-b5d6a1ec94b3"
      },
      "source": [
        "### Setup classifiers and metrics to be used on all n-grams\n",
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "     \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", multi_class='ovr', max_iter=10000, random_state=123)\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "### Compare classifiers on unigrams ###\n",
        "# Pick features to use\n",
        "feature_set = list(unigram_df.columns[:-1])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, feature_set, \"labels_A\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"The unigram classifier is: {best_name} \\nWith K={best:.3f}.\")    \n",
        "\n",
        "### Compare classifiers on bigrams ###\n",
        "# Pick features to use\n",
        "feature_set = list(bigram_df.columns[:-1])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bigram_df, feature_set, \"labels_A\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"The bigram classifier is: {best_name} \\nWith K={best:.3f}.\")    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.120\n",
            "-------------\n",
            "The unigram classifier is: Logistic Regression \n",
            "With K=0.120.\n",
            "Logistic Regression: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.117\n",
            "-------------\n",
            "The bigram classifier is: Logistic Regression \n",
            "With K=0.117.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irYTuhrcl0Pc"
      },
      "source": [
        "Comparing unigram with bigram features using Logistic Regression classifier, **unigram** feature space performs slighlt better. The kappa value equals 0.12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_XaF8IobHwa"
      },
      "source": [
        "#### **(i). For Naive Bayes, evaluate different implementations: ComplementNB, MultinomialNB, BernoulliNB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNPYTLfZbI98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fd1209-d6d1-4e06-9005-d40b1717cb70"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Bernoulli NB\": BernoulliNB(),\n",
        "    \"Complement NB\": ComplementNB(), \n",
        "    \"Multinomial NB\": MultinomialNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result\n",
        "sorted_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_A\", labels=sorted_labels, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.021\n",
            "-------------\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.037\n",
            "-------------\n",
            "Multinomial NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.063\n",
            "-------------\n",
            "Best classifier is: Multinomial NB \n",
            "With K=0.063.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRfyGhDzndXS"
      },
      "source": [
        "Among three types of Naive Bayes classifers, **Multinomial NB** performs the best. The best kappa value is 0.063."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lVBue7oWRZA"
      },
      "source": [
        "#### **(k). For Logistic Regression, try L1 and L2 regularization, as well as unregularized features.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsn3o_DYUKkM",
        "outputId": "fae506e4-65cb-4997-e123-5fe44d1f4b4d"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"LogisticRegression l2\": LogisticRegression(penalty=\"l2\", solver=\"saga\", max_iter=10000, random_state=123),\n",
        "    \"LogisticRegression l1\": LogisticRegression(penalty='l1', random_state=123, solver='saga', max_iter=10000), \n",
        "    \"Unregularized Features\": LogisticRegression(random_state=123, solver='saga', max_iter=10000)}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result\n",
        "sorted_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_A\", labels=sorted_labels, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression l2: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.121\n",
            "-------------\n",
            "LogisticRegression l1: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.161\n",
            "-------------\n",
            "Unregularized Features: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.121\n",
            "-------------\n",
            "Best classifier is: LogisticRegression l1 \n",
            "With K=0.161.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evrd3TmDViOp"
      },
      "source": [
        "Based on the above evaluation, logistic regression models with l1 penalty has the highest kappa value, which is 0.161. Thus the model with **l1 penalty** performs better. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaas7_ITWuRa"
      },
      "source": [
        "#### **(j). For Support Vector Machines, evaluate different kernels including a polynomial kernel and a radial basis function kernel.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUgk5a28WtbD",
        "outputId": "e55b2745-7735-4d23-c1c5-ffbf4a18eecf"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Linear SVM\": LinearSVC(),\n",
        "    \"RBF SVM\": SVC(kernel='rbf'),\n",
        "    \"Poly SVM\": SVC(kernel='poly')\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result\n",
        "sorted_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_A\", labels=sorted_labels, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.093\n",
            "-------------\n",
            "RBF SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: -0.010\n",
            "-------------\n",
            "Poly SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.014\n",
            "-------------\n",
            "Best classifier is: Linear SVM \n",
            "With K=0.093.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPBGK3smXKsf"
      },
      "source": [
        "Based on the result, **Linear SVM** performs the best, with a kappa value of 0.093."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Based on the five optimizations above, **LogisticRegression(max_iter=10000, penalty='l1', random_state=123,\n",
        "                   solver='saga') on unigram feature face** is the best model, with Kappa value of 0.161. "
      ],
      "metadata": {
        "id": "s9A_M7jdSCxh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOOkWEaIdEWu"
      },
      "source": [
        "# Task 2.3\n",
        "\n",
        "Train two models, each **trained on the full 80% training set, and tested on the held-out 20% test set**:\n",
        "   - A Naïve Bayes classifier with unigram features.\n",
        "   - The best-tuned model from task two, retrained on the full 80% training set. \n",
        "   \n",
        "Report three sets of evaluation metrics:\n",
        "   - The estimated performance from cross-validation in Task 2.\n",
        "   - The performance of the simple Naïve Bayes unigram classifier on the held-out test set.\n",
        "   - The performance of the best-tuned model on the held-out test set.\n",
        "\n",
        "At minimum, your evaluations should include percent accuracy and Kappa values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mV9LXUKJt95"
      },
      "source": [
        "####**A Naive Bayes classifier with unigram features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCoLJJdubWyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b01efd4-7fec-4eef-9b89-f70ed4e8ef77"
      },
      "source": [
        "# Train a Naive Bayes classifier with unigram features.\n",
        "# Here we choose BernoulliNB() as our Naive Bayes classifer.\n",
        "unigram_df=ngrams(df, max_n=1)\n",
        "feature_set = list(unigram_df.columns[:-1])\n",
        "unigram_training=unigram_df.iloc[df_training.index,:]\n",
        "unigram_testing=unigram_df.iloc[df_testing.index,:]\n",
        "\n",
        "X_train=unigram_training.loc[:, feature_set]\n",
        "y_train=unigram_training.iloc[:,-1]\n",
        "X_test=unigram_testing.loc[:, feature_set]\n",
        "y_test=unigram_testing.iloc[:,-1]\n",
        "NB=BernoulliNB()\n",
        "NB.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DPdhTJ1J9Ix"
      },
      "source": [
        "####**The best-tuned model from task two, retrained on the full 80% training set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uZ3xOMNBOFk",
        "outputId": "49db5b85-4653-439a-accb-aeaeeef8e859"
      },
      "source": [
        "# Train the best performance model- Logistic Regression unigram features\n",
        "lr=LogisticRegression(penalty='l1', random_state=123, solver='saga', max_iter=10000)\n",
        "lr.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=10000, penalty='l1', random_state=123,\n",
              "                   solver='saga')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZy303cNLHad"
      },
      "source": [
        "####**Report three sets of evaluation metrics:**\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svpTOLkCPZlI",
        "outputId": "95e33f60-fca2-44ef-d0d1-67ba2685bac3"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "# Calculate and print the estimated performance from 10-fold-validation.\n",
        "a_scores = cross_val_score(estimator = NB,\n",
        "                         X = X_train,\n",
        "                         y = y_train,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = \"accuracy\")\n",
        "# print('10-fold accuracy: %s' % a_scores)\n",
        "print(\"Estimated performance from cross-validation:\")\n",
        "print('10-fold accuracy: %.3f +/- %.3f' % (np.mean(a_scores), np.std(a_scores)))\n",
        "\n",
        "kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "k_scores = cross_val_score(estimator = NB,\n",
        "                         X = X_train,\n",
        "                         y = y_train,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = kappa_scorer)\n",
        "# print('10-fold Cohen's Kappa: %s' % k_scores)\n",
        "print('10-fold Kappa: %.3f +/- %.3f' % (np.mean(k_scores), np.std(k_scores)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Calculate and print the performance of the Bernoulli NB model on the held-out test set.\n",
        "print(\"Performance on the held-out test set:\")\n",
        "y_pred = NB.predict(X_test)\n",
        "accuracy_NB = accuracy_score(y_test, y_pred)\n",
        "print(f\"The accuracy is: {accuracy_NB:.4f}.\")\n",
        "kappa_NB = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"The Kappa is: {kappa_NB:.4f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated performance from cross-validation:\n",
            "10-fold accuracy: 0.506 +/- 0.052\n",
            "10-fold Kappa: 0.021 +/- 0.097\n",
            "------------------------------------\n",
            "Performance on the held-out test set:\n",
            "The accuracy is: 0.6000.\n",
            "The Kappa is: 0.1011.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm6zRkJHQh4D",
        "outputId": "b20cb13f-4e6f-4f04-d732-7b19a8e8bcc9"
      },
      "source": [
        "# Calculate and print the estimated performance from 10-fold-validation.\n",
        "a_scores2 = cross_val_score(estimator = lr,\n",
        "                         X = X_train,\n",
        "                         y = y_train,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = \"accuracy\")\n",
        "# print('10-fold accuracy: %s' % a_scores)\n",
        "print(\"Estimated performance from cross-validation:\")\n",
        "print('10-fold accuracy: %.3f +/- %.3f' % (np.mean(a_scores2), np.std(a_scores2)))\n",
        "\n",
        "kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "k_scores2 = cross_val_score(estimator = lr,\n",
        "                         X = X_train,\n",
        "                         y = y_train,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = kappa_scorer)\n",
        "# print('10-fold Cohen's Kappa: %s' % k_scores)\n",
        "print('10-fold Kappa: %.3f +/- %.3f' % (np.mean(k_scores2), np.std(k_scores2)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Calculate and print the performance of the best tuned model on the held-out test set.\n",
        "print(\"Performance on the held-out test set:\")\n",
        "y_pred = lr.predict(X_test)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred)\n",
        "print(f\"The accuracy is: {accuracy_lr:.4f}.\")\n",
        "kappa_lr = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"The Kappa is: {kappa_lr:.4f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated performance from cross-validation:\n",
            "10-fold accuracy: 0.525 +/- 0.116\n",
            "10-fold Kappa: 0.149 +/- 0.203\n",
            "------------------------------------\n",
            "Performance on the held-out test set:\n",
            "The accuracy is: 0.5250.\n",
            "The Kappa is: 0.1017.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BlyTZVzLMXl"
      },
      "source": [
        "Based on the three sets of evaluation metircs above, the accuracy for simple Naïve Bayes unigram classifier on the held-out test set is 0.6 and Kappa is 0.1011, while the estimated performance from 10-fold cross-validation in task 2 shows accuracy 0.506 +/- 0.052 and Kappa 0.021 +/- 0.097. The accuracy is higher than the estimated range, and Kappa is in the range. \n",
        "\n",
        "For the best-tuned model (Logistic Regression model) on the held-out test set, the accuracy is 0.5250 and Kappa is 0.1017, while the estimated performance from 10-fold cross-validation in task 2 shows accuracy 0.525 +/- 0.116 and Kappa 0.149 +/- 0.203. Both the accuracy and Kappa are in the estimated range. \n",
        "\n",
        "The Kappa value is slightly better with the best-tuned model than the one with Naïve Bayes unigram classifier and accuracy score is the other way around. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-nzeiXvm05T"
      },
      "source": [
        "#1. Extra Credit\n",
        "\n",
        "For up to 2 points of extra credit:\n",
        "   - Perform five of the optimizations above instead of three.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Please see code above)."
      ],
      "metadata": {
        "id": "edurOVZQVr9f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4FrP56qUv43"
      },
      "source": [
        "#2. Extra Credit\n",
        "\n",
        "For up to 2 points of extra credit:\n",
        "   - Re-run the same set of code above but on `labels_B` instead of `labels_A`. Choose a new set of optimized hyperparameters and features based on these results. How do the chosen models differ, and are the model quality metrics different between the two columns in a statistically significant way?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyQO-9qYahyE"
      },
      "source": [
        "#### **(a). Compare Naïve Bayes, Logistic Regression, and SVMs on a unigram feature space. (Labels_B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Iy2mS1jTaj-c",
        "outputId": "d7059790-28b7-4fcf-8224-3e01343e3cbb"
      },
      "source": [
        "vocab_size = 1000\n",
        "# By default we can build a unigram model - capturing individual words only\n",
        "vectorizer = CountVectorizer(max_features=vocab_size)\n",
        "X = vectorizer.fit_transform(df_training[\"text\"])\n",
        "# Now lets make a DataFrame with our BOW model representations for each message\n",
        "bow_df = pd.DataFrame(X.toarray())\n",
        "column_names = [str(i) for i in range(vocab_size)]\n",
        "# Make the column names the words\n",
        "for k, v in vectorizer.vocabulary_.items():\n",
        "  column_names[v] = k\n",
        "bow_df.columns = column_names\n",
        "# Add our Y labels to our DataFrame\n",
        "bow_df[\"labels_B\"] = df_training[\"labels_B\"].values\n",
        "# Take a look at our DataFrame\n",
        "bow_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     00  00pm  04  0915  0ffsxzymap  10  100  11  11th  12  ...  yfoa4i09ex  \\\n",
              "0     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "1     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "2     0     0   0     0           0   0    0   0     0   1  ...           0   \n",
              "3     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "4     0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "..   ..   ...  ..   ...         ...  ..  ...  ..   ...  ..  ...         ...   \n",
              "155   0     0   0     0           0   1    0   0     0   0  ...           0   \n",
              "156   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "157   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "158   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "159   0     0   0     0           0   0    0   0     0   0  ...           0   \n",
              "\n",
              "     yoga  york  you  your  yrr3b  ytncrtupl2  yts  zachkleinwsb  labels_B  \n",
              "0       0     0    0     0      0           0    0             0  Positive  \n",
              "1       0     0    0     0      0           0    0             0   Neutral  \n",
              "2       0     0    0     0      0           0    0             0  Positive  \n",
              "3       0     0    0     0      0           0    0             0  Negative  \n",
              "4       0     0    0     0      0           0    0             0  Positive  \n",
              "..    ...   ...  ...   ...    ...         ...  ...           ...       ...  \n",
              "155     0     0    0     1      0           0    0             0   Neutral  \n",
              "156     0     0    0     0      0           0    0             0   Neutral  \n",
              "157     0     0    0     0      0           0    0             0   Neutral  \n",
              "158     0     0    1     0      0           0    0             0  Positive  \n",
              "159     0     0    0     0      0           0    0             0  Negative  \n",
              "\n",
              "[160 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bc99a7b-04ef-4041-b3cc-85d2890cbcd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>00pm</th>\n",
              "      <th>04</th>\n",
              "      <th>0915</th>\n",
              "      <th>0ffsxzymap</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>11th</th>\n",
              "      <th>12</th>\n",
              "      <th>...</th>\n",
              "      <th>yfoa4i09ex</th>\n",
              "      <th>yoga</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "      <th>yrr3b</th>\n",
              "      <th>ytncrtupl2</th>\n",
              "      <th>yts</th>\n",
              "      <th>zachkleinwsb</th>\n",
              "      <th>labels_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bc99a7b-04ef-4041-b3cc-85d2890cbcd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bc99a7b-04ef-4041-b3cc-85d2890cbcd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bc99a7b-04ef-4041-b3cc-85d2890cbcd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKUlVFTVakg_",
        "outputId": "b04cf081-1f1c-4131-ab50-fcdda1870ec1"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifiers = {\n",
        "    \"Bernoulli NB\": BernoulliNB(),\n",
        "    \"Linear SVM\": LinearSVC(),\n",
        "    \"RBF SVM\": SVC(kernel='rbf'),\n",
        "    \"Poly SVM\": SVC(kernel='poly'),\n",
        "    \"Complement NB\": ComplementNB(), \n",
        "    \"Multinomial NB\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", multi_class='ovr', max_iter=10000, random_state=123),\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "sorted_sentiments=[\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_B\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.058\n",
            "-------------\n",
            "Linear SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.105\n",
            "-------------\n",
            "RBF SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: -0.035\n",
            "-------------\n",
            "Poly SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.017\n",
            "-------------\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.152\n",
            "-------------\n",
            "Multinomial NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.136\n",
            "-------------\n",
            "Logistic Regression: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.114\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.152.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSmTmQ0fjQ3y"
      },
      "source": [
        "Among Naïve Bayes, Logistic Regression, and SVMs, the **Completement NB** performs the best, its kappa value eqauls 0.152."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlbg_G3WbNgH"
      },
      "source": [
        "#### **(b). Compare a unigram feature space with a feature space that also includes longer N-grams. (Labels_B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwjxuNjbLLS"
      },
      "source": [
        "# Create a vocab of n-grams from the dataframe\n",
        "def ngrams(df, vocab_size = 1000, max_n=1):\n",
        "  vectorizer = CountVectorizer(max_features=vocab_size, ngram_range=(1,max_n))\n",
        "  X = vectorizer.fit_transform(df[\"text\"])\n",
        "\n",
        "  bow_df = pd.DataFrame(X.toarray())\n",
        "  column_names = [str(i) for i in range(vocab_size)]\n",
        "  for k, v in vectorizer.vocabulary_.items():\n",
        "    column_names[v] = k\n",
        "  bow_df.columns = column_names\n",
        "\n",
        "  bow_df[\"labels_B\"] = df[\"labels_B\"].reset_index()['labels_B']\n",
        "  return bow_df\n",
        "# create unigram and bigrams DataFrame\n",
        "unigram_df = ngrams(df_training, max_n=1)\n",
        "bigram_df = ngrams(df_training, max_n=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IRi9xCnbZBD",
        "outputId": "b9416193-6c0d-4304-cad7-533cb09215f2"
      },
      "source": [
        "### Setup classifiers and metrics to be used on all n-grams\n",
        "# Since Complement NB performs the best in a), we pick it as our Classifier\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "### Compare classifiers on unigrams ###\n",
        "# Pick features to use\n",
        "feature_set = list(unigram_df.columns[:-1])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, feature_set, \"labels_B\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"The unigram classifier is: {best_name} \\nWith K={best:.3f}.\")    \n",
        "\n",
        "### Compare classifiers on bigrams ###\n",
        "# Pick features to use\n",
        "feature_set = list(bigram_df.columns[:-1])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bigram_df, feature_set, \"labels_B\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"The bigram classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.152\n",
            "-------------\n",
            "The unigram classifier is: Complement NB \n",
            "With K=0.152.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.158\n",
            "-------------\n",
            "The bigram classifier is: Complement NB \n",
            "With K=0.158.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI06BUcgjijz"
      },
      "source": [
        "Comparing unigram with bigram using Complement NB classifier, **bigram feature space** performs slighlt better. The kappa value equals 0.158."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye62dkD9bvTX"
      },
      "source": [
        "#### **(i). For Naive Bayes, evaluate different implementations: ComplementNB, MultinomialNB, BernoulliNB. (Labels_B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpvnKElXbueh",
        "outputId": "86fec889-21a7-4381-8490-9355908d1043"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Bernoulli NB\": BernoulliNB(),\n",
        "    \"Complement NB\": ComplementNB(), \n",
        "    \"Multinomial NB\": MultinomialNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result\n",
        "sorted_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_B\", labels=sorted_labels, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.058\n",
            "-------------\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.152\n",
            "-------------\n",
            "Multinomial NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.136\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.152.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufqrRI-gj0qQ"
      },
      "source": [
        "Among three types of Naive Bayes classifers, **Complement NB** performs the best. The best kappa value is 0.152.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-JytNm0cBso"
      },
      "source": [
        "#### **(k). For Logistic Regression, try L1 and L2 regularization, as well as unregularized features. (Labels_B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWthnokwcGK2",
        "outputId": "7c94b59f-34c6-4f27-9b81-ece96264f561"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"LogisticRegression l2\": LogisticRegression(penalty=\"l2\", solver=\"saga\", max_iter=10000, random_state=123),\n",
        "    \"LogisticRegression l1\": LogisticRegression(penalty='l1', random_state=123, solver='saga', max_iter=10000), \n",
        "    \"Unregularized Features\": LogisticRegression(random_state=123, solver='saga', max_iter=10000)}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result\n",
        "sorted_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_B\", labels=sorted_labels, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression l2: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.118\n",
            "-------------\n",
            "LogisticRegression l1: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.049\n",
            "-------------\n",
            "Unregularized Features: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.118\n",
            "-------------\n",
            "Best classifier is: LogisticRegression l2 \n",
            "With K=0.118.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ooKpKYUkBnG"
      },
      "source": [
        "Based on the above evaluation, logistic regression models with l2 penalty and unregularized logistic regression have similiar kappa value and both greately higher than logistic regression model with l1 pental. Logistic regression model with l2 penalty has the slight higher kappa value, which is 0.118. Thus the model with **l2 penalty** performs better. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRvmVIkpc8Sd"
      },
      "source": [
        "#### **(j). For Support Vector Machines, evaluate different kernels including a polynomial kernel and a radial basis function kernel. (Labels_B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38uG5Zntc7Ba",
        "outputId": "20b3589e-76f4-4ae3-cd59-6fa814f28622"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Linear SVM\": LinearSVC(),\n",
        "    \"RBF SVM\": SVC(kernel='rbf'),\n",
        "    \"Poly SVM\": SVC(kernel='poly')\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result\n",
        "sorted_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bow_df, feature_set, \"labels_B\", labels=sorted_labels, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.105\n",
            "-------------\n",
            "RBF SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: -0.035\n",
            "-------------\n",
            "Poly SVM: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.017\n",
            "-------------\n",
            "Best classifier is: Linear SVM \n",
            "With K=0.105.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3ToA1C4kMen"
      },
      "source": [
        "Based on the result, **Linear SVM** performs the best, with a kappa value of 0.105."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Among the five optimizations above, the best model is the one with **ComplementNB model with bigram feature space**. "
      ],
      "metadata": {
        "id": "DeymmpODnMW0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo7J0AIRdWDl"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K_btZyXdmZP"
      },
      "source": [
        "####**A Naive Bayes classifier with unigram features (Labels_B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0kGSwbEdgyy",
        "outputId": "88cd49eb-a359-4e11-b4a0-767704d6cb9e"
      },
      "source": [
        "# Train a Naive Bayes classifier with unigram features.\n",
        "unigram_df=ngrams(df, max_n=1)\n",
        "feature_set = list(unigram_df.columns[:-1])\n",
        "unigram_training=unigram_df.iloc[df_training.index,:]\n",
        "unigram_testing=unigram_df.iloc[df_testing.index,:]\n",
        "X_train=unigram_training.loc[:, feature_set]\n",
        "y_train=unigram_training.iloc[:,-1]\n",
        "X_test=unigram_testing.loc[:, feature_set]\n",
        "y_test=unigram_testing.iloc[:,-1]\n",
        "NB=BernoulliNB()\n",
        "NB.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpU1aSLEd47K"
      },
      "source": [
        "####**The best-tuned model from task two, retrained on the full 80% training set. (Labels_B)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xQ3eRvMdvMB",
        "outputId": "8a2c4084-b679-4460-c639-85c1fe6d9147"
      },
      "source": [
        "# Train the best performance model-Complement NB bigram features\n",
        "NBC=ComplementNB()\n",
        "bigram_df=ngrams(df, max_n=2)\n",
        "feature_set = list(bigram_df.columns[:-1])\n",
        "bigram_training=bigram_df.iloc[df_training.index,:]\n",
        "bigram_testing=bigram_df.iloc[df_testing.index,:]\n",
        "X_train2=bigram_training.loc[:, feature_set]\n",
        "y_train2=bigram_training.iloc[:,-1]\n",
        "X_test2=bigram_testing.loc[:, feature_set]\n",
        "y_test2=bigram_testing.iloc[:,-1]\n",
        "NBC.fit(X_train2,y_train2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplementNB()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyHgRQs7eMPB"
      },
      "source": [
        "####**Report three sets of evaluation metrics (Labels_B):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnLhFnFceRh7",
        "outputId": "17223998-b1e2-4bfc-a0f8-b9b0d741d468"
      },
      "source": [
        "# Calculate and print the estimated performance from 10-fold-validation.\n",
        "a_scores = cross_val_score(estimator = NB,\n",
        "                         X = X_train,\n",
        "                         y = y_train,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = \"accuracy\")\n",
        "# print('10-fold accuracy: %s' % a_scores)\n",
        "print(\"Estimated performance from cross-validation:\")\n",
        "print('10-fold accuracy: %.3f +/- %.3f' % (np.mean(a_scores), np.std(a_scores)))\n",
        "\n",
        "kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "k_scores = cross_val_score(estimator = NB,\n",
        "                         X = X_train,\n",
        "                         y = y_train,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = kappa_scorer)\n",
        "# print('10-fold Cohen's Kappa: %s' % k_scores)\n",
        "print('10-fold Kappa: %.3f +/- %.3f' % (np.mean(k_scores), np.std(k_scores)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Calculate and print the performance of the Bernoulli NB model on the held-out test set.\n",
        "print(\"Performance on the held-out test set:\")\n",
        "y_pred = NB.predict(X_test)\n",
        "accuracy_NB = accuracy_score(y_test, y_pred)\n",
        "print(f\"The accuracy is: {accuracy_NB:.4f}.\")\n",
        "kappa_NB = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"The Kappa is: {kappa_NB:.4f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated performance from cross-validation:\n",
            "10-fold accuracy: 0.481 +/- 0.101\n",
            "10-fold Kappa: 0.096 +/- 0.171\n",
            "------------------------------------\n",
            "Performance on the held-out test set:\n",
            "The accuracy is: 0.5250.\n",
            "The Kappa is: 0.2475.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5muigXoTexIx",
        "outputId": "57884353-e8c2-47b5-9a56-63165c6285bc"
      },
      "source": [
        "# Calculate and print the estimated performance from 10-fold-validation.\n",
        "a_scores2 = cross_val_score(estimator = NBC,\n",
        "                         X = X_train2,\n",
        "                         y = y_train2,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = \"accuracy\")\n",
        "# print('10-fold accuracy: %s' % a_scores)\n",
        "print(\"Estimated performance from cross-validation:\")\n",
        "print('10-fold accuracy: %.3f +/- %.3f' % (np.mean(a_scores2), np.std(a_scores2)))\n",
        "\n",
        "kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "k_scores2 = cross_val_score(estimator = NBC,\n",
        "                         X = X_train2,\n",
        "                         y = y_train2,\n",
        "                         cv = 10,\n",
        "                         n_jobs = 1,\n",
        "                         scoring = kappa_scorer)\n",
        "# print('10-fold Cohen's Kappa: %s' % k_scores)\n",
        "print('10-fold Kappa: %.3f +/- %.3f' % (np.mean(k_scores2), np.std(k_scores2)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Calculate and print the performance of the best-tuned model on the held-out test set.\n",
        "print(\"Performance on the held-out test set:\")\n",
        "y_pred = NBC.predict(X_test2)\n",
        "accuracy_NBC = accuracy_score(y_test2, y_pred)\n",
        "print(f\"The accuracy is: {accuracy_NBC:.4f}.\")\n",
        "kappa_NBC = cohen_kappa_score(y_test2, y_pred)\n",
        "print(f\"The Kappa is: {kappa_NBC:.4f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated performance from cross-validation:\n",
            "10-fold accuracy: 0.456 +/- 0.097\n",
            "10-fold Kappa: 0.163 +/- 0.145\n",
            "------------------------------------\n",
            "Performance on the held-out test set:\n",
            "The accuracy is: 0.4750.\n",
            "The Kappa is: 0.1977.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the three sets of evaluation metircs above, the accuracy for simple Naïve Bayes unigram classifier on the held-out test set is 0.525 and Kappa is 0.2475, while the estimated performance from 10-fold cross-validation in task 2 shows accuracy 0.481 +/- 0.101 and Kappa 0.096 +/- 0.171. Both the accuracy and Kappa are in the estimated range. \n",
        "\n",
        "For the best-tuned model (ComplementNB with bigram) on the held-out test set, the accuracy is 0.4750 and Kappa is 0.1977, while the estimated performance from 10-fold cross-validation in task 2 shows accuracy 0.456 +/- 0.097 and Kappa 0.163 +/- 0.145. Both the accuracy and Kappa are in the estimated range. \n"
      ],
      "metadata": {
        "id": "WKgbljzPWzrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison between labels_A and labels_B:** the best-tuned model with labels_A is logistic regression on unigram feature space, while with labels_B is the one with the Complement Naive Bayes classifier on bigram feature space. Comparing the best-tuned model of both labels_A and labels_B, we mainly look at the accuracy and kappa value on the held-out test set. For accuracy, labels_A is 0.5250 and labels_B is 0.4750, so labels_A is 0.05 better than labels_B. For Kappa, labels_A is 0.1017 and labels_B is 0.1977, so labels_B is 0.096 better than labels_A. Since mainly we rely on Kappa score for judgement, the performance with **labels_B is better** overall.  "
      ],
      "metadata": {
        "id": "XMLcV3d4W6dk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2upx-ygRKE-"
      },
      "source": [
        "\n",
        "# Scoring Rubric\n",
        "![](https://drive.google.com/uc?export=view&id=1JqI8Tfmi3YrnjVdDxjwNu1ZOuOOgQCuI)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1VfVuKGmNBu6oJgXBTX4YB6Lxe_0t9cWN)"
      ]
    }
  ]
}