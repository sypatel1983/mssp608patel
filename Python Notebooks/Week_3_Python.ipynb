{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dGUsekIP1TQ"
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from matplotlib import dates\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-nnWJXXnr-f"
      },
      "source": [
        "# Prerequisites (What you should know from Day 1)\n",
        "\n",
        "Here's what you should understand well from day 1 to be able to understand this notebook. If you don't feel comfortable with any of these topics its HIGHLY recommended that you review it before continuing with this notebook!\n",
        "\n",
        "- Preprocessing the data with pandas\n",
        "- What are decision trees\n",
        "- How to train a decision tree in scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfzos_3nR3-F"
      },
      "source": [
        "# Downloading and Preprocessing the Data (Same as in Day 1)\n",
        "\n",
        "If you understand this part of the Day 1 notebook, then feel free to skip over reading this part of the notebook since it is exactly the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrIzmeDLSDfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dc7235-7e36-4c72-9c33-c2a87559cda1"
      },
      "source": [
        "# Download the data\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ' -O bikeshare_train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-27 20:33:31--  https://docs.google.com/uc?export=download&id=0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.203.113, 74.125.203.100, 74.125.203.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jc97pnmmh6l4hsuama7iq5p6sarvbtuf/1643315550000/09819396713149841370/*/0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-01-27 20:33:32--  https://doc-0s-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jc97pnmmh6l4hsuama7iq5p6sarvbtuf/1643315550000/09819396713149841370/*/0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ?e=download\n",
            "Resolving doc-0s-5c-docs.googleusercontent.com (doc-0s-5c-docs.googleusercontent.com)... 74.125.204.132, 2404:6800:4008:c04::84\n",
            "Connecting to doc-0s-5c-docs.googleusercontent.com (doc-0s-5c-docs.googleusercontent.com)|74.125.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 648353 (633K) [text/csv]\n",
            "Saving to: ‘bikeshare_train.csv’\n",
            "\n",
            "bikeshare_train.csv 100%[===================>] 633.16K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-01-27 20:33:32 (127 MB/s) - ‘bikeshare_train.csv’ saved [648353/648353]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFc_Fr7wP1Td"
      },
      "source": [
        "# Load the data with pandas and properly setup the date/time data\n",
        "bikeshare = pd.read_csv(\"bikeshare_train.csv\")\n",
        "bikeshare[\"date_objs\"] = bikeshare[\"datetime\"].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT0M5uPOP1Tj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "490e313c-b00b-4e5f-d3a2-58017f57b676"
      },
      "source": [
        "# Create columns for different parts of the date/time data\n",
        "bikeshare[\"hour\"] = bikeshare[\"date_objs\"].apply(lambda x: x.hour)\n",
        "bikeshare[\"day\"] = bikeshare[\"date_objs\"].apply(lambda x: x.day)\n",
        "bikeshare[\"month\"] = bikeshare[\"date_objs\"].apply(lambda x: x.month)\n",
        "bikeshare[\"year\"] = bikeshare[\"date_objs\"].apply(lambda x: x.year)\n",
        "bikeshare[\"weekday\"] = bikeshare[\"date_objs\"].apply(lambda x: x.weekday())\n",
        "bikeshare[\"plot_time\"] = bikeshare[\"datetime\"].apply(dates.datestr2num)\n",
        "\n",
        "bikeshare[\"month_str\"] = bikeshare[\"month\"].apply(lambda x: calendar.month_name[x])\n",
        "bikeshare[\"weekday_str\"] = bikeshare[\"weekday\"].apply(lambda x: calendar.day_name[x])\n",
        "\n",
        "# Create column to tell to represent the traffic ammount \n",
        "bikeshare[\"high_traffic\"] = bikeshare[\"count\"] > 145\n",
        "bikeshare[\"low_traffic\"] = bikeshare[\"count\"] < 145\n",
        "\n",
        "\n",
        "# Create columns for the weather data\n",
        "def weather_norm(x):\n",
        "    if x == 1:\n",
        "        return \"clear\"\n",
        "    if x == 2:\n",
        "        return \"overcast\"\n",
        "    if x > 2:\n",
        "        return \"gross\"\n",
        "    \n",
        "bikeshare[\"weather_norm\"] = bikeshare[\"weather\"].apply(weather_norm)\n",
        "\n",
        "# Check the distribution of the weather data and preview the dataframe\n",
        "print(bikeshare[\"weather_norm\"].value_counts())\n",
        "bikeshare.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clear       7192\n",
            "overcast    2834\n",
            "gross        860\n",
            "Name: weather_norm, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9c4ced78-ddd4-41fa-a43d-d0645dad46da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "      <th>date_objs</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>weekday</th>\n",
              "      <th>plot_time</th>\n",
              "      <th>month_str</th>\n",
              "      <th>weekday_str</th>\n",
              "      <th>high_traffic</th>\n",
              "      <th>low_traffic</th>\n",
              "      <th>weather_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.000000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.041667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.083333</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.125000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.166667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c4ced78-ddd4-41fa-a43d-d0645dad46da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c4ced78-ddd4-41fa-a43d-d0645dad46da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c4ced78-ddd4-41fa-a43d-d0645dad46da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              datetime  season  holiday  ...  high_traffic  low_traffic  weather_norm\n",
              "0  2011-01-01 00:00:00       1        0  ...         False         True         clear\n",
              "1  2011-01-01 01:00:00       1        0  ...         False         True         clear\n",
              "2  2011-01-01 02:00:00       1        0  ...         False         True         clear\n",
              "3  2011-01-01 03:00:00       1        0  ...         False         True         clear\n",
              "4  2011-01-01 04:00:00       1        0  ...         False         True         clear\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjzEnlHSSrJx"
      },
      "source": [
        "# Train/Test Splits\n",
        "\n",
        "Setting data into different groups for training and testing is a very important part of the data sciene workflow. Many of the models we use can easily fit the data set they are trained on perfectly, but this usually results in nonsensical models that are \"overfitted\" to the data and cannot generalize to any other new  data points. This makes them basically useless. Setting aside some data for testing allows us to simulate this change and perform better evaluations of our model. [Check this resource out for more info on train/test splits.](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocwdyn7VP1Tr"
      },
      "source": [
        "## Creating the Train/Test Split\n",
        "\n",
        "Now that we know that using a train/test split is important for properly evaluating our models, let's consider some different ways to potentially create that train/test split. We'll see that we have to be careful when creating our train/test split to make sure that it makes sense. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv54N-ouXIMV"
      },
      "source": [
        "### The most naive split\n",
        "\n",
        "What is the simplest way to create a train/test split? Draw a line at some point in the dataset and take one side to be the train data and the other to be the test data! The following steps detail an easy procedure to do this. \n",
        "1.   Pick a size for the test set (in this case, we will use 20% of the data for the test set)\n",
        "2.   Take the first section of data as the train set\n",
        "3.   Take the second section of data as the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yw9SrsAP1Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881b8914-acb1-44ce-c024-52c81222edd7"
      },
      "source": [
        "# Calculate where the cutoff should be if we want 20% of our data to be in the test set\n",
        "test_set_percentage = 0.2\n",
        "test_set_size = int(len(bikeshare)*test_set_percentage) \n",
        "test_cutoff = len(bikeshare) - test_set_size \n",
        "\n",
        "# Take everything before the cutoff to be the train set\n",
        "bikeshare_train = bikeshare[:test_cutoff]\n",
        "\n",
        "# Take everything after the cutoff to be the test set \n",
        "bikeshare_test = bikeshare[test_cutoff:]\n",
        "\n",
        "# Lets check to make sure the size of our train and test data seem about correct\n",
        "print(\"Size of train data:\", len(bikeshare_train))\n",
        "print(\"Size of test  data:\", len(bikeshare_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train data: 8709\n",
            "Size of test  data: 2177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEUgllhmP1Ty"
      },
      "source": [
        "But doing this split naively can sometimes be a big problem! To see why, lets look at the distribution of the months represented in the train set and the months represented in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvkAoadoP1T0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070b1ddb-ba51-4dc5-96cb-b5be6f86eec7"
      },
      "source": [
        "print(\"Training set months:\")\n",
        "print(bikeshare_train[\"month_str\"].value_counts())\n",
        "print('-----------')\n",
        "print(\"Test set months:\")\n",
        "print(bikeshare_test[\"month_str\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set months:\n",
            "May          912\n",
            "June         912\n",
            "July         912\n",
            "April        909\n",
            "March        901\n",
            "February     901\n",
            "January      884\n",
            "August       558\n",
            "December     456\n",
            "November     456\n",
            "October      455\n",
            "September    453\n",
            "Name: month_str, dtype: int64\n",
            "-----------\n",
            "Test set months:\n",
            "December     456\n",
            "October      456\n",
            "September    456\n",
            "November     455\n",
            "August       354\n",
            "Name: month_str, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CMilxnP1T7"
      },
      "source": [
        "### Improving our sampling method\n",
        "Notice that our test set only contains 5/12 of the months! This means that whenever we run our model, we are only evaluating our model on its performance during these months. What we really want is to evaluate our model on a little bit of data from every month so, clearly, this method is not what we want for this task. \n",
        "\n",
        "So, how can we fix this? Lets think about why the problem is occuring in the first place. The best way to do this is to look at the data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ktlMxGdcwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "08e41bc2-76f9-4b63-91a8-e1da543a4ed5"
      },
      "source": [
        "bikeshare.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d1075c7-5664-4aec-926e-580f53aa1f21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "      <th>date_objs</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>weekday</th>\n",
              "      <th>plot_time</th>\n",
              "      <th>month_str</th>\n",
              "      <th>weekday_str</th>\n",
              "      <th>high_traffic</th>\n",
              "      <th>low_traffic</th>\n",
              "      <th>weather_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.000000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.041667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.083333</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.125000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.166667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d1075c7-5664-4aec-926e-580f53aa1f21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d1075c7-5664-4aec-926e-580f53aa1f21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d1075c7-5664-4aec-926e-580f53aa1f21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              datetime  season  holiday  ...  high_traffic  low_traffic  weather_norm\n",
              "0  2011-01-01 00:00:00       1        0  ...         False         True         clear\n",
              "1  2011-01-01 01:00:00       1        0  ...         False         True         clear\n",
              "2  2011-01-01 02:00:00       1        0  ...         False         True         clear\n",
              "3  2011-01-01 03:00:00       1        0  ...         False         True         clear\n",
              "4  2011-01-01 04:00:00       1        0  ...         False         True         clear\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKuyROlndhpa"
      },
      "source": [
        "If we look at the data, we can quickly realize that the data points are sorted by their date/time! This means that when we are taking the last 20% of the data, we are actually taking the data from the last 20% of dates/times and this is why we only see a few of the months appear in our current test set!\n",
        "\n",
        "Lets come up with a different way to sample our test data that avoids this problem. An easy way to do this if we want 20% of our data in the test set is to through the data in order and for every 5 data points, we set the first 1 to be test data and the last 4 to be train data. Visually, we can compare the two sampling methods in the following way:\n",
        "\n",
        "Simplest method: OOOOOOOOOOOOXXX\n",
        "\n",
        "Improved method: OOOOXOOOOXOOOOX\n",
        "\n",
        "Now lets try implementing this in code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJuuF13aP1T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9e6a26-ea66-4800-8de2-ecc5d930ab71"
      },
      "source": [
        "# Calculate how often to send data to the test set (in our case for an 80/20 train/test split)\n",
        "test_size = 0.2\n",
        "test_modulus = int(1/test_size)\n",
        "\n",
        "# Set 4/5 data points from each set of 5 data points to be in the train set\n",
        "bikeshare_train = bikeshare.iloc[bikeshare.index % test_modulus != 0]\n",
        "# Set the remaining 1 data point from each set of 5 data points to be in the test set\n",
        "bikeshare_test = bikeshare.iloc[bikeshare.index % test_modulus == 0]\n",
        "\n",
        "# Lets confirm the size of the train and test set are still about right\n",
        "print(\"Size of train data:\", len(bikeshare_train))\n",
        "print(\"Size of test  data:\", len(bikeshare_test))\n",
        "\n",
        "# Lets examine the distribution of the months in the two datasets\n",
        "print(\"Training set months:\")\n",
        "print(bikeshare_train[\"month_str\"].value_counts())\n",
        "print(\"Test set months:\")\n",
        "print(bikeshare_test[\"month_str\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train data: 8708\n",
            "Size of test  data: 2178\n",
            "Training set months:\n",
            "May          730\n",
            "August       730\n",
            "October      729\n",
            "June         729\n",
            "July         729\n",
            "December     729\n",
            "November     728\n",
            "September    728\n",
            "April        727\n",
            "March        721\n",
            "February     721\n",
            "January      707\n",
            "Name: month_str, dtype: int64\n",
            "Test set months:\n",
            "July         183\n",
            "June         183\n",
            "December     183\n",
            "November     183\n",
            "May          182\n",
            "October      182\n",
            "August       182\n",
            "April        182\n",
            "September    181\n",
            "March        180\n",
            "February     180\n",
            "January      177\n",
            "Name: month_str, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe5oIwknc48R"
      },
      "source": [
        "Notice how now our train and test datasets now have the same distribution of months! If we didn't look at the data, it would seem like these two methods are essentially identical and interchangable. This example shows us that sometimes a very simple modification can make a big difference and why its important to be careful when making our train/test split. \n",
        "\n",
        "Now, it might seem like we can always use this second method we have developed and like it will always be better than the first method. In practice, this turns out to be very false. For example, if we had taken 1 out of every 12 data points to be in our test set, our test set would be entirely data points from noon and midnight, with no other times represented! It is important to think about your data carefully before making a decision on how to do your train/test split! Here are some resources to learn more about this problem:\n",
        "\n",
        "- [The story of a bad train/test split](https://anotherdatum.com/train-test.html)\n",
        "- [Random Test/Train Splits is Not Always Enough](http://www.win-vector.com/blog/2015/01/random-testtrain-split-is-not-always-enough/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx8avvDtP1UC"
      },
      "source": [
        "## Comparing models with Train/Test Splits\n",
        "\n",
        "Lets see how we can use the train/test split we created to better understand and compare different models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5M0pQJpqAWI"
      },
      "source": [
        "# Create lists of possible features (Same as in Day 1)\n",
        "date_features = [\"day\", \"month_str\", \"year\", \"weekday_str\", \"season\", \"holiday\", \"workingday\"]\n",
        "time_features = [\"hour\"]\n",
        "weather_features = [\"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
        "\n",
        "feature_sets = {\n",
        "    \"date\": date_features,\n",
        "    \"time\": time_features,\n",
        "    \"date + time\": date_features + time_features,\n",
        "    \"weather\": weather_features,\n",
        "    \"all\": date_features + time_features + weather_features\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nuB1Z1NqP1UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee071a29-2f48-44dd-d6fb-64d55051a09f"
      },
      "source": [
        "# We'll keep track of which classifier was the best\n",
        "best = 0\n",
        "best_name = None\n",
        "best_actual = None\n",
        "best_predictions = None\n",
        "\n",
        "test_accuracies = []\n",
        "train_accuracies = []\n",
        "\n",
        "# For each feature set, we evaluate our model on both the train and the test set\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    # Create a dummyset with only the features in our feature set\n",
        "    X = bikeshare.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = bikeshare[\"high_traffic\"]\n",
        "\n",
        "    # Use scikit-learn to create our train/test split and train our decision tree\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "\n",
        "    # Calculate our accuracy on the train and test sets\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_accuracy = 100*accuracy_score(y_train, train_pred)\n",
        "    test_pred = model.predict(X_test)\n",
        "    test_accuracy = 100*accuracy_score(y_test, test_pred)\n",
        "\n",
        "    # Keep track of the best model on the test set\n",
        "    if test_accuracy > best:\n",
        "        best = test_accuracy\n",
        "        best_name = set_name\n",
        "        best_actual = y_test\n",
        "        best_predictions = test_pred\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Display the accuracy on the train and test set for each model\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(f\"Accuracy on the train set: {train_accuracy:.1f}\")\n",
        "    print(f\"Accuracy on the test set: {test_accuracy:.1f}\")\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for date:\n",
            "Accuracy on the train set: 66.4\n",
            "Accuracy on the test set: 62.6\n",
            "------------------------\n",
            "Results for time:\n",
            "Accuracy on the train set: 81.0\n",
            "Accuracy on the test set: 80.1\n",
            "------------------------\n",
            "Results for date + time:\n",
            "Accuracy on the train set: 100.0\n",
            "Accuracy on the test set: 90.8\n",
            "------------------------\n",
            "Results for weather:\n",
            "Accuracy on the train set: 90.7\n",
            "Accuracy on the test set: 68.5\n",
            "------------------------\n",
            "Results for all:\n",
            "Accuracy on the train set: 100.0\n",
            "Accuracy on the test set: 90.7\n",
            "------------------------\n",
            "Best feature set is: date + time \n",
            "With: 90.8% accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3rBROZYuP1UL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ba68deba-2f3e-4c4a-fac3-383e783aa512"
      },
      "source": [
        "locs = np.arange(len(test_accuracies))\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.bar(locs-0.2, train_accuracies, width=0.4)\n",
        "ax.bar(locs+0.2, test_accuracies, width=0.4)\n",
        "ax.set_xticks(locs)\n",
        "ax.set_xticklabels(list(feature_sets.keys()))\n",
        "ax.legend([\"Train Accuracy\", \"Test Accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hg5ZZ4zthbn"
      },
      "source": [
        "If we had just looked at the train set, we would have thought that using date and time alone we could perfectly model the levels of bikeshare traffic. Once we look at the test accuracy, we realize that that is not true at all! While 90% accuracy is pretty great, that 10% of misclassified data demonstrates that our model is definitely not perfect. \n",
        "\n",
        "We can also see that the model trained on just date/time is actually better than the model trained on date/time/weather! This is an example of more data not always being better and an example of how our decision tree algorithm does not always converge to the optimal tree, just a pretty good one!\n",
        "\n",
        "Here are some more resources diving further into comparing models using train/test splits and the convergence of decision trees:\n",
        "\n",
        "- [Train/Test Splits and Cross Validation in Python](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
        "- [Disadvantages of Decision Trees (this article is pretty technical)](https://www.edupristine.com/blog/decision-trees-development-and-scoring)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9KIukwvP1UQ"
      },
      "source": [
        "# Metrics of Model Quality\n",
        "\n",
        "While accuracy is great some of the time, there are many cases where it is not a good metric for understanding the performance of our models. Lets explore some alternate methods for evaluating our models and figure out when we should be using them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQjfddI-zMoJ"
      },
      "source": [
        "# Lets keep the predictions from the best tree that we found to use in this section\n",
        "predictions = best_predictions\n",
        "actual = np.array(list(best_actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjbrVmTsP1UW"
      },
      "source": [
        "### Accuracy\n",
        "\n",
        "$$ accuracy = \\frac{correct \\space predictions}{total \\space predictions} \\times 100 $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO8JyuwvP1UY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d969747-8564-4c7d-96e9-1964e3ff4ab0"
      },
      "source": [
        "# Calculating accuracy manually\n",
        "matches = (predictions == actual).sum() \n",
        "accuracy = matches / len(actual)\n",
        "print(f\"Manual accuracy metric: {100*accuracy:.1f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual accuracy metric: 90.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bq3FRJA2ghY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467b2977-4e8d-4dfd-e97a-0ff1403c0fd5"
      },
      "source": [
        "# Calculating accuracy with scikit-learn\n",
        "accuracy = accuracy_score(actual, predictions)\n",
        "print(f\"scikit-learn accuracy metric: {100*accuracy:.1f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn accuracy metric: 90.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkSqyL94yVME"
      },
      "source": [
        "#### Pros/Cons the accuracy metric\n",
        "\n",
        "**Benefit**\n",
        "- Accuracy is very intuitive and easy to understand\n",
        "\n",
        "**Weakness**\n",
        "- Accuracy can sometimes paint an inaccurate picture of the model. For example, consider a model that predicts whether or not there will be an earthquake in LA today. You could get >99% accuracy by just guessing no every time, so accuracy can be very misleading in this case!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qzDpWovP1Uc"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "The confusion matrix is a great way to visualize where our model is making errors. Elements on the diagonal represent correct predictions. Elements off the diagonal represent that the model predicted the wrong class.\n",
        "\n",
        "![Example Confusion Matrix](https://www.mathworks.com/help/examples/nnet/win64/CreateConfusionMatrixChartExample_02.png)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGC_guSsP1Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db38ae4f-5212-427c-cf91-b98e7f48096c"
      },
      "source": [
        "# Generating our confusion matrix manually\n",
        "\n",
        "# Helper function to display our confusion matrix nicely\n",
        "def matrix_print(matrix):\n",
        "    print(\"           Predictions\")\n",
        "    print(f\"Actual    |\", end='')\n",
        "    for pred in list(matrix.keys()):\n",
        "        print(f\"{str(pred).rjust(10)}|\", end='')\n",
        "    print()\n",
        "    for act in list(matrix.keys()):\n",
        "        print(f\"{str(act).rjust(10)}|\", end='')\n",
        "        for pred in list(matrix.keys()):\n",
        "            cell = matrix[pred][act]\n",
        "            print(f\"{str(cell).rjust(10)}|\", end='')\n",
        "        print()\n",
        "\n",
        "# Actually computing our confusion matrix         \n",
        "def build_confusion_matrix(actual, predictions):\n",
        "    confusion_matrix = {}\n",
        "    for pred_value in np.unique(predictions):\n",
        "        confusion_matrix[pred_value] = {}\n",
        "        for act_value in np.unique(actual):\n",
        "            cell_count = 0\n",
        "            for i in range(len(actual)):\n",
        "                if predictions[i] == pred_value and actual[i] == act_value:\n",
        "                    cell_count += 1\n",
        "            confusion_matrix[pred_value][act_value] = cell_count\n",
        "    return confusion_matrix\n",
        "\n",
        "conf_matrix = build_confusion_matrix(actual, predictions)\n",
        "matrix_print(conf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Predictions\n",
            "Actual    |     False|      True|\n",
            "     False|       976|        97|\n",
            "      True|       103|      1002|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ2y9AnqzzGI"
      },
      "source": [
        "#### Pros/Cons of the confusion matrix\n",
        "\n",
        "**Benefit**\n",
        "- Gives us a deeper understanding of our model performance than accuracy alone\n",
        "\n",
        "**Weakness**\n",
        "- We don't get a single number out so it is hard to tell which model is \"better\" when comparing two models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auzth_5JP1Uj"
      },
      "source": [
        "### Cohen's Kappa\n",
        "\n",
        "$$ \\kappa = \\frac{accuracy - chance \\space agreement}{1 - chance \\space agreement}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkCyuEgrP1Uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d044bf5e-1372-4f7e-ed86-fc9d32118a57"
      },
      "source": [
        "# Calculating Kappa Manually\n",
        "matching_by_chance = 0\n",
        "for label in np.unique(actual):\n",
        "    predicted_probability = (predictions == label).sum() / len(predictions)\n",
        "    actual_probability = (actual == label).sum() / len(actual)\n",
        "    matching_by_chance += (predicted_probability * actual_probability)\n",
        "\n",
        "print(f\"Probability of matching by chance: {matching_by_chance:.3f}\")\n",
        "kappa = (accuracy - matching_by_chance) / (1 - matching_by_chance)\n",
        "print(f\"Manual kappa metric: {kappa:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of matching by chance: 0.500\n",
            "Manual kappa metric: 0.816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKOYL5VT9i3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ad0e9a-6f5b-4566-ad14-8646507905d8"
      },
      "source": [
        "# Calculating Kappa with scikit-learn\n",
        "kappa = cohen_kappa_score(actual, predictions)\n",
        "print(f\"scikit-learn kappa metric: {kappa:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn kappa metric: 0.816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rml2sD4e99c0"
      },
      "source": [
        "#### Pros/Cons of Cohen's Kappa\n",
        "\n",
        "**Benefit**\n",
        "- Gives us a single number that evaluates the accuracy of our model and compares it to a simple baseline model -- guessing randomly based on the distribution of the data\n",
        "\n",
        "**Weakness**\n",
        "- What threshold denotes a \"good\" kappa value is highly subjective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trf8kb9JP1Up"
      },
      "source": [
        "### Precision, Recall, and F-Score\n",
        "\n",
        "$$ Precision = \\frac{sucessful \\space predictions}{predicted \\space positives}$$\n",
        "$$ Recall = \\frac{sucessful \\space predictions}{actual \\space positives}$$\n",
        "$$ F \\mbox{-} score = \\frac{2 \\times precision \\times recall}{precision + recall}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QQ58yjrsP1Uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6fa423-8f7d-4ab9-9851-a28e8730e2d2"
      },
      "source": [
        "# Compute Precision, Recall, and F-Score Manually\n",
        "# Compute number of predictions, number of correct predictions, and number of total positives\n",
        "predicted_positives = (predictions == True).sum()\n",
        "actual_positives = (actual == True).sum()\n",
        "successful_predictions = 0\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] == True and actual[i] == True:\n",
        "        successful_predictions += 1\n",
        "\n",
        "# Compute Precision Manually\n",
        "precision = successful_predictions / predicted_positives\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "# Compute Recall Manually\n",
        "recall = successful_predictions / actual_positives\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "\n",
        "#Compute F-Score Manually\n",
        "f = (2*precision*recall)/(precision + recall)\n",
        "print(f\"F-Score: {f:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.912\n",
            "Recall: 0.907\n",
            "F-Score: 0.909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RabGO8IbP1U0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951727cf-0e3c-4c08-ed38-d18a99c63635"
      },
      "source": [
        "# Compute Precision, Recall, and F-Score with a Confusion Matrix\n",
        "conf_matrix = build_confusion_matrix(actual, predictions)\n",
        "\n",
        "successful_positives = conf_matrix[True][True]\n",
        "predicted_positives = 0\n",
        "for a in conf_matrix[True].keys():\n",
        "    predicted_positives += conf_matrix[True][a]\n",
        "\n",
        "precision = successful_positives / predicted_positives\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "actual_positives = 0\n",
        "for p in conf_matrix.keys():\n",
        "    actual_positives += conf_matrix[p][True]\n",
        "    \n",
        "recall = successful_positives / actual_positives\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "\n",
        "f = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "print(f\"F-Score: {f:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.912\n",
            "Recall: 0.907\n",
            "F-Score: 0.909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJT27o2dCROO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce97460f-b9e6-41e2-fbf4-06b8ab7eaa47"
      },
      "source": [
        "# Compute Precision, Recall, and F-Score with scikit-learn\n",
        "precision = precision_score(actual, predictions)\n",
        "recall = recall_score(actual, predictions)\n",
        "f = f1_score(actual, predictions)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F-Score: {f:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.912\n",
            "Recall: 0.907\n",
            "F-Score: 0.909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8xHX1LxDtVf"
      },
      "source": [
        "#### Pros/Cons of F-score\n",
        "\n",
        "**Benefit**\n",
        "- Achieves a balance between precision and recall without sacrificing much of either\n",
        "\n",
        "**Weakness**\n",
        "- It is hard to interpret, and is not as useful when we care about one of the two components more than the other\n",
        "\n",
        "**High precision is important when...**\n",
        "- You are working with limited resources and can’t say yes often\n",
        "- The stakes for making a mistake are very high\n",
        "\n",
        "**High recall is important when...**\n",
        "- It is not very expensive or hard to say yes to everything\n",
        "- The cost of missing out is greater than the cost of making a mistake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8fkR4TaP1U5"
      },
      "source": [
        "### Additional metric calculation\n",
        "\n",
        "There are many other metrics that could be used to compare models. Here are a few more:\n",
        "\n",
        "$$ specificity = \\frac{successful \\space negatives}{actual \\space negatives}$$\n",
        "\n",
        "$$ sensitivity = \\frac{successful \\space positives}{actual \\space positives} = recall $$\n",
        "\n",
        "$$ false \\space positive \\space rate = \\frac{false \\space positives}{predicted \\space positives}$$\n",
        "\n",
        "$$ false \\space negative \\space rate = \\frac{false \\space negatives}{predicted \\space negatives}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuQ_Ox6qP1U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3784159-4e67-4ff6-8dcb-b7f4a7b2a81f"
      },
      "source": [
        "conf_matrix = build_confusion_matrix(actual, predictions)\n",
        "\n",
        "# Specificity\n",
        "successful_negatives = conf_matrix[False][False]\n",
        "actual_negatives = 0\n",
        "for p in conf_matrix.keys():\n",
        "    actual_negatives += conf_matrix[p][False]\n",
        "specificity = successful_negatives / actual_negatives\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "# Sensitivity\n",
        "actual_positives = 0\n",
        "for p in conf_matrix.keys():\n",
        "    actual_positives += conf_matrix[p][True]\n",
        "\n",
        "sensitivity = successful_positives / actual_positives\n",
        "print(f\"Sensitivity: {sensitivity:.3f}\")\n",
        "\n",
        "# False Positive Rate\n",
        "false_positives = conf_matrix[True][False]\n",
        "predicted_positives = 0\n",
        "for a in conf_matrix[True].keys():\n",
        "    predicted_positives += conf_matrix[True][a]\n",
        "fpr = false_positives / predicted_positives\n",
        "print(f\"False Positive Rate: {fpr:.3f}\")\n",
        "\n",
        "# False Negative Rate\n",
        "false_negatives = conf_matrix[False][True]\n",
        "predicted_negatives = 0\n",
        "for a in conf_matrix[False].keys():\n",
        "    predicted_negatives += conf_matrix[False][a]\n",
        "fnr = false_negatives / predicted_negatives\n",
        "print(f\"False Negative Rate: {fnr:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specificity: 0.910\n",
            "Sensitivity: 0.907\n",
            "False Positive Rate: 0.088\n",
            "False Negative Rate: 0.095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-jwJxaUIxqm"
      },
      "source": [
        "#### Pros/Cons of these metrics\n",
        "\n",
        "**Benefit**\n",
        "- In some use cases, certain results have much bigger impacts than other. For example, in a self-driving car, we'd much rather have a false positive detection of a human in front of the car than a false negative. In the case of a false positive, the car detects a human who isn't there and slows down which is fine, but in a false negative the car does not detect a human that is there and runs them over. For these sorts of high sensitivity use cases, these metrics can be very important. \n",
        "\n",
        "**Weakness**\n",
        "- Each of these metrics only paints a partial picture of our model's performance as they are highly specialized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0nOkdOP1U-"
      },
      "source": [
        "### Using metrics to compare models\n",
        "Now let's group everything together, all in a single loop, using scikit-learn's built-in calculations for several of the above metrics and compare our models. Notice how the scikit-learn functions for each of the metrics takes in the same inputs in the same order. This allows us to easily interchange functions whenever we want and is one of the truly beautiful parts of scikit-learn's design!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GemZ2MtDKRgY"
      },
      "source": [
        "date_features = [\"day\", \"month_str\", \"year\", \"weekday_str\", \"season\", \"holiday\", \"workingday\"]\n",
        "time_features = [\"hour\"]\n",
        "weather_features = [\"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
        "\n",
        "feature_sets = {\n",
        "    \"date\": date_features,\n",
        "    \"time\": time_features,\n",
        "    \"date + time\": date_features + time_features,\n",
        "    \"weather\": weather_features,\n",
        "    \"all\": date_features + time_features + weather_features\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4NJl3VQP1VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d170ae-0a73-4ecf-a3c3-cfb1939518f0"
      },
      "source": [
        "best = 0\n",
        "best_name = None\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "kappas = []\n",
        "accuracies = []\n",
        "\n",
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    X = bikeshare.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = bikeshare[\"high_traffic\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    \n",
        "    metric_to_optimize = accuracy\n",
        "    \n",
        "    if metric_to_optimize > best:\n",
        "        best = metric_to_optimize\n",
        "        best_name = set_name\n",
        "        \n",
        "    predictions[set_name] = y_pred\n",
        "    actual = np.array(list(y_test))\n",
        "    \n",
        "    # Bookkeeping and printing for the reader (not part of the core loop)\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f}\")\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    kappas.append(kappa)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for date:\n",
            "[[572 501]\n",
            " [314 791]]\n",
            "Accuracy: 62.6 Kappa: 0.250 Precision: 0.612 Recall: 0.716\n",
            "------------------------\n",
            "Results for time:\n",
            "[[ 717  356]\n",
            " [  78 1027]]\n",
            "Accuracy: 80.1 Kappa: 0.600 Precision: 0.743 Recall: 0.929\n",
            "------------------------\n",
            "Results for date + time:\n",
            "[[ 976   97]\n",
            " [ 103 1002]]\n",
            "Accuracy: 90.8 Kappa: 0.816 Precision: 0.912 Recall: 0.907\n",
            "------------------------\n",
            "Results for weather:\n",
            "[[780 293]\n",
            " [392 713]]\n",
            "Accuracy: 68.5 Kappa: 0.372 Precision: 0.709 Recall: 0.645\n",
            "------------------------\n",
            "Results for all:\n",
            "[[ 962  111]\n",
            " [  91 1014]]\n",
            "Accuracy: 90.7 Kappa: 0.814 Precision: 0.901 Recall: 0.918\n",
            "------------------------\n",
            "Best feature set is: date + time \n",
            "With: 90.8% accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgM-tTgxL9LX"
      },
      "source": [
        "Notice how even though our \"best\" feature set results in a model that performs better for most metrics, it is still worse than some of the other models in recall. Its up to you as the scientist to determine what metrics are most important for a good model in your context!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H90v266oP1VE"
      },
      "source": [
        "#### Results by Feature Set\n",
        "\n",
        "With the loop above, we're able to quickly see the following results:\n",
        "\n",
        "| Date | Time | Weather | Accuracy  |\n",
        "|------|------|---------|-----------|\n",
        "| X    |      |         | 61.3%     |\n",
        "|      | X    |         | 81.7%     |\n",
        "|      |      | X       | 66.9%     |\n",
        "| X    | X    |         | **90.8%** |\n",
        "| X    | X    | X       | 90.7%     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsZbeieRP1VH"
      },
      "source": [
        "### Visualizing model comparisons\n",
        "We can use plots to visually see the differing performances of our models on two metrics at the same time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wzQ-3qAdP1VJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "57abd09b-225a-435f-c5ee-4ff638bf052a"
      },
      "source": [
        "# Set up plot\n",
        "plt.xlim(0.5,1)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylim(0.5,1)\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs Precision for Different Feature Sets\")\n",
        "\n",
        "# Plot data\n",
        "names = list(feature_sets.keys())\n",
        "for i in range(len(precisions)):\n",
        "    x = precisions[i]\n",
        "    y = recalls[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+.01, y+.01, names[i], fontsize=9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aABw1p7QP1VT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "28e418ee-8710-46c2-b23a-49ed50bb020d"
      },
      "source": [
        "# Set up plot\n",
        "plt.xlim(0.5,1)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel(\"Kappa\")\n",
        "plt.title(\"Kappa vs Precision for Different Feature Sets\")\n",
        "\n",
        "# Plot data\n",
        "names = list(feature_sets.keys())\n",
        "for i in range(len(kappas)):\n",
        "    x = precisions[i]\n",
        "    y = kappas[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+.01, y+.01, names[i], fontsize=9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y6t6odHP1VZ"
      },
      "source": [
        "## Statistical significance of differences with a train/test set\n",
        "\n",
        "The following code check, for each pair of models that we have trained, whether or not the models are making significantly different predictions. Here, we are using the [Wilcoxon Signed-Rank Test](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) to get an associated test statistic and p-value for each pair of models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYdIVo1jP1Va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008872de-2434-43df-cfc9-5a1f4d9c32ac"
      },
      "source": [
        "matches = {}\n",
        "\n",
        "for feature_set in predictions.keys():\n",
        "    boolean_matches = (predictions[feature_set] == actual)\n",
        "    int_matches = [int(x) for x in boolean_matches]\n",
        "    matches[feature_set] = int_matches\n",
        "\n",
        "for set_a in matches.keys():\n",
        "    for set_b in matches.keys():\n",
        "        if set_a != set_b:\n",
        "            matches_a = matches[set_a]\n",
        "            matches_b = matches[set_b]\n",
        "            t, p = stats.wilcoxon(matches_a, matches_b)\n",
        "            print(f\"{set_a} || {set_b}: t={t:.1f}, p={p:.3f}\")\n",
        "    print('------')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date || time: t=208502.0, p=0.000\n",
            "date || date + time: t=44405.0, p=0.000\n",
            "date || weather: t=170945.0, p=0.000\n",
            "date || all: t=48530.0, p=0.000\n",
            "------\n",
            "time || date: t=208502.0, p=0.000\n",
            "time || date + time: t=23362.5, p=0.000\n",
            "time || weather: t=128527.0, p=0.000\n",
            "time || all: t=21650.0, p=0.000\n",
            "------\n",
            "date + time || date: t=44405.0, p=0.000\n",
            "date + time || time: t=23362.5, p=0.000\n",
            "date + time || weather: t=41170.0, p=0.000\n",
            "date + time || all: t=9554.5, p=0.886\n",
            "------\n",
            "weather || date: t=170945.0, p=0.000\n",
            "weather || time: t=128527.0, p=0.000\n",
            "weather || date + time: t=41170.0, p=0.000\n",
            "weather || all: t=38720.0, p=0.000\n",
            "------\n",
            "all || date: t=48530.0, p=0.000\n",
            "all || time: t=21650.0, p=0.000\n",
            "all || date + time: t=9554.5, p=0.886\n",
            "all || weather: t=38720.0, p=0.000\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xACZQuErXHTd"
      },
      "source": [
        "We can see that almost all the pairs of models are pretty different in this cases, indicating that splitting by different features results in models with significantly different predictions! The only two models that don't have significantly different predictions are the models using date/time and date/time/weather, indicating that weather only plays a small role in the model that uses all 3 feature subets!"
      ]
    }
  ]
}