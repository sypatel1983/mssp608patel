{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ui1q9c0JEZ12",
        "aST8THJPko33",
        "fTpO780wF76j",
        "dn9lW9aVKhE9",
        "keiww9t4QOaP",
        "sU_d5OEMS4yG",
        "Y0xJSqkTCGoC",
        "E9gMXLV-KJsJ",
        "u1GHIjcBKXf6",
        "t-ZNtZw0CLw-",
        "0lhQbSZQB-wm",
        "MjsScR-7-Wne",
        "Shig_bSD-iMz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nps9Yo_mwOt5"
      },
      "source": [
        "# Prerequisites\n",
        "To get the most out of this notebook you should be comfortable with the following concepts.\n",
        "- Basics of working with text data (from the Day 4 Notebook)\n",
        "- The Bag-of-Words model\n",
        "- Basic classifiers (Logistic Regression, Decision Trees, Naive Bayes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui1q9c0JEZ12"
      },
      "source": [
        "# Initial Setup\n",
        "\n",
        "The first several cells here are setting up our ever-more-complex development environment for working with a new set of tools, moving to multilingual NLP with a set of more state-of-the-art methods, and downloading two different datasets for analysis. Much of the contents is duplicated from past notebooks.\n",
        "\n",
        "**Run the first cell once and restart the runtime before running the rest of the notebook!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbtXaxl9XvIJ",
        "outputId": "c3531a54-945b-4868-f07c-3b9acd0eb2ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# You are going to need to run this cell, restart the runtime after running this command,\n",
        "# then start over before you can run the code in this notebook.\n",
        "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 106 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==2.2.0) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.9.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.21.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->en-core-web-md==2.2.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->en-core-web-md==2.2.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->en-core-web-md==2.2.0) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmMwQQapvhDc"
      },
      "source": [
        "**Import our Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0L1x2YCUNT2",
        "outputId": "8f6ccc39-0495-431e-b11b-1e1b2e9dc205",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make our Imports\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from matplotlib import dates\n",
        "from datetime import datetime\n",
        "import re\n",
        "import calendar\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB, GaussianNB, MultinomialNB \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.zh import Chinese\n",
        "\n",
        "import jieba\n",
        "\n",
        "import sklearn\n",
        "estimators = sklearn.utils.all_estimators(type_filter=None)\n",
        "for name, class_ in estimators:\n",
        "    if hasattr(class_, 'predict_proba'):\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoostClassifier\n",
            "BaggingClassifier\n",
            "BayesianGaussianMixture\n",
            "BernoulliNB\n",
            "CalibratedClassifierCV\n",
            "CategoricalNB\n",
            "ClassifierChain\n",
            "ComplementNB\n",
            "DecisionTreeClassifier\n",
            "DummyClassifier\n",
            "ExtraTreeClassifier\n",
            "ExtraTreesClassifier\n",
            "GaussianMixture\n",
            "GaussianNB\n",
            "GaussianProcessClassifier\n",
            "GradientBoostingClassifier\n",
            "GridSearchCV\n",
            "HalvingGridSearchCV\n",
            "HalvingRandomSearchCV\n",
            "HistGradientBoostingClassifier\n",
            "KNeighborsClassifier\n",
            "LabelPropagation\n",
            "LabelSpreading\n",
            "LinearDiscriminantAnalysis\n",
            "LogisticRegression\n",
            "LogisticRegressionCV\n",
            "MLPClassifier\n",
            "MultiOutputClassifier\n",
            "MultinomialNB\n",
            "NuSVC\n",
            "OneVsRestClassifier\n",
            "Pipeline\n",
            "QuadraticDiscriminantAnalysis\n",
            "RFE\n",
            "RFECV\n",
            "RadiusNeighborsClassifier\n",
            "RandomForestClassifier\n",
            "RandomizedSearchCV\n",
            "SGDClassifier\n",
            "SVC\n",
            "SelfTrainingClassifier\n",
            "StackingClassifier\n",
            "VotingClassifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdyssnqrvdB6"
      },
      "source": [
        "**Download our Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3Vc8A81vMk",
        "outputId": "b67e2170-b0aa-40df-d6b0-20396003cfc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1FJ5Jp5TgpMV1cP0CX0Z1hszSNsiEWDhp' -O alexa_train.csv\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1VYfti_C9WuF9moYKf73yV6IQwK-zZbdL' -O weibo.csv\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1amPW_B1Lr5cnmArs31d2RKTMuKXRSaoE' -O stopwords-zh.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-18 03:30:28--  https://drive.google.com/uc?export=download&id=1FJ5Jp5TgpMV1cP0CX0Z1hszSNsiEWDhp\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.31.101, 74.125.31.138, 74.125.31.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.31.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/h9c61u6kjn32obb2d9uhulcqub2ndgou/1650252600000/09640029349513786515/*/1FJ5Jp5TgpMV1cP0CX0Z1hszSNsiEWDhp?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-18 03:30:30--  https://doc-0s-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/h9c61u6kjn32obb2d9uhulcqub2ndgou/1650252600000/09640029349513786515/*/1FJ5Jp5TgpMV1cP0CX0Z1hszSNsiEWDhp?e=download\n",
            "Resolving doc-0s-b0-docs.googleusercontent.com (doc-0s-b0-docs.googleusercontent.com)... 172.217.193.132, 2607:f8b0:400c:c03::84\n",
            "Connecting to doc-0s-b0-docs.googleusercontent.com (doc-0s-b0-docs.googleusercontent.com)|172.217.193.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62290587 (59M) [text/csv]\n",
            "Saving to: ‘alexa_train.csv’\n",
            "\n",
            "alexa_train.csv     100%[===================>]  59.40M   285MB/s    in 0.2s    \n",
            "\n",
            "2022-04-18 03:30:30 (285 MB/s) - ‘alexa_train.csv’ saved [62290587/62290587]\n",
            "\n",
            "--2022-04-18 03:30:30--  https://drive.google.com/uc?export=download&id=1VYfti_C9WuF9moYKf73yV6IQwK-zZbdL\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.31.101, 74.125.31.113, 74.125.31.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.31.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qvfbdk8aondc7s9orhlb5vrqdu0nfn4h/1650252600000/09640029349513786515/*/1VYfti_C9WuF9moYKf73yV6IQwK-zZbdL?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-18 03:30:31--  https://doc-0s-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qvfbdk8aondc7s9orhlb5vrqdu0nfn4h/1650252600000/09640029349513786515/*/1VYfti_C9WuF9moYKf73yV6IQwK-zZbdL?e=download\n",
            "Resolving doc-0s-b0-docs.googleusercontent.com (doc-0s-b0-docs.googleusercontent.com)... 172.217.193.132, 2607:f8b0:400c:c04::84\n",
            "Connecting to doc-0s-b0-docs.googleusercontent.com (doc-0s-b0-docs.googleusercontent.com)|172.217.193.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84645701 (81M) [text/csv]\n",
            "Saving to: ‘weibo.csv’\n",
            "\n",
            "weibo.csv           100%[===================>]  80.72M   188MB/s    in 0.4s    \n",
            "\n",
            "2022-04-18 03:30:32 (188 MB/s) - ‘weibo.csv’ saved [84645701/84645701]\n",
            "\n",
            "--2022-04-18 03:30:32--  https://drive.google.com/uc?export=download&id=1amPW_B1Lr5cnmArs31d2RKTMuKXRSaoE\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.31.101, 74.125.31.102, 74.125.31.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.31.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9r8etua4tkfmr591368bp21ofaqod84f/1650252600000/09640029349513786515/*/1amPW_B1Lr5cnmArs31d2RKTMuKXRSaoE?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-18 03:30:32--  https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9r8etua4tkfmr591368bp21ofaqod84f/1650252600000/09640029349513786515/*/1amPW_B1Lr5cnmArs31d2RKTMuKXRSaoE?e=download\n",
            "Resolving doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)... 172.217.193.132, 2607:f8b0:400c:c03::84\n",
            "Connecting to doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)|172.217.193.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4770 (4.7K) [text/plain]\n",
            "Saving to: ‘stopwords-zh.txt’\n",
            "\n",
            "stopwords-zh.txt    100%[===================>]   4.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-18 03:30:32 (45.0 MB/s) - ‘stopwords-zh.txt’ saved [4770/4770]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIFpPlM3vlzk"
      },
      "source": [
        "**Bring in functions from other Notebooks**\n",
        "\n",
        "This allows us to easily compare different classifiers we train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz3SIWguka4X"
      },
      "source": [
        "\"\"\"\n",
        "Options for noisy: \"loud\", \"quiet\", and other. Any other value prints nothing (silent).\n",
        "\"\"\"\n",
        "\n",
        "# Start by defining a function to evaluate a classifier's predictions\n",
        "def evaluate(y_pred, y_actual, metrics, model_name = 'model'):\n",
        "    # Compute Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "\n",
        "    # Compute and store each metric\n",
        "    model_metrics = {}\n",
        "    for (metric_name, metric) in metrics.items():\n",
        "        result = metric(y_actual, y_pred)\n",
        "        model_metrics[metric_name] = result\n",
        "\n",
        "    return conf_matrix, model_metrics\n",
        "\n",
        "# Then define a function that trains a classifier and evaluates it on one fold\n",
        "def evaluate_one_fold(classifier_name, classifier, X_train, y_train, X_test, y_test, metrics, fold_num, noisy = 'loud', labels=[]):\n",
        "\n",
        "    # Train and Evaluate Model\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    conf_matrix, model_metrics = evaluate(y_pred, y_test, metrics, model_name = classifier_name)\n",
        "\n",
        "    # Display Results appropriately when noisy is set to 'loud' or 'quiet'\n",
        "    if noisy == 'quiet' and fold_num == 0:\n",
        "        print(f\"{classifier_name}: Fold {fold_num}\", end = '')\n",
        "    elif noisy == 'quiet':\n",
        "        print(f'...{fold_num}', end ='')\n",
        "    elif noisy == 'loud':\n",
        "        print(f\"{classifier_name}: Fold {fold_num} Results\")\n",
        "        ConfusionMatrixDisplay(conf_matrix, labels).plot(values_format='.4g')\n",
        "        plt.show()\n",
        "        print(model_metrics)\n",
        "        print(\"------------------------\")\n",
        "\n",
        "    return model_metrics\n",
        "\n",
        "# Then define a function to evaluate over all folds\n",
        "def evaluate_all_folds(classifier_name, classifier, X, y, kf, metrics, noisy = 'loud', labels=[]):\n",
        "\n",
        "    # Initialize tracking variables\n",
        "    all_fold_metrics = {metric_name: [] for metric_name in metrics}\n",
        "\n",
        "    # Iterate over each fold\n",
        "    for fold_num, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "        # Get the data subset for the current fold\n",
        "        X_train = X.iloc[train_index]\n",
        "        X_test = X.iloc[test_index]\n",
        "        y_train = y.iloc[train_index]\n",
        "        y_test = y.iloc[test_index]\n",
        "\n",
        "        # Train and Evaluate the Model\n",
        "        model_metrics =  evaluate_one_fold(classifier_name, classifier, X_train, y_train, X_test, y_test, metrics, fold_num, noisy, labels=labels)\n",
        "\n",
        "        # Update our tracking variables\n",
        "        [all_fold_metrics[metric_name].append(metric_val) for metric_name, metric_val in model_metrics.items()]\n",
        "\n",
        "    return all_fold_metrics\n",
        "\n",
        "#Dont worry about these two lines\n",
        "\n",
        "# Then define a function to compare different classifiers\n",
        "def compare_classifiers(classifiers, metrics, metric_to_optimize, df, feature_set,\n",
        "                        target, folds = 10, shuffle = True, noisy='loud', labels=[]):\n",
        "    # Initialize tracking variables\n",
        "    best = 0\n",
        "    best_name = None\n",
        "    classifier_comparison = {}\n",
        "\n",
        "    # Set up dataset and cross validation\n",
        "    X = df.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "    y = df[target]\n",
        "    kf = StratifiedKFold(n_splits=folds, shuffle=shuffle, random_state=123)\n",
        "\n",
        "\n",
        "    # For each classifier\n",
        "    for classifier_name, classifier in classifiers.items():\n",
        "        # Evaluate on all metrics for all folds\n",
        "        all_fold_metrics = evaluate_all_folds(classifier_name, classifier, X, y, kf, metrics, noisy = noisy, labels=labels)\n",
        "\n",
        "        # Compute average performance on metric to optimize over\n",
        "        optimization_metric_avg = np.mean(all_fold_metrics[metric_to_optimize])\n",
        "\n",
        "        # Update Tracking Variables\n",
        "        if optimization_metric_avg > best:\n",
        "            best = optimization_metric_avg\n",
        "            best_name = classifier_name\n",
        "        classifier_comparison[classifier_name] = all_fold_metrics\n",
        "        if noisy == 'quiet': \n",
        "            print()\n",
        "            print(f\"Average {metric_to_optimize}: {optimization_metric_avg:.3f}\")\n",
        "            print('-------------')\n",
        "    # Return our results\n",
        "    return best, best_name, classifier_comparison\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzKJU7zxv00A"
      },
      "source": [
        "**Prepare the Data**\n",
        "- Load data with pandas\n",
        "- Reduce the dataset size, and remove incomplete entries\n",
        "- Create our simpler output labels we want to classify\n",
        "- Preview our modified data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7qVL6AxBCK3",
        "outputId": "60331b10-5c11-4072-ef3d-7ddf0b1253d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "filename = \"alexa_train.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "df = df.dropna()\n",
        "df = df.loc[df.conv_id % 10 == 0].copy()\n",
        "df = df.reset_index()\n",
        "\n",
        "# This creates a binary rating task instead of a more complex 5-label scale.\n",
        "def simplify_rating(label):\n",
        "  if label == \"Excellent\" or label == \"Good\":\n",
        "    return \"Positive\"\n",
        "  else:\n",
        "    return \"Neutral/Negative\"\n",
        "\n",
        "# This will produce a 4-label multiclass task, shrinking down from the eight labels \n",
        "# originally provided to us in the dataset.\n",
        "def simplify_sentiment(label):\n",
        "  if label in [\"Sad\", \"Disgusted\", \"Fearful\", \"Angry\"]:\n",
        "      return \"Negative\"\n",
        "  elif label in [\"Happy\", \"Surprised\"]:\n",
        "      return \"Positive\"\n",
        "  else:\n",
        "      return label\n",
        "\n",
        "df[\"rating_simple\"] = df[\"turn_rating\"].apply(simplify_rating)\n",
        "df[\"sentiment_simple\"] = df[\"sentiment\"].apply(simplify_sentiment)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        index  conv_id                                                url  \\\n",
              "0         191   100010  https://www.washingtonpost.com/lifestyle/style...   \n",
              "1         192   100010  https://www.washingtonpost.com/lifestyle/style...   \n",
              "2         193   100010  https://www.washingtonpost.com/lifestyle/style...   \n",
              "3         194   100010  https://www.washingtonpost.com/lifestyle/style...   \n",
              "4         195   100010  https://www.washingtonpost.com/lifestyle/style...   \n",
              "...       ...      ...                                                ...   \n",
              "18609  188192   108620  http://www.washingtonpost.com/education/2018/0...   \n",
              "18610  188193   108620  http://www.washingtonpost.com/education/2018/0...   \n",
              "18611  188194   108620  http://www.washingtonpost.com/education/2018/0...   \n",
              "18612  188195   108620  http://www.washingtonpost.com/education/2018/0...   \n",
              "18613  188196   108620  http://www.washingtonpost.com/education/2018/0...   \n",
              "\n",
              "      conf                                            message    agent  \\\n",
              "0        B       Naming a cloned cat \"copy cat\", that's cute.  agent_1   \n",
              "1        B  You must have ESP. I was going to tell you teh...  agent_2   \n",
              "2        B                      Really? That's awful to hear!  agent_1   \n",
              "3        B  Of Roosevelt's 20 pets two were a bear and hyena!  agent_2   \n",
              "4        B  Whoa, cool! I know he seemed to be quite the a...  agent_1   \n",
              "...    ...                                                ...      ...   \n",
              "18609    B  I just heard about it recently.  I did see him...  agent_2   \n",
              "18610    B  Did someone walk a mile in someone's 5,000 yea...  agent_1   \n",
              "18611    B  Yes, that's right.  Years ago, shoes were more...  agent_2   \n",
              "18612    B  Fashion for sure and the prices for some are c...  agent_1   \n",
              "18613    B  It sure is.  When our kids moved out, I put in...  agent_2   \n",
              "\n",
              "       sentiment                  source turn_rating agent_1_rating  \\\n",
              "0        Neutral                 ['FS3']   Excellent      Excellent   \n",
              "1            Sad                 ['FS3']        Good      Excellent   \n",
              "2      Surprised                 ['FS2']        Poor      Excellent   \n",
              "3      Surprised                 ['FS3']    Passable      Excellent   \n",
              "4      Surprised  ['Personal Knowledge']        Poor      Excellent   \n",
              "...          ...                     ...         ...            ...   \n",
              "18609    Neutral                 ['FS1']   Excellent      Excellent   \n",
              "18610  Surprised                 ['FS1']   Excellent      Excellent   \n",
              "18611    Neutral                 ['FS1']   Excellent      Excellent   \n",
              "18612  Surprised                 ['FS1']   Excellent      Excellent   \n",
              "18613    Neutral  ['Personal Knowledge']   Excellent      Excellent   \n",
              "\n",
              "      agent_2_rating     rating_simple sentiment_simple  \n",
              "0               Good          Positive          Neutral  \n",
              "1               Good          Positive         Negative  \n",
              "2               Good  Neutral/Negative         Positive  \n",
              "3               Good  Neutral/Negative         Positive  \n",
              "4               Good  Neutral/Negative         Positive  \n",
              "...              ...               ...              ...  \n",
              "18609      Excellent          Positive          Neutral  \n",
              "18610      Excellent          Positive         Positive  \n",
              "18611      Excellent          Positive          Neutral  \n",
              "18612      Excellent          Positive         Positive  \n",
              "18613      Excellent          Positive          Neutral  \n",
              "\n",
              "[18614 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7b41f35-1131-44d0-804f-758c7aec47a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>conv_id</th>\n",
              "      <th>url</th>\n",
              "      <th>conf</th>\n",
              "      <th>message</th>\n",
              "      <th>agent</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "      <th>turn_rating</th>\n",
              "      <th>agent_1_rating</th>\n",
              "      <th>agent_2_rating</th>\n",
              "      <th>rating_simple</th>\n",
              "      <th>sentiment_simple</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>191</td>\n",
              "      <td>100010</td>\n",
              "      <td>https://www.washingtonpost.com/lifestyle/style...</td>\n",
              "      <td>B</td>\n",
              "      <td>Naming a cloned cat \"copy cat\", that's cute.</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>192</td>\n",
              "      <td>100010</td>\n",
              "      <td>https://www.washingtonpost.com/lifestyle/style...</td>\n",
              "      <td>B</td>\n",
              "      <td>You must have ESP. I was going to tell you teh...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Sad</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Good</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>193</td>\n",
              "      <td>100010</td>\n",
              "      <td>https://www.washingtonpost.com/lifestyle/style...</td>\n",
              "      <td>B</td>\n",
              "      <td>Really? That's awful to hear!</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Surprised</td>\n",
              "      <td>['FS2']</td>\n",
              "      <td>Poor</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>194</td>\n",
              "      <td>100010</td>\n",
              "      <td>https://www.washingtonpost.com/lifestyle/style...</td>\n",
              "      <td>B</td>\n",
              "      <td>Of Roosevelt's 20 pets two were a bear and hyena!</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Surprised</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Passable</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>195</td>\n",
              "      <td>100010</td>\n",
              "      <td>https://www.washingtonpost.com/lifestyle/style...</td>\n",
              "      <td>B</td>\n",
              "      <td>Whoa, cool! I know he seemed to be quite the a...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Surprised</td>\n",
              "      <td>['Personal Knowledge']</td>\n",
              "      <td>Poor</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18609</th>\n",
              "      <td>188192</td>\n",
              "      <td>108620</td>\n",
              "      <td>http://www.washingtonpost.com/education/2018/0...</td>\n",
              "      <td>B</td>\n",
              "      <td>I just heard about it recently.  I did see him...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS1']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18610</th>\n",
              "      <td>188193</td>\n",
              "      <td>108620</td>\n",
              "      <td>http://www.washingtonpost.com/education/2018/0...</td>\n",
              "      <td>B</td>\n",
              "      <td>Did someone walk a mile in someone's 5,000 yea...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Surprised</td>\n",
              "      <td>['FS1']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18611</th>\n",
              "      <td>188194</td>\n",
              "      <td>108620</td>\n",
              "      <td>http://www.washingtonpost.com/education/2018/0...</td>\n",
              "      <td>B</td>\n",
              "      <td>Yes, that's right.  Years ago, shoes were more...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS1']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18612</th>\n",
              "      <td>188195</td>\n",
              "      <td>108620</td>\n",
              "      <td>http://www.washingtonpost.com/education/2018/0...</td>\n",
              "      <td>B</td>\n",
              "      <td>Fashion for sure and the prices for some are c...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Surprised</td>\n",
              "      <td>['FS1']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18613</th>\n",
              "      <td>188196</td>\n",
              "      <td>108620</td>\n",
              "      <td>http://www.washingtonpost.com/education/2018/0...</td>\n",
              "      <td>B</td>\n",
              "      <td>It sure is.  When our kids moved out, I put in...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['Personal Knowledge']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18614 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7b41f35-1131-44d0-804f-758c7aec47a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7b41f35-1131-44d0-804f-758c7aec47a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7b41f35-1131-44d0-804f-758c7aec47a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-YBgDrpCCYU"
      },
      "source": [
        "# More Classical NLP!\n",
        "\n",
        "We're going to introduce three final ways of thinking about how to represent text:\n",
        "   - Part-of-Speech Tagging\n",
        "   - Dependency Parsing\n",
        "   - Embedding Vectors\n",
        "\n",
        "For each of them, we'll show how you can represent individual sentences in many different ways, each of which captures a different nuance about language.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aST8THJPko33"
      },
      "source": [
        "## Establishing a Baseline\n",
        "\n",
        "First we'll go back and re-run our unigram baseline to remember our performance on this data when all we had was surface features. This is a duplication of our results from yesterday. As a reminder, this was using unigrams for the BOW model in combination with a Naive Bayes classifier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZCDr_3Njukk",
        "outputId": "88af0aeb-0c1e-459a-844a-5c07e5806cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "def ngrams(column, vocab_size = 1000, min_n=1, max_n=1):\n",
        "  vectorizer = CountVectorizer(max_features=vocab_size, ngram_range=(1,max_n))\n",
        "  X = vectorizer.fit_transform(column)\n",
        "\n",
        "  bow_df = pd.DataFrame(X.toarray())\n",
        "  column_names = [str(i) for i in range(vocab_size)]\n",
        "  for k, v in vectorizer.vocabulary_.items():\n",
        "    column_names[v] = k\n",
        "  bow_df.columns = column_names\n",
        "  return column_names, bow_df\n",
        "\n",
        "unigram_names, unigram_df = ngrams(df[\"message\"], vocab_size = 1000, min_n=1, max_n=1)\n",
        "unigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "unigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "\n",
        "unigram_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       000  10  100  11  12  13  15  20  2000  2005  ...  york  you  young  \\\n",
              "0        0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "1        0   0    0   0   0   0   0   0     0     0  ...     0    2      0   \n",
              "2        0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "3        0   0    0   0   0   0   0   1     0     0  ...     0    0      0   \n",
              "4        0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "...    ...  ..  ...  ..  ..  ..  ..  ..   ...   ...  ...   ...  ...    ...   \n",
              "18609    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "18610    1   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "18611    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "18612    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "18613    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "\n",
              "       younger  your  yourself  youtube  zimbabwe            rating  sentiment  \n",
              "0            0     0         0        0         0          Positive    Neutral  \n",
              "1            0     0         0        0         0          Positive   Negative  \n",
              "2            0     0         0        0         0  Neutral/Negative   Positive  \n",
              "3            0     0         0        0         0  Neutral/Negative   Positive  \n",
              "4            0     0         0        0         0  Neutral/Negative   Positive  \n",
              "...        ...   ...       ...      ...       ...               ...        ...  \n",
              "18609        0     0         0        0         0          Positive    Neutral  \n",
              "18610        0     0         0        0         0          Positive   Positive  \n",
              "18611        0     0         0        0         0          Positive    Neutral  \n",
              "18612        0     0         0        0         0          Positive   Positive  \n",
              "18613        0     0         0        0         0          Positive    Neutral  \n",
              "\n",
              "[18614 rows x 1002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d25a558a-74b0-4ed2-8016-c1163bb44aff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>15</th>\n",
              "      <th>20</th>\n",
              "      <th>2000</th>\n",
              "      <th>2005</th>\n",
              "      <th>...</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zimbabwe</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18609</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18610</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18611</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18612</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18613</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18614 rows × 1002 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d25a558a-74b0-4ed2-8016-c1163bb44aff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d25a558a-74b0-4ed2-8016-c1163bb44aff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d25a558a-74b0-4ed2-8016-c1163bb44aff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYr8QF1LnLi6",
        "outputId": "8495c25d-57f9-467d-f60e-8bf28d63a83a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB(),\n",
        "    \"Linear SVM\": LinearSVC(),\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "feature_set = unigram_names\n",
        "\n",
        "sorted_sentiments = [\"Curious to dive deeper\", \"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVM: Fold 0"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...1"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...2"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...3"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...4"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...6"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...7"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...8...9\n",
            "Average Kappa: 0.218\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.238.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTpO780wF76j"
      },
      "source": [
        "### Hyperparameter: N-Gram Length\n",
        "Let's also tune our n-gram length like we did in the previous notebook!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhej5jkKGA-x",
        "outputId": "3571a200-9e8b-4ce7-ad88-fa97cebc1b11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# DataFrame of Bigrams\n",
        "bigram_names, bigram_df = ngrams(df[\"message\"], vocab_size = 5000, max_n=2)\n",
        "bigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "bigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "\n",
        "\n",
        "# DataFrame of Trigrams\n",
        "trigram_names, trigram_df = ngrams(df[\"message\"], vocab_size = 5000, max_n=3)\n",
        "trigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "trigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "print(trigram_df.iloc[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   000  000 per  000 per episode  000 year  000 years  10  10 episodes  \\\n",
            "0    0        0                0         0          0   0            0   \n",
            "1    0        0                0         0          0   0            0   \n",
            "2    0        0                0         0          0   0            0   \n",
            "3    0        0                0         0          0   0            0   \n",
            "4    0        0                0         0          0   0            0   \n",
            "\n",
            "   10 people  10 years  100  ...  youtube  youtube is  yup  zealand  zimbabwe  \\\n",
            "0          0         0    0  ...        0           0    0        0         0   \n",
            "1          0         0    0  ...        0           0    0        0         0   \n",
            "2          0         0    0  ...        0           0    0        0         0   \n",
            "3          0         0    0  ...        0           0    0        0         0   \n",
            "4          0         0    0  ...        0           0    0        0         0   \n",
            "\n",
            "   zimbabwe was  zimbabwe was called  zuckerberg            rating  sentiment  \n",
            "0             0                    0           0          Positive    Neutral  \n",
            "1             0                    0           0          Positive   Negative  \n",
            "2             0                    0           0  Neutral/Negative   Positive  \n",
            "3             0                    0           0  Neutral/Negative   Positive  \n",
            "4             0                    0           0  Neutral/Negative   Positive  \n",
            "\n",
            "[5 rows x 5002 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAGLme4YJdj3",
        "outputId": "e3d1ebd5-b11f-4502-c34b-7b22631c8507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### Setup classifiers and metrics to be used on all n-grams\n",
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "### Compare classifiers on unigrams ###\n",
        "\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, unigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Unigram classifier K={best:.3f}.\")    \n",
        "\n",
        "### Compare classifiers on bigrams ###\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, bigram_df, bigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Bigram classifier K={best:.3f}.\")    \n",
        "\n",
        "### Compare classifiers on trigrams ###\n",
        "\n",
        "feature_set = list(trigram_df.columns[:-2])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, trigram_df, trigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Trigram classifier K={best:.3f}.\")    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n",
            "Unigram classifier K=0.238.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.254\n",
            "-------------\n",
            "Bigram classifier K=0.254.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.253\n",
            "-------------\n",
            "Trigram classifier K=0.253.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn9lW9aVKhE9"
      },
      "source": [
        "### Hyperparameter: Stopwords, Case\n",
        "\n",
        "On top of picking n for our n-grams, there are other ways we can preprocess the text for our BOW model. \n",
        "\n",
        "For example, we can make everything lowercase. This will lose case-sensitive features but will also help simplify our overall vocabulary of possible words.\n",
        "\n",
        "There are also some words that are very common in the language. For example, \"the\" shows up in a large amount of sentences. Therefore, these words don't have much predictive power since they are in basically every text and we can just ignore them/remove them from our representation of the text. We call these extra common words **stopwords**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1HBsCpKlFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451fed9c-0ba2-4f73-a9c0-37eaa4bccd85"
      },
      "source": [
        "# Extract features for unigrams with no stopwords included.\n",
        "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1,1), stop_words='english')\n",
        "X = vectorizer.fit_transform(df[\"message\"])\n",
        "\n",
        "no_stopwords_df = pd.DataFrame(X.toarray())\n",
        "no_stopwords_columns = [str(i) for i in range(1000)]\n",
        "for k, v in vectorizer.vocabulary_.items():\n",
        "  no_stopwords_columns[v] = k\n",
        "no_stopwords_df.columns = no_stopwords_columns\n",
        "no_stopwords_df[\"rating\"] = df[\"rating_simple\"]\n",
        "no_stopwords_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "no_stopwords_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   000  10  100  11  12  13  15  16  18  20  ...  yellow  yep  yes  york  \\\n",
              "0    0   0    0   0   0   0   0   0   0   0  ...       0    0    0     0   \n",
              "1    0   0    0   0   0   0   0   0   0   0  ...       0    0    0     0   \n",
              "2    0   0    0   0   0   0   0   0   0   0  ...       0    0    0     0   \n",
              "3    0   0    0   0   0   0   0   0   0   1  ...       0    0    0     0   \n",
              "4    0   0    0   0   0   0   0   0   0   0  ...       0    0    0     0   \n",
              "\n",
              "   young  younger  youtube  zimbabwe            rating  sentiment  \n",
              "0      0        0        0         0          Positive    Neutral  \n",
              "1      0        0        0         0          Positive   Negative  \n",
              "2      0        0        0         0  Neutral/Negative   Positive  \n",
              "3      0        0        0         0  Neutral/Negative   Positive  \n",
              "4      0        0        0         0  Neutral/Negative   Positive  \n",
              "\n",
              "[5 rows x 1002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-100dd5d7-de5d-4633-8909-0d017fa2830b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>20</th>\n",
              "      <th>...</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zimbabwe</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1002 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-100dd5d7-de5d-4633-8909-0d017fa2830b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-100dd5d7-de5d-4633-8909-0d017fa2830b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-100dd5d7-de5d-4633-8909-0d017fa2830b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb4b7IgvLiWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a042f4a-3850-4346-e830-dc98bb5fa4ea"
      },
      "source": [
        "# Extract features for unigrams with case-sensitive features\n",
        "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1,1), lowercase=False)\n",
        "X = vectorizer.fit_transform(df[\"message\"])\n",
        "\n",
        "case_sensitive_df = pd.DataFrame(X.toarray())\n",
        "case_sensitive_columns = [str(i) for i in range(1000)]\n",
        "for k, v in vectorizer.vocabulary_.items():\n",
        "  case_sensitive_columns[v] = k\n",
        "case_sensitive_df.columns = case_sensitive_columns\n",
        "case_sensitive_df[\"rating\"] = df[\"rating_simple\"]\n",
        "case_sensitive_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "case_sensitive_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   000  10  100  11  12  13  15  20  212  30  ...  year  years  yes  yet  you  \\\n",
              "0    0   0    0   0   0   0   0   0    0   0  ...     0      0    0    0    0   \n",
              "1    0   0    0   0   0   0   0   0    0   0  ...     0      0    0    0    1   \n",
              "2    0   0    0   0   0   0   0   0    0   0  ...     0      0    0    0    0   \n",
              "3    0   0    0   0   0   0   0   1    0   0  ...     0      0    0    0    0   \n",
              "4    0   0    0   0   0   0   0   0    0   0  ...     0      0    0    0    0   \n",
              "\n",
              "   young  your  youtube            rating  sentiment  \n",
              "0      0     0        0          Positive    Neutral  \n",
              "1      0     0        0          Positive   Negative  \n",
              "2      0     0        0  Neutral/Negative   Positive  \n",
              "3      0     0        0  Neutral/Negative   Positive  \n",
              "4      0     0        0  Neutral/Negative   Positive  \n",
              "\n",
              "[5 rows x 1002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0dbe7707-42b0-4fed-b3d1-6ba9b75e19fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>15</th>\n",
              "      <th>20</th>\n",
              "      <th>212</th>\n",
              "      <th>30</th>\n",
              "      <th>...</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>youtube</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1002 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dbe7707-42b0-4fed-b3d1-6ba9b75e19fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0dbe7707-42b0-4fed-b3d1-6ba9b75e19fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0dbe7707-42b0-4fed-b3d1-6ba9b75e19fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "unigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "unigram_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jh2i3YCC9DI",
        "outputId": "e72deae6-c05b-4cda-ce9e-b5c343c6be38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   000  10  100  11  12  13  15  20  2000  2005  ...  york  you  young  \\\n",
              "0    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "1    0   0    0   0   0   0   0   0     0     0  ...     0    2      0   \n",
              "2    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "3    0   0    0   0   0   0   0   1     0     0  ...     0    0      0   \n",
              "4    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
              "\n",
              "   younger  your  yourself  youtube  zimbabwe            rating  sentiment  \n",
              "0        0     0         0        0         0          Positive    Neutral  \n",
              "1        0     0         0        0         0          Positive   Negative  \n",
              "2        0     0         0        0         0  Neutral/Negative   Positive  \n",
              "3        0     0         0        0         0  Neutral/Negative   Positive  \n",
              "4        0     0         0        0         0  Neutral/Negative   Positive  \n",
              "\n",
              "[5 rows x 1002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-020c18bf-f68b-4f48-bf6d-e9704ac171cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>15</th>\n",
              "      <th>20</th>\n",
              "      <th>2000</th>\n",
              "      <th>2005</th>\n",
              "      <th>...</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zimbabwe</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral/Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1002 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-020c18bf-f68b-4f48-bf6d-e9704ac171cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-020c18bf-f68b-4f48-bf6d-e9704ac171cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-020c18bf-f68b-4f48-bf6d-e9704ac171cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGwfDYNbLJB0",
        "outputId": "b0232399-8a85-4295-8ece-bd91887688e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Re-run our classifier with stopwords included, as a baseline (i.e., KEEP \"THE\").\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, unigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier with stopwords K={best:.3f}.\")    \n",
        "\n",
        "# Then run our classifier on the feature space with stopwords removed (i.e., DROP \"THE\").\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, no_stopwords_df, no_stopwords_columns, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier without stopwords K={best:.3f}.\")   \n",
        "\n",
        "# Finally run our classifier on the feature space with case-sensitive unigrams (i.e., KEEP UPPER CASE WORDS AS UPPSER CASE).\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, case_sensitive_df, case_sensitive_columns, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier with case-sensitive unigrams K={best:.3f}.\")   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n",
            "Classifier with stopwords K=0.238.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.195\n",
            "-------------\n",
            "Classifier without stopwords K=0.195.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.251\n",
            "-------------\n",
            "Classifier with case-sensitive unigrams K=0.251.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yr7b3agL88w",
        "outputId": "302b2b00-77e1-4711-d038-7ad870047f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Since we did slightly better with case-sensitive unigrams, it's interesting to find out why.\n",
        "\n",
        "unique_features = []\n",
        "for feature in case_sensitive_columns:\n",
        "  if feature not in unigram_names:\n",
        "    unique_features.append(feature)\n",
        "  \n",
        "print(len(unique_features))\n",
        "for feature in unique_features:\n",
        "  print(feature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167\n",
            "Africa\n",
            "Agreed\n",
            "All\n",
            "Also\n",
            "Although\n",
            "Amazon\n",
            "America\n",
            "American\n",
            "And\n",
            "Another\n",
            "Anyway\n",
            "Apparently\n",
            "Are\n",
            "As\n",
            "At\n",
            "Bart\n",
            "Bill\n",
            "Black\n",
            "Brady\n",
            "But\n",
            "Can\n",
            "Canada\n",
            "Canadian\n",
            "Christmas\n",
            "Cool\n",
            "Crazy\n",
            "DC\n",
            "DO\n",
            "Did\n",
            "Disney\n",
            "Do\n",
            "Earth\n",
            "Eminem\n",
            "Even\n",
            "Everest\n",
            "Exactly\n",
            "Facebook\n",
            "Floyd\n",
            "For\n",
            "Fox\n",
            "France\n",
            "George\n",
            "Good\n",
            "Google\n",
            "Great\n",
            "Ha\n",
            "Haha\n",
            "Have\n",
            "He\n",
            "Hello\n",
            "Hey\n",
            "Hi\n",
            "His\n",
            "House\n",
            "How\n",
            "Iceland\n",
            "If\n",
            "Im\n",
            "In\n",
            "Indonesia\n",
            "Interesting\n",
            "Internet\n",
            "Is\n",
            "Isn\n",
            "It\n",
            "Its\n",
            "Iverson\n",
            "JFK\n",
            "Jackson\n",
            "James\n",
            "Japan\n",
            "Jefferson\n",
            "Jim\n",
            "John\n",
            "Jordan\n",
            "Jupiter\n",
            "Just\n",
            "King\n",
            "Korea\n",
            "LOL\n",
            "Lebron\n",
            "Like\n",
            "Linkin\n",
            "Lol\n",
            "Martin\n",
            "Maybe\n",
            "Me\n",
            "Michael\n",
            "Murray\n",
            "My\n",
            "NBA\n",
            "NFL\n",
            "Netflix\n",
            "Nevada\n",
            "New\n",
            "News\n",
            "Nice\n",
            "Nike\n",
            "No\n",
            "North\n",
            "Not\n",
            "Now\n",
            "Oh\n",
            "On\n",
            "One\n",
            "Or\n",
            "Park\n",
            "People\n",
            "Pink\n",
            "Pokemon\n",
            "President\n",
            "Probably\n",
            "QB\n",
            "Really\n",
            "Right\n",
            "Roosevelt\n",
            "Same\n",
            "Seems\n",
            "She\n",
            "Simpsons\n",
            "So\n",
            "Some\n",
            "Sometimes\n",
            "Sounds\n",
            "South\n",
            "Speaking\n",
            "Star\n",
            "Stephen\n",
            "TV\n",
            "Thanks\n",
            "That\n",
            "Thats\n",
            "The\n",
            "Then\n",
            "There\n",
            "They\n",
            "This\n",
            "Those\n",
            "Tim\n",
            "Tom\n",
            "True\n",
            "Trump\n",
            "Tupac\n",
            "UK\n",
            "US\n",
            "Very\n",
            "Wars\n",
            "Washington\n",
            "We\n",
            "Well\n",
            "What\n",
            "When\n",
            "White\n",
            "Who\n",
            "Why\n",
            "Wonder\n",
            "World\n",
            "Would\n",
            "Wow\n",
            "Yea\n",
            "Yeah\n",
            "Yep\n",
            "Yes\n",
            "York\n",
            "You\n",
            "YouTube\n",
            "Youtube\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keiww9t4QOaP"
      },
      "source": [
        "### Hyperparameter: Vocabulary Size\n",
        "We can also tune how many words we store in our representations of the texts. Having a large vocabulary size means that we get more information about each document, but it also means that our dataframes will take up more room in memory and it will take more time to train our models!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxc45klUQNlI",
        "outputId": "bd18c1ec-e988-4846-e13d-b2b55b34231f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kappa_results = []\n",
        "sizes_to_test = [50, 250, 500, 750, 1000, 1500, 2000, 2500]\n",
        "for size in sizes_to_test:\n",
        "  unigram_names, unigram_df = ngrams(df[\"message\"], vocab_size = size, min_n=1, max_n=1)\n",
        "  unigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "  unigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "  best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, unigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "  print(f\"At vocab size {size}, K={best:.3f}\")\n",
        "  kappa_results.append(best)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.155\n",
            "-------------\n",
            "At vocab size 50, K=0.155\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.212\n",
            "-------------\n",
            "At vocab size 250, K=0.212\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.235\n",
            "-------------\n",
            "At vocab size 500, K=0.235\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.241\n",
            "-------------\n",
            "At vocab size 750, K=0.241\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n",
            "At vocab size 1000, K=0.238\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n",
            "At vocab size 1500, K=0.238\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.236\n",
            "-------------\n",
            "At vocab size 2000, K=0.236\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.234\n",
            "-------------\n",
            "At vocab size 2500, K=0.234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--RJDGE6Q6BK",
        "outputId": "53bd18db-efb0-4b49-bfa4-a3f1cdc63c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plt.plot(sizes_to_test, kappa_results)\n",
        "plt.ylim(0, 0.25)\n",
        "plt.ylabel(\"Kappa\")\n",
        "plt.xlabel(\"Vocabulary Size\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kappa_results = []\n",
        "sizes_to_test = [50, 250, 500, 750, 1000, 1500, 2000, 2500]\n",
        "for size in sizes_to_test:\n",
        "  unigram_names, unigram_df = ngrams(df[\"message\"], vocab_size = size, min_n=1, max_n=1)\n",
        "  unigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "  unigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "  best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, unigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "  print(f\"At vocab size {size}, K={best:.3f}\")\n",
        "  kappa_results.append(best)"
      ],
      "metadata": {
        "id": "d_pfMOLqIRrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d935e556-45b3-4810-9b9a-7885700a7ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.155\n",
            "-------------\n",
            "At vocab size 50, K=0.155\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.212\n",
            "-------------\n",
            "At vocab size 250, K=0.212\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.235\n",
            "-------------\n",
            "At vocab size 500, K=0.235\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.241\n",
            "-------------\n",
            "At vocab size 750, K=0.241\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n",
            "At vocab size 1000, K=0.238\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.238\n",
            "-------------\n",
            "At vocab size 1500, K=0.238\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.236\n",
            "-------------\n",
            "At vocab size 2000, K=0.236\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.234\n",
            "-------------\n",
            "At vocab size 2500, K=0.234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU_d5OEMS4yG"
      },
      "source": [
        "## Stemming\n",
        "\n",
        "If we think about it, there are many words that have very similar meaning. It seems logical that we may want to treat those words the same when we train our models. For example, \"dog\" is probably about as similar to \"dogs\" as it is to just \"dog\" for many tasks. Stemming is one way to do this. We go through our sentence and simplify some common words before creating our ngrams and training a classifier. Here are some examples of some stemming:\n",
        "\n",
        "am, are, is $\\Rightarrow$ be \n",
        "\n",
        "car, cars, car's, cars' $\\Rightarrow$ car\n",
        "\n",
        "[More on Stemming](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fphzeo5WTj31",
        "outputId": "6c013591-c245-4bf3-c2b3-6c49d959736b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "# First we're going to shrink our dataset down again so that parsing and POS tagging run in reasonable\n",
        "# time while we're all in class. If you're willing to wait a few minutes to get tags for the whole\n",
        "# dataset, you can skip these lines.\n",
        "\n",
        "df = df.loc[df.conv_id % 50 == 0].copy()\n",
        "df = df.reset_index()\n",
        "df = df.drop(\"level_0\", axis=1).drop(\"index\", axis=1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      conv_id                                                url conf  \\\n",
              "0      100050  https://www.washingtonpost.com/local/virginia-...    D   \n",
              "1      100050  https://www.washingtonpost.com/local/virginia-...    D   \n",
              "2      100050  https://www.washingtonpost.com/local/virginia-...    D   \n",
              "3      100050  https://www.washingtonpost.com/local/virginia-...    D   \n",
              "4      100050  https://www.washingtonpost.com/local/virginia-...    D   \n",
              "...       ...                                                ...  ...   \n",
              "3740   108600  https://www.washingtonpost.com/news/fancy-stat...    D   \n",
              "3741   108600  https://www.washingtonpost.com/news/fancy-stat...    D   \n",
              "3742   108600  https://www.washingtonpost.com/news/fancy-stat...    D   \n",
              "3743   108600  https://www.washingtonpost.com/news/fancy-stat...    D   \n",
              "3744   108600  https://www.washingtonpost.com/news/fancy-stat...    D   \n",
              "\n",
              "                                                message    agent  \\\n",
              "0      What did you think of the last couple elections?  agent_1   \n",
              "1     I think it has been great for the country. peo...  agent_2   \n",
              "2     That is a great point. I want to keep seeing m...  agent_1   \n",
              "3     the vote should be mandatory. then people woul...  agent_2   \n",
              "4     I agree, I am sure other countries do that. I ...  agent_1   \n",
              "...                                                 ...      ...   \n",
              "3740  Wow, I guess football wasnt that popular back ...  agent_1   \n",
              "3741  The guy must have had incredible hands or spec...  agent_2   \n",
              "3742  I bet he was, probably worth a few points, did...  agent_1   \n",
              "3743  I guess they're hoping to psych out the opposi...  agent_2   \n",
              "3744                     Think that could be effective.  agent_1   \n",
              "\n",
              "                   sentiment                         source turn_rating  \\\n",
              "0     Curious to dive deeper                        ['FS2']   Excellent   \n",
              "1                    Neutral                        ['FS2']   Excellent   \n",
              "2     Curious to dive deeper                        ['FS2']   Excellent   \n",
              "3                    Neutral  ['FS2', 'Personal Knowledge']   Excellent   \n",
              "4     Curious to dive deeper                        ['FS2']   Excellent   \n",
              "...                      ...                            ...         ...   \n",
              "3740  Curious to dive deeper                        ['FS3']   Excellent   \n",
              "3741                 Neutral                        ['FS3']        Good   \n",
              "3742  Curious to dive deeper                        ['FS3']   Excellent   \n",
              "3743                 Neutral                        ['FS3']        Good   \n",
              "3744  Curious to dive deeper                        ['FS3']        Good   \n",
              "\n",
              "     agent_1_rating agent_2_rating rating_simple        sentiment_simple  \n",
              "0         Excellent      Excellent      Positive  Curious to dive deeper  \n",
              "1         Excellent      Excellent      Positive                 Neutral  \n",
              "2         Excellent      Excellent      Positive  Curious to dive deeper  \n",
              "3         Excellent      Excellent      Positive                 Neutral  \n",
              "4         Excellent      Excellent      Positive  Curious to dive deeper  \n",
              "...             ...            ...           ...                     ...  \n",
              "3740           Good           Good      Positive  Curious to dive deeper  \n",
              "3741           Good           Good      Positive                 Neutral  \n",
              "3742           Good           Good      Positive  Curious to dive deeper  \n",
              "3743           Good           Good      Positive                 Neutral  \n",
              "3744           Good           Good      Positive  Curious to dive deeper  \n",
              "\n",
              "[3745 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-974228a0-847a-4d45-9015-0131d8ab0bc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conv_id</th>\n",
              "      <th>url</th>\n",
              "      <th>conf</th>\n",
              "      <th>message</th>\n",
              "      <th>agent</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>source</th>\n",
              "      <th>turn_rating</th>\n",
              "      <th>agent_1_rating</th>\n",
              "      <th>agent_2_rating</th>\n",
              "      <th>rating_simple</th>\n",
              "      <th>sentiment_simple</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100050</td>\n",
              "      <td>https://www.washingtonpost.com/local/virginia-...</td>\n",
              "      <td>D</td>\n",
              "      <td>What did you think of the last couple elections?</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>['FS2']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>https://www.washingtonpost.com/local/virginia-...</td>\n",
              "      <td>D</td>\n",
              "      <td>I think it has been great for the country. peo...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS2']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100050</td>\n",
              "      <td>https://www.washingtonpost.com/local/virginia-...</td>\n",
              "      <td>D</td>\n",
              "      <td>That is a great point. I want to keep seeing m...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>['FS2']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100050</td>\n",
              "      <td>https://www.washingtonpost.com/local/virginia-...</td>\n",
              "      <td>D</td>\n",
              "      <td>the vote should be mandatory. then people woul...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS2', 'Personal Knowledge']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100050</td>\n",
              "      <td>https://www.washingtonpost.com/local/virginia-...</td>\n",
              "      <td>D</td>\n",
              "      <td>I agree, I am sure other countries do that. I ...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>['FS2']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3740</th>\n",
              "      <td>108600</td>\n",
              "      <td>https://www.washingtonpost.com/news/fancy-stat...</td>\n",
              "      <td>D</td>\n",
              "      <td>Wow, I guess football wasnt that popular back ...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3741</th>\n",
              "      <td>108600</td>\n",
              "      <td>https://www.washingtonpost.com/news/fancy-stat...</td>\n",
              "      <td>D</td>\n",
              "      <td>The guy must have had incredible hands or spec...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3742</th>\n",
              "      <td>108600</td>\n",
              "      <td>https://www.washingtonpost.com/news/fancy-stat...</td>\n",
              "      <td>D</td>\n",
              "      <td>I bet he was, probably worth a few points, did...</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3743</th>\n",
              "      <td>108600</td>\n",
              "      <td>https://www.washingtonpost.com/news/fancy-stat...</td>\n",
              "      <td>D</td>\n",
              "      <td>I guess they're hoping to psych out the opposi...</td>\n",
              "      <td>agent_2</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3744</th>\n",
              "      <td>108600</td>\n",
              "      <td>https://www.washingtonpost.com/news/fancy-stat...</td>\n",
              "      <td>D</td>\n",
              "      <td>Think that could be effective.</td>\n",
              "      <td>agent_1</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "      <td>['FS3']</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3745 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-974228a0-847a-4d45-9015-0131d8ab0bc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-974228a0-847a-4d45-9015-0131d8ab0bc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-974228a0-847a-4d45-9015-0131d8ab0bc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dOsGgI3MgQJ",
        "outputId": "25f0baf8-771d-47a1-e344-ecdc2cca78c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "aBCFJVbBNMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LzXQdERTxk2",
        "outputId": "8d67785b-9ee1-43d2-d27a-91da4b5fa619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute STEMMING using Spacy\n",
        "nlp = spacy.load('en_core_web_md', disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "\n",
        "def tokenize(nlp, row):\n",
        "    message = row[\"message\"]\n",
        "    ix = row[\"conv_id\"]\n",
        "    tokens = nlp(message)\n",
        "    return tokens\n",
        "\n",
        "%time all_stemmed = df.apply(lambda x: tokenize(nlp, x), axis=1)\n",
        "all_stemmed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 475 ms, sys: 5.63 ms, total: 480 ms\n",
            "Wall time: 479 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       (What, did, you, think, of, the, last, couple,...\n",
              "1       (I, think, it, has, been, great, for, the, cou...\n",
              "2       (That, is, a, great, point, ., I, want, to, ke...\n",
              "3       (the, vote, should, be, mandatory, ., then, pe...\n",
              "4       (I, agree, ,, I, am, sure, other, countries, d...\n",
              "                              ...                        \n",
              "3740    (Wow, ,, I, guess, football, was, nt, that, po...\n",
              "3741    (The, guy, must, have, had, incredible, hands,...\n",
              "3742    (I, bet, he, was, ,, probably, worth, a, few, ...\n",
              "3743    (I, guess, they, 're, hoping, to, psych, out, ...\n",
              "3744               (Think, that, could, be, effective, .)\n",
              "Length: 3745, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H02ftBvMUAfh",
        "outputId": "b3492d8c-cc00-439b-a934-81e6a9140faf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Turn our list of stemmed tokens back into strings\n",
        "stemmed_inputs = []\n",
        "for stemmed_tokens in all_stemmed:\n",
        "  stemmed_string = \" \".join([token.lemma_ for token in stemmed_tokens])\n",
        "  stemmed_inputs.append(stemmed_string)\n",
        "\n",
        "# Lets see what this stemming transformation looks like!\n",
        "for i in [0, 1]:\n",
        "  for token in all_stemmed.iloc[i]:\n",
        "    print(token.text.ljust(10), end='')\n",
        "  print()\n",
        "  for token in all_stemmed.iloc[i]:\n",
        "    print(token.lemma_.ljust(10), end='')\n",
        "  print()\n",
        "  print('-----------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What      did       you       think     of        the       last      couple    elections ?         \n",
            "What      do        you       think     of        the       last      couple    election  ?         \n",
            "-----------------------------------------------\n",
            "I         think     it        has       been      great     for       the       country   .         people    have      come      to        realize   the       power     of        the       vote      .         \n",
            "I         think     it        have      be        great     for       the       country   .         people    have      come      to        realize   the       power     of        the       vote      .         \n",
            "-----------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ5PwAE_UsAl"
      },
      "source": [
        "# Now let's create some new dataframes and try training models with stemmed inputs\n",
        "unigram_names, unigram_df = ngrams(df[\"message\"])\n",
        "stemmed_names, stemmed_df = ngrams(stemmed_inputs)\n",
        "\n",
        "\n",
        "unigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "unigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "\n",
        "stemmed_df[\"rating\"] = df[\"rating_simple\"]\n",
        "stemmed_df[\"sentiment\"] = df[\"sentiment_simple\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW4i9KnTU9JI",
        "outputId": "298d708e-7641-4b5e-c44a-f75232725408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Re-run our classifier with stopwords included, as a baseline.\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, unigram_df, unigram_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier with surface unigrams K={best:.3f}.\")    \n",
        "\n",
        "\n",
        "# Finally run our classifier on the feature space with case-sensitive unigrams.\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, stemmed_df, stemmed_names, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier with stemmed unigrams K={best:.3f}.\")   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.213\n",
            "-------------\n",
            "Classifier with surface unigrams K=0.213.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.207\n",
            "-------------\n",
            "Classifier with stemmed unigrams K=0.207.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0xJSqkTCGoC"
      },
      "source": [
        "## Part-of-Speech Tagging\n",
        "\n",
        "So far, we have been working exclusively with Bag of Words models for our documents. One of the (several) problems with the BOW model is that we completely ignore the structure of our sentences and just note whether individual words or phrases are present. Part-of-Speech Tagging is one way we can reintroduce some of the properties of our words back to our model by combining our BOW features with features representing the syntactic use of those sentences and the structure of our sentence.\n",
        "\n",
        "\n",
        "This section walks through examples for tagging texts with part-of-speech tags, then inspecting those tags to understand what they look like in real data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv65YSmxBXT_",
        "outputId": "12111b8f-5722-4f28-af26-aa3cd173f598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute POS tagging using Spacy\n",
        "nlp = spacy.load('en_core_web_md', disable=[\"parser\", \"ner\"])\n",
        "\n",
        "def tokenize(nlp, row):\n",
        "    message = row[\"message\"]\n",
        "    ix = row[\"conv_id\"]\n",
        "    tokens = nlp(message)\n",
        "    return tokens\n",
        "\n",
        "%time all_tagged = df.apply(lambda x: tokenize(nlp, x), axis=1)\n",
        "df[\"tokenized\"] = all_tagged"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16 s, sys: 93.2 ms, total: 16.1 s\n",
            "Wall time: 16 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TMWHzkOBhPJ",
        "outputId": "78c26d3f-a3bb-4d13-e6e8-9c660ae790c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the first 2 messages\n",
        "print(df[\"tokenized\"].iloc[0])\n",
        "print(df[\"tokenized\"].iloc[1])\n",
        "print()\n",
        "\n",
        "# As well as their POS tagging\n",
        "for i in [0, 1]:\n",
        "  for token in df[\"tokenized\"].iloc[i]:\n",
        "    print(token.text.ljust(10), end='')\n",
        "  print()\n",
        "  for token in df[\"tokenized\"].iloc[i]:\n",
        "    print(token.lemma_.ljust(10), end='')\n",
        "  print()\n",
        "  for token in df[\"tokenized\"].iloc[i]:\n",
        "    print(token.pos_.ljust(10), end='')\n",
        "  print()\n",
        "  for token in df[\"tokenized\"].iloc[i]:\n",
        "    print(token.tag_.ljust(10), end='')\n",
        "  print(\"\\n-------------------------------------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What did you think of the last couple elections?\n",
            "I think it has been great for the country. people have come to realize the power of the vote.\n",
            "\n",
            "What      did       you       think     of        the       last      couple    elections ?         \n",
            "what      do        -PRON-    think     of        the       last      couple    election  ?         \n",
            "PRON      AUX       PRON      VERB      ADP       DET       ADJ       NOUN      NOUN      PUNCT     \n",
            "WP        VBD       PRP       VB        IN        DT        JJ        NN        NNS       .         \n",
            "-------------------------------------------------------------------------------------------------\n",
            "I         think     it        has       been      great     for       the       country   .         people    have      come      to        realize   the       power     of        the       vote      .         \n",
            "-PRON-    think     -PRON-    have      be        great     for       the       country   .         people    have      come      to        realize   the       power     of        the       vote      .         \n",
            "PRON      VERB      PRON      AUX       AUX       ADJ       ADP       DET       NOUN      PUNCT     NOUN      AUX       VERB      PART      VERB      DET       NOUN      ADP       DET       NOUN      PUNCT     \n",
            "PRP       VBP       PRP       VBZ       VBN       JJ        IN        DT        NN        .         NNS       VBP       VBN       TO        VB        DT        NN        IN        DT        NN        .         \n",
            "-------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9gMXLV-KJsJ"
      },
      "source": [
        "### Classifying with POS Tag Features\n",
        "\n",
        "Next we can evaluate our performance using syntactic POS features alone, without that surface representation. However, we have essentially completely thrown away any information on what words were in our review other than their part of speech. This means that every review that is composed of a noun, verb, and adjective looks exactly the same! This results in the following being identical:\n",
        "\n",
        "- The product is AMAZING\n",
        "- The product is HORRIBLE\n",
        "\n",
        "Unsurprisingly, losing this much information degrades our performance!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkaAEY_dlbBS",
        "outputId": "a79761ea-7902-4001-fc8d-29c45bf12ebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a string of the POS features for each sentence\n",
        "pos_strings = []\n",
        "for row in df[\"tokenized\"]:\n",
        "    pos_strings.append(\" \".join([token.tag_ for token in row]))\n",
        "\n",
        "print(\"Example of POS Features\")\n",
        "print(pos_strings[0])\n",
        "print()\n",
        "\n",
        "# Get the bigram representation of the POS features\n",
        "column_names, pos_df = ngrams(pos_strings, vocab_size = 500, min_n=2, max_n=2)\n",
        "\n",
        "# Add our classification features\n",
        "pos_df[\"rating\"] = df[\"rating_simple\"]\n",
        "pos_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "\n",
        "# Preview the dataframe\n",
        "print(\"Preview POS bigram dataframe\")\n",
        "pos_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of POS Features\n",
            "WP VBD PRP VB IN DT JJ NN NNS .\n",
            "\n",
            "Preview POS bigram dataframe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      _sp  _sp cc  _sp dt  _sp ex  _sp in  _sp jj  _sp nnp  _sp nns  _sp prp  \\\n",
              "0       0       0       0       0       0       0        0        0        0   \n",
              "1       0       0       0       0       0       0        0        0        0   \n",
              "2       0       0       0       0       0       0        0        0        0   \n",
              "3       0       0       0       0       0       0        0        0        0   \n",
              "4       0       0       0       0       0       0        0        0        0   \n",
              "...   ...     ...     ...     ...     ...     ...      ...      ...      ...   \n",
              "3740    0       0       0       0       0       0        0        0        0   \n",
              "3741    0       0       0       0       0       0        0        0        0   \n",
              "3742    0       0       0       0       0       0        0        0        0   \n",
              "3743    0       0       0       0       0       0        0        0        0   \n",
              "3744    0       0       0       0       0       0        0        0        0   \n",
              "\n",
              "      _sp rb  ...  wrb nns  wrb prp  wrb rb  wrb to  wrb vbd  wrb vbp  \\\n",
              "0          0  ...        0        0       0       0        0        0   \n",
              "1          0  ...        0        0       0       0        0        0   \n",
              "2          0  ...        0        0       0       0        0        0   \n",
              "3          0  ...        0        0       0       0        0        0   \n",
              "4          0  ...        0        0       0       0        0        0   \n",
              "...      ...  ...      ...      ...     ...     ...      ...      ...   \n",
              "3740       0  ...        0        0       0       0        0        0   \n",
              "3741       0  ...        0        0       0       0        0        0   \n",
              "3742       0  ...        0        0       0       0        0        0   \n",
              "3743       0  ...        0        0       0       0        0        0   \n",
              "3744       0  ...        0        0       0       0        0        0   \n",
              "\n",
              "      wrb vbz  xx    rating               sentiment  \n",
              "0           0   0  Positive  Curious to dive deeper  \n",
              "1           0   0  Positive                 Neutral  \n",
              "2           0   0  Positive  Curious to dive deeper  \n",
              "3           0   0  Positive                 Neutral  \n",
              "4           0   0  Positive  Curious to dive deeper  \n",
              "...       ...  ..       ...                     ...  \n",
              "3740        0   0  Positive  Curious to dive deeper  \n",
              "3741        0   0  Positive                 Neutral  \n",
              "3742        0   0  Positive  Curious to dive deeper  \n",
              "3743        0   0  Positive                 Neutral  \n",
              "3744        0   0  Positive  Curious to dive deeper  \n",
              "\n",
              "[3745 rows x 502 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb168b8f-684b-418d-b417-df4a604e05c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_sp</th>\n",
              "      <th>_sp cc</th>\n",
              "      <th>_sp dt</th>\n",
              "      <th>_sp ex</th>\n",
              "      <th>_sp in</th>\n",
              "      <th>_sp jj</th>\n",
              "      <th>_sp nnp</th>\n",
              "      <th>_sp nns</th>\n",
              "      <th>_sp prp</th>\n",
              "      <th>_sp rb</th>\n",
              "      <th>...</th>\n",
              "      <th>wrb nns</th>\n",
              "      <th>wrb prp</th>\n",
              "      <th>wrb rb</th>\n",
              "      <th>wrb to</th>\n",
              "      <th>wrb vbd</th>\n",
              "      <th>wrb vbp</th>\n",
              "      <th>wrb vbz</th>\n",
              "      <th>xx</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3740</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3741</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3742</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3743</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3744</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3745 rows × 502 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb168b8f-684b-418d-b417-df4a604e05c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb168b8f-684b-418d-b417-df4a604e05c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb168b8f-684b-418d-b417-df4a604e05c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIxpqPN7jh3q",
        "outputId": "541de75d-aceb-489e-fddb-9354ebcad574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "pos_features = column_names\n",
        "feature_set = pos_features\n",
        "\n",
        "sorted_sentiments = [\"Curious to dive deeper\", \"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, pos_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.189\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.189.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1GHIjcBKXf6"
      },
      "source": [
        "### Combining Feature Spaces\n",
        "\n",
        "By simply appending all of our POS features to our bag-of-words features, we can get a representation that is much larger and still very sparse, but that outperforms the unigrams alone. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1xHP87kmKdx"
      },
      "source": [
        "unigram_names, unigram_df = ngrams(df[\"message\"], vocab_size = 1000, min_n=1, max_n=1)\n",
        "pos_bigram_names, pos_bigram_df = ngrams(pos_strings, vocab_size = 500, min_n=2, max_n=2)\n",
        "\n",
        "combined_bigram_df = unigram_df.merge(pos_bigram_df, how=\"left\", left_index=True, right_index=True)\n",
        "combined_bigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "combined_bigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "\n",
        "pos_trigram_names, pos_trigram_df = ngrams(pos_strings, vocab_size = 500, min_n=2, max_n=3)\n",
        "\n",
        "combined_trigram_df = unigram_df.merge(pos_trigram_df, how=\"left\", left_index=True, right_index=True)\n",
        "combined_trigram_df[\"rating\"] = df[\"rating_simple\"]\n",
        "combined_trigram_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOkhXQQ3m2dx",
        "outputId": "637d73a2-84ef-4947-f688-1df06f02be48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "sorted_sentiments = [\"Curious to dive deeper\", \"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "# Pick features to use\n",
        "feature_set = list(combined_bigram_df.columns[:-2])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, combined_bigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier with Unigrams + POS Bigrams K={best:.3f}.\")    \n",
        "\n",
        "# Pick features to use\n",
        "feature_set = list(combined_trigram_df.columns[:-2])\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, combined_trigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Classifier with Unigrams + POS Bigrams and Trigrams K={best:.3f}.\")    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.244\n",
            "-------------\n",
            "Classifier with Unigrams + POS Bigrams K=0.244.\n",
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.237\n",
            "-------------\n",
            "Classifier with Unigrams + POS Bigrams and Trigrams K=0.237.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tceFPfS1CLr8"
      },
      "source": [
        "## Dependency Parsing\n",
        "\n",
        "Another weakness that we saw with the BOW model was that we completely lose the relationship between the words in the sentence. Dependency Parsing allows us to (kind of) fix this issue. For example, we may want to use phrases such as “South Africa” as a single word instead of ‘South’ and ‘Africa’ as separate words. Dependency Parsing allows us to do this, because we can notice that \"South\" is an adjective describing the noun \"Africa\" so we can understand how words are linked together in sentences.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/3052/1*f6e0uf5PX17pTceYU4rbCA.jpeg\" width=\"600\">\n",
        "\n",
        "[You can read more about Part-of-Speech Tagging and Dependency Parsing here.](https://medium.com/greyatom/learning-pos-tagging-chunking-in-nlp-85f7f811a8cb)\n",
        "\n",
        "[Here is another source on combining these \"Classical\" NLP techniques](https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e)\n",
        "\n",
        "This section will walk through and inspect how we can use dependency parsing to get additional understanding about the structure and content of our texts. This is starting to get into slower, more advanced NLP, and so this is about as deep as we're going to go for the purposes of this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq4vWJmoCbkP",
        "outputId": "88eca429-292e-4cf7-c925-c4eecef64381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "parser = spacy.load('en_core_web_md', disable=[\"ner\"])\n",
        "\n",
        "def parse(nlp, row):\n",
        "    message = row[\"message\"]\n",
        "    ix = row[\"conv_id\"]\n",
        "    tokens = nlp(message)\n",
        "    return tokens\n",
        "\n",
        "%time all_parses = df.apply(lambda x: parse(parser, x), axis=1)\n",
        "df[\"parses\"] = all_parses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.9 s, sys: 132 ms, total: 33 s\n",
            "Wall time: 33 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxyGrbziqlUc",
        "outputId": "215c9da7-b760-4063-e6cd-2fe634ca8f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "for parse in df[\"parses\"][:5]:\n",
        "    print(parse)\n",
        "    for chunk in parse.noun_chunks:\n",
        "        print(chunk)\n",
        "    displacy.render(parse, style='dep', jupyter=True)\n",
        "    print(\"---\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What did you think of the last couple elections?\n",
            "What\n",
            "you\n",
            "the last couple elections\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"daa992ba05f04943b67cd24c0d702e06-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">What</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">did</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">think</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">last</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">couple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">elections?</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1445.0,89.5 1445.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-daa992ba05f04943b67cd24c0d702e06-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-daa992ba05f04943b67cd24c0d702e06-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "I think it has been great for the country. people have come to realize the power of the vote.\n",
            "I\n",
            "it\n",
            "the country\n",
            "people\n",
            "the power\n",
            "the vote\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a273e96896a649cc974d9947b792dfd2-0\" class=\"displacy\" width=\"3375\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">think</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">it</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">has</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">been</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">great</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">country.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">people</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">have</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">come</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">realize</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">power</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">vote.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-10\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,177.0 2315.0,177.0 2315.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,266.5 L2162,254.5 2178,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-11\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,89.5 2320.0,89.5 2320.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2320.0,266.5 L2328.0,254.5 2312.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-12\" stroke-width=\"2px\" d=\"M2520,264.5 C2520,177.0 2665.0,177.0 2665.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,266.5 L2512,254.5 2528,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-13\" stroke-width=\"2px\" d=\"M2345,264.5 C2345,89.5 2670.0,89.5 2670.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2670.0,266.5 L2678.0,254.5 2662.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-14\" stroke-width=\"2px\" d=\"M2695,264.5 C2695,177.0 2840.0,177.0 2840.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2840.0,266.5 L2848.0,254.5 2832.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-15\" stroke-width=\"2px\" d=\"M3045,264.5 C3045,177.0 3190.0,177.0 3190.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,266.5 L3037,254.5 3053,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a273e96896a649cc974d9947b792dfd2-0-16\" stroke-width=\"2px\" d=\"M2870,264.5 C2870,89.5 3195.0,89.5 3195.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a273e96896a649cc974d9947b792dfd2-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3195.0,266.5 L3203.0,254.5 3187.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "That is a great point. I want to keep seeing more and more voter turnout. It hasn't been more than 62.8 percent in 100 years\n",
            "a great point\n",
            "I\n",
            "more and more voter turnout\n",
            "It\n",
            "more than 62.8 percent\n",
            "100 years\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3b068cde423147eb9e3a4c1315ad79c5-0\" class=\"displacy\" width=\"4600\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">That</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">great</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">point.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">want</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">keep</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">seeing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">more</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">more</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">voter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">turnout.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">It</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">has</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">n't</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">been</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">more</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">than</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">62.8</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">percent</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">100</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">years</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-1\" stroke-width=\"2px\" d=\"M420,439.5 C420,264.5 735.0,264.5 735.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-3\" stroke-width=\"2px\" d=\"M245,439.5 C245,177.0 740.0,177.0 740.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,441.5 L748.0,429.5 732.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-4\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-5\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-6\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,264.5 1435.0,264.5 1435.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1435.0,441.5 L1443.0,429.5 1427.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1605.0,441.5 L1613.0,429.5 1597.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-8\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,89.5 2495.0,89.5 2495.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1955.0,441.5 L1963.0,429.5 1947.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-10\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,264.5 2135.0,264.5 2135.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2135.0,441.5 L2143.0,429.5 2127.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-11\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-12\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,2.0 2500.0,2.0 2500.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2500.0,441.5 L2508.0,429.5 2492.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-13\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,177.0 3190.0,177.0 3190.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-14\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,264.5 3185.0,264.5 3185.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,441.5 L2862,429.5 2878,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-15\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,352.0 3180.0,352.0 3180.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,441.5 L3037,429.5 3053,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-16\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,264.5 3710.0,264.5 3710.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,441.5 L3387,429.5 3403,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-17\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,352.0 3705.0,352.0 3705.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-18\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,352.0 3880.0,352.0 3880.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,441.5 L3737,429.5 3753,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-19\" stroke-width=\"2px\" d=\"M3220,439.5 C3220,89.5 3895.0,89.5 3895.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3895.0,441.5 L3903.0,429.5 3887.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-20\" stroke-width=\"2px\" d=\"M3920,439.5 C3920,352.0 4055.0,352.0 4055.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4055.0,441.5 L4063.0,429.5 4047.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-21\" stroke-width=\"2px\" d=\"M4270,439.5 C4270,352.0 4405.0,352.0 4405.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4270,441.5 L4262,429.5 4278,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-3b068cde423147eb9e3a4c1315ad79c5-0-22\" stroke-width=\"2px\" d=\"M4095,439.5 C4095,264.5 4410.0,264.5 4410.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-3b068cde423147eb9e3a4c1315ad79c5-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4410.0,441.5 L4418.0,429.5 4402.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "the vote should be mandatory. then people would see the power of the ballot.\n",
            "the vote\n",
            "people\n",
            "the power\n",
            "the ballot\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"84f7ca36eeed4529a981bb3dc313a192-0\" class=\"displacy\" width=\"2500\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">vote</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">should</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">be</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">mandatory.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">then</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">people</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">would</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">see</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">power</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">ballot.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-7\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1795.0,266.5 L1803.0,254.5 1787.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1965.0,266.5 L1973.0,254.5 1957.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-10\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,177.0 2315.0,177.0 2315.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,266.5 L2162,254.5 2178,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-84f7ca36eeed4529a981bb3dc313a192-0-11\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,89.5 2320.0,89.5 2320.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-84f7ca36eeed4529a981bb3dc313a192-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2320.0,266.5 L2328.0,254.5 2312.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "I agree, I am sure other countries do that. I don't think we should go back to how ancient athens did it, do you know how?\n",
            "I\n",
            "I\n",
            "other countries\n",
            "I\n",
            "we\n",
            "how ancient athens\n",
            "it\n",
            "you\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fba4a6d41f2b4c38b85ae2bb39a1abf4-0\" class=\"displacy\" width=\"4775\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">agree,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">am</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">sure</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">other</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">countries</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">do</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">that.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">do</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">n't</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">think</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">we</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">should</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">go</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">back</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">how</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">ancient</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">athens</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">did</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">it,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">do</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">know</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">how?</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-1\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-2\" stroke-width=\"2px\" d=\"M245,439.5 C245,264.5 560.0,264.5 560.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M560.0,441.5 L568.0,429.5 552.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M730.0,441.5 L738.0,429.5 722.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-4\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-5\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-6\" stroke-width=\"2px\" d=\"M770,439.5 C770,177.0 1265.0,177.0 1265.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1265.0,441.5 L1273.0,429.5 1257.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-7\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1430.0,441.5 L1438.0,429.5 1422.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,177.0 2140.0,177.0 2140.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,264.5 2135.0,264.5 2135.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-10\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,441.5 L1987,429.5 2003,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-11\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,2.0 4425.0,2.0 4425.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,441.5 L2162,429.5 2178,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,264.5 2660.0,264.5 2660.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-13\" stroke-width=\"2px\" d=\"M2520,439.5 C2520,352.0 2655.0,352.0 2655.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,441.5 L2512,429.5 2528,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-14\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,177.0 2665.0,177.0 2665.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2665.0,441.5 L2673.0,429.5 2657.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-15\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,352.0 2830.0,352.0 2830.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2830.0,441.5 L2838.0,429.5 2822.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-16\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3005.0,441.5 L3013.0,429.5 2997.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-17\" stroke-width=\"2px\" d=\"M3220,439.5 C3220,352.0 3355.0,352.0 3355.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,441.5 L3212,429.5 3228,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-18\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,352.0 3530.0,352.0 3530.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,441.5 L3387,429.5 3403,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-19\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,352.0 3705.0,352.0 3705.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-20\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,89.5 3720.0,89.5 3720.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3720.0,441.5 L3728.0,429.5 3712.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-21\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,352.0 3880.0,352.0 3880.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3880.0,441.5 L3888.0,429.5 3872.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-22\" stroke-width=\"2px\" d=\"M4095,439.5 C4095,264.5 4410.0,264.5 4410.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4095,441.5 L4087,429.5 4103,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-23\" stroke-width=\"2px\" d=\"M4270,439.5 C4270,352.0 4405.0,352.0 4405.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4270,441.5 L4262,429.5 4278,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-24\" stroke-width=\"2px\" d=\"M4445,439.5 C4445,352.0 4580.0,352.0 4580.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fba4a6d41f2b4c38b85ae2bb39a1abf4-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4580.0,441.5 L4588.0,429.5 4572.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ZNtZw0CLw-"
      },
      "source": [
        "# Multilingual NLP\n",
        "\n",
        "Of course, English isn't the only language that there are NLP tools available for. You can find similar tools available for most widely spoken languages! Let's take a look at this by doing some sentiment analysis on posts from [weibo](https://en.wikipedia.org/wiki/Microblogging_in_China), a chinese microblogging site similar to Twitter. We will look at each of the posts and predict the emotion felt by the poster from the text! While normally its not recommended to train models on data that you do not understand -- because it is nearly impossible to catch common training mistakes -- we can all look at this as just an example of how we can extend the techniques we have used so far to other languages.\n",
        "\n",
        "To start off, let's load and preview our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XnUKnf5FGMX",
        "outputId": "ce406bae-2663-4d0e-bb4d-d577bfa8d256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filename = \"stopwords-zh.txt\"\n",
        "zh_stopwords = open(filename).readlines()\n",
        "zh_stopwords = [x.strip() for x in zh_stopwords]\n",
        "print(zh_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['一', '一些', '一何', '一切', '一则', '一方面', '一旦', '一来', '一样', '一般', '一转眼', '七', '万一', '三', '上', '上下', '下', '不', '不仅', '不但', '不光', '不单', '不只', '不外乎', '不如', '不妨', '不尽', '不尽然', '不得', '不怕', '不惟', '不成', '不拘', '不料', '不是', '不比', '不然', '不特', '不独', '不管', '不至于', '不若', '不论', '不过', '不问', '与', '与其', '与其说', '与否', '与此同时', '且', '且不说', '且说', '两者', '个', '个别', '中', '临', '为', '为了', '为什么', '为何', '为止', '为此', '为着', '乃', '乃至', '乃至于', '么', '之', '之一', '之所以', '之类', '乌乎', '乎', '乘', '九', '也', '也好', '也罢', '了', '二', '二来', '于', '于是', '于是乎', '云云', '云尔', '五', '些', '亦', '人', '人们', '人家', '什', '什么', '什么样', '今', '介于', '仍', '仍旧', '从', '从此', '从而', '他', '他人', '他们', '他们们', '以', '以上', '以为', '以便', '以免', '以及', '以故', '以期', '以来', '以至', '以至于', '以致', '们', '任', '任何', '任凭', '会', '似的', '但', '但凡', '但是', '何', '何以', '何况', '何处', '何时', '余外', '作为', '你', '你们', '使', '使得', '例如', '依', '依据', '依照', '便于', '俺', '俺们', '倘', '倘使', '倘或', '倘然', '倘若', '借', '借傥然', '假使', '假如', '假若', '做', '像', '儿', '先不先', '光是', '全体', '全部', '八', '六', '兮', '共', '关于', '关于具体地说', '其', '其一', '其中', '其二', '其他', '其余', '其它', '其次', '具体地说', '具体说来', '兼之', '内', '再', '再其次', '再则', '再有', '再者', '再者说', '再说', '冒', '冲', '况且', '几', '几时', '凡', '凡是', '凭', '凭借', '出于', '出来', '分', '分别', '则', '则甚', '别', '别人', '别处', '别是', '别的', '别管', '别说', '到', '前后', '前此', '前者', '加之', '加以', '即', '即令', '即使', '即便', '即如', '即或', '即若', '却', '去', '又', '又及', '及', '及其', '及至', '反之', '反而', '反过来', '反过来说', '受到', '另', '另一方面', '另外', '另悉', '只', '只当', '只怕', '只是', '只有', '只消', '只要', '只限', '叫', '叮咚', '可', '可以', '可是', '可见', '各', '各个', '各位', '各种', '各自', '同', '同时', '后', '后者', '向', '向使', '向着', '吓', '吗', '否则', '吧', '吧哒', '含', '吱', '呀', '呃', '呕', '呗', '呜', '呜呼', '呢', '呵', '呵呵', '呸', '呼哧', '咋', '和', '咚', '咦', '咧', '咱', '咱们', '咳', '哇', '哈', '哈哈', '哉', '哎', '哎呀', '哎哟', '哗', '哟', '哦', '哩', '哪', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼', '哼唷', '唉', '唯有', '啊', '啐', '啥', '啦', '啪达', '啷当', '喂', '喏', '喔唷', '喽', '嗡', '嗡嗡', '嗬', '嗯', '嗳', '嘎', '嘎登', '嘘', '嘛', '嘻', '嘿', '嘿嘿', '四', '因', '因为', '因了', '因此', '因着', '因而', '固然', '在', '在下', '在于', '地', '基于', '处在', '多', '多么', '多少', '大', '大家', '她', '她们', '好', '如', '如上', '如上所述', '如下', '如何', '如其', '如同', '如是', '如果', '如此', '如若', '始而', '孰料', '孰知', '宁', '宁可', '宁愿', '宁肯', '它', '它们', '对', '对于', '对待', '对方', '对比', '将', '小', '尔', '尔后', '尔尔', '尚且', '就', '就是', '就是了', '就是说', '就算', '就要', '尽', '尽管', '尽管如此', '岂但', '己', '已', '已矣', '巴', '巴巴', '年', '并', '并且', '庶乎', '庶几', '开外', '开始', '归', '归齐', '当', '当地', '当然', '当着', '彼', '彼时', '彼此', '往', '待', '很', '得', '得了', '怎', '怎么', '怎么办', '怎么样', '怎奈', '怎样', '总之', '总的来看', '总的来说', '总的说来', '总而言之', '恰恰相反', '您', '惟其', '慢说', '我', '我们', '或', '或则', '或是', '或曰', '或者', '截至', '所', '所以', '所在', '所幸', '所有', '才', '才能', '打', '打从', '把', '抑或', '拿', '按', '按照', '换句话说', '换言之', '据', '据此', '接着', '故', '故此', '故而', '旁人', '无', '无宁', '无论', '既', '既往', '既是', '既然', '日', '时', '时候', '是', '是以', '是的', '更', '曾', '替', '替代', '最', '月', '有', '有些', '有关', '有及', '有时', '有的', '望', '朝', '朝着', '本', '本人', '本地', '本着', '本身', '来', '来着', '来自', '来说', '极了', '果然', '果真', '某', '某个', '某些', '某某', '根据', '欤', '正值', '正如', '正巧', '正是', '此', '此地', '此处', '此外', '此时', '此次', '此间', '毋宁', '每', '每当', '比', '比及', '比如', '比方', '没奈何', '沿', '沿着', '漫说', '焉', '然则', '然后', '然而', '照', '照着', '犹且', '犹自', '甚且', '甚么', '甚或', '甚而', '甚至', '甚至于', '用', '用来', '由', '由于', '由是', '由此', '由此可见', '的', '的确', '的话', '直到', '相对而言', '省得', '看', '眨眼', '着', '着呢', '矣', '矣乎', '矣哉', '离', '秒', '竟而', '第', '等', '等到', '等等', '简言之', '管', '类如', '紧接着', '纵', '纵令', '纵使', '纵然', '经', '经过', '结果', '给', '继之', '继后', '继而', '综上所述', '罢了', '者', '而', '而且', '而况', '而后', '而外', '而已', '而是', '而言', '能', '能否', '腾', '自', '自个儿', '自从', '自各儿', '自后', '自家', '自己', '自打', '自身', '至', '至于', '至今', '至若', '致', '般的', '若', '若夫', '若是', '若果', '若非', '莫不然', '莫如', '莫若', '虽', '虽则', '虽然', '虽说', '被', '要', '要不', '要不是', '要不然', '要么', '要是', '譬喻', '譬如', '让', '许多', '论', '设使', '设或', '设若', '诚如', '诚然', '该', '说', '说来', '请', '诸', '诸位', '诸如', '谁', '谁人', '谁料', '谁知', '贼死', '赖以', '赶', '起', '起见', '趁', '趁着', '越是', '距', '跟', '较', '较之', '边', '过', '还', '还是', '还有', '还要', '这', '这一来', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这次', '这般', '这边', '这里', '进而', '连', '连同', '逐步', '通过', '遵循', '遵照', '那', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那样', '那般', '那边', '那里', '都', '鄙人', '鉴于', '针对', '阿', '除', '除了', '除外', '除开', '除此之外', '除非', '随', '随后', '随时', '随着', '难道说', '零', '非', '非但', '非徒', '非特', '非独', '靠', '顺', '顺着', '首先']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Fcjg3HANTA",
        "outputId": "b965e781-9fa9-427a-c4dd-eb00be1f1091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "filename = \"weibo.csv\"\n",
        "zh_df = pd.read_csv(open(filename))\n",
        "zh_df = zh_df.drop('Unnamed: 0', axis=1)\n",
        "zh_df[\"post\"] = [x.replace(\"\\n\",\"\") for x in zh_df[\"post\"]]\n",
        "zh_df[\"reply\"] = [x.replace(\"\\n\",\"\") for x in zh_df[\"reply\"]]\n",
        "print(f\"Original shape: {zh_df.shape}\")\n",
        "zh_df = zh_df.loc[zh_df.index % 50 == 0].copy()\n",
        "print(f\"Reduced-size shape: {zh_df.shape}\")\n",
        "\n",
        "print(zh_df[\"post_emotion\"].value_counts())\n",
        "print(zh_df[\"reply_emotion\"].value_counts())\n",
        "zh_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (663621, 4)\n",
            "Reduced-size shape: (13273, 4)\n",
            "Like         4491\n",
            "Disgust      3135\n",
            "Sadness      2193\n",
            "Happiness    2064\n",
            "Anger        1390\n",
            "Name: post_emotion, dtype: int64\n",
            "Like         2974\n",
            "Happiness    2948\n",
            "Disgust      2765\n",
            "Sadness      2604\n",
            "Anger        1982\n",
            "Name: reply_emotion, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           post post_emotion  \\\n",
              "0                   哈哈 、 生日 快乐 。 我 地 居然 同一 日 生日    Happiness   \n",
              "50                         是 2 丁目 的 工作 证 照片 吗 ?      Disgust   \n",
              "100                                老板 娘 很 喜欢 摩托         Like   \n",
              "150                                   笑 点 好 低 啊    Happiness   \n",
              "200                                 应该 是 酷毙 了 !         Like   \n",
              "...                                         ...          ...   \n",
              "663400                这 是 杂 啦 。 生 大气 了 。 别 生气 。      Disgust   \n",
              "663450  哈哈 ， 现在 看到 方 舟子 ， 我 有 一 种 强烈 的 肖 传国 感 。    Happiness   \n",
              "663500                 不 带 宝贝 ， 老天 爷 也 不 高兴 了 吧      Sadness   \n",
              "663550                        厉害 ！ 果然 是 闪电 不断 。         Like   \n",
              "663600                           这 张 好 有 家 的 感觉         Like   \n",
              "\n",
              "                                                    reply reply_emotion  \n",
              "0                                            哈哈 … 生日 快乐 。     Happiness  \n",
              "50                                 可以 不要 爆 人家 的 历史 背景 吗 ？       Disgust  \n",
              "100                  这个 只能 算 花边 新闻 ， 好 不好 ！ 吃 的 东西 怎么 样 ？       Disgust  \n",
              "150     是 比不上 你 那个 家里 三缺一 不能 打牌 就 决定 再生 个 出来 的 构想 搞笑 雷...       Disgust  \n",
              "200                                   不错 相当 酷 我 喜欢 。 嘿嘿 。          Like  \n",
              "...                                                   ...           ...  \n",
              "663400                                     哎 。 。 。 气死 我 了       Sadness  \n",
              "663450      这 句 话 传神 ， 当然 ， 方 粉 脑袋 上 过 环 ， 会 以为 你 有 暴力 倾向       Disgust  \n",
              "663500                                         老天 爷 真 棒 ！          Like  \n",
              "663550               一 秒 闪 三四 下 ， 估计 机场 惨 了 ， 塔台 乱套 了 吧 ？       Sadness  \n",
              "663600                                   整体 感觉 很 舒适 ， 象 家          Like  \n",
              "\n",
              "[13273 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d9dd8ec-e1e2-4c9f-9df2-e00f05d1e80f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post</th>\n",
              "      <th>post_emotion</th>\n",
              "      <th>reply</th>\n",
              "      <th>reply_emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>哈哈 、 生日 快乐 。 我 地 居然 同一 日 生日</td>\n",
              "      <td>Happiness</td>\n",
              "      <td>哈哈 … 生日 快乐 。</td>\n",
              "      <td>Happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>是 2 丁目 的 工作 证 照片 吗 ?</td>\n",
              "      <td>Disgust</td>\n",
              "      <td>可以 不要 爆 人家 的 历史 背景 吗 ？</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>老板 娘 很 喜欢 摩托</td>\n",
              "      <td>Like</td>\n",
              "      <td>这个 只能 算 花边 新闻 ， 好 不好 ！ 吃 的 东西 怎么 样 ？</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>笑 点 好 低 啊</td>\n",
              "      <td>Happiness</td>\n",
              "      <td>是 比不上 你 那个 家里 三缺一 不能 打牌 就 决定 再生 个 出来 的 构想 搞笑 雷...</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>应该 是 酷毙 了 !</td>\n",
              "      <td>Like</td>\n",
              "      <td>不错 相当 酷 我 喜欢 。 嘿嘿 。</td>\n",
              "      <td>Like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663400</th>\n",
              "      <td>这 是 杂 啦 。 生 大气 了 。 别 生气 。</td>\n",
              "      <td>Disgust</td>\n",
              "      <td>哎 。 。 。 气死 我 了</td>\n",
              "      <td>Sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663450</th>\n",
              "      <td>哈哈 ， 现在 看到 方 舟子 ， 我 有 一 种 强烈 的 肖 传国 感 。</td>\n",
              "      <td>Happiness</td>\n",
              "      <td>这 句 话 传神 ， 当然 ， 方 粉 脑袋 上 过 环 ， 会 以为 你 有 暴力 倾向</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663500</th>\n",
              "      <td>不 带 宝贝 ， 老天 爷 也 不 高兴 了 吧</td>\n",
              "      <td>Sadness</td>\n",
              "      <td>老天 爷 真 棒 ！</td>\n",
              "      <td>Like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663550</th>\n",
              "      <td>厉害 ！ 果然 是 闪电 不断 。</td>\n",
              "      <td>Like</td>\n",
              "      <td>一 秒 闪 三四 下 ， 估计 机场 惨 了 ， 塔台 乱套 了 吧 ？</td>\n",
              "      <td>Sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663600</th>\n",
              "      <td>这 张 好 有 家 的 感觉</td>\n",
              "      <td>Like</td>\n",
              "      <td>整体 感觉 很 舒适 ， 象 家</td>\n",
              "      <td>Like</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13273 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d9dd8ec-e1e2-4c9f-9df2-e00f05d1e80f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d9dd8ec-e1e2-4c9f-9df2-e00f05d1e80f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d9dd8ec-e1e2-4c9f-9df2-e00f05d1e80f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFJ6qij6xfd"
      },
      "source": [
        "**Once again, let's simplify our possibile sentiments to make classification simpler**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGb3CbO9KD-q",
        "outputId": "e01f93a0-c044-46bd-8f98-b52a2208e9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def simplify_sentiment(emotion):\n",
        "  if emotion in [\"Like\", \"Happiness\"]:\n",
        "    return \"Positive\"\n",
        "  elif emotion in [\"Sadness\", \"Disgust\", \"Anger\"]:\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Other\"\n",
        "\n",
        "zh_df[\"post_sentiment\"] = zh_df[\"post_emotion\"].apply(simplify_sentiment)\n",
        "zh_df[\"reply_sentiment\"] = zh_df[\"reply_emotion\"].apply(simplify_sentiment)\n",
        "zh_df = zh_df.reset_index()\n",
        "print(zh_df[\"post_sentiment\"].value_counts())\n",
        "print(zh_df[\"reply_sentiment\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative    6718\n",
            "Positive    6555\n",
            "Name: post_sentiment, dtype: int64\n",
            "Negative    7351\n",
            "Positive    5922\n",
            "Name: reply_sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faCURg5J1cXY"
      },
      "source": [
        "### Predicting Sentiment of Posts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW9QU2ATCRP6",
        "outputId": "32a49c46-a92f-4094-d22a-7984db1eb553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Notice we can use the same Spacy tools for Chinese as we did for English\n",
        "chinese_nlp = Chinese()\n",
        "\n",
        "sample_sentence = \"新浪微博，是一个由新浪网推出，提供微博客的社交媒体网站。\"\n",
        "\n",
        "tokenized = chinese_nlp(sample_sentence)\n",
        "for token in tokenized:\n",
        "    print(token)\n",
        "\n",
        "spaced = \" \".join([x.text for x in tokenized])\n",
        "print(spaced)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新浪\n",
            "微博\n",
            "，\n",
            "是\n",
            "一个\n",
            "由\n",
            "新浪网\n",
            "推出\n",
            "，\n",
            "提供\n",
            "微\n",
            "博客\n",
            "的\n",
            "社交\n",
            "媒体\n",
            "网站\n",
            "。\n",
            "新浪 微博 ， 是 一个 由 新浪网 推出 ， 提供 微 博客 的 社交 媒体 网站 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFXXDhTFmy5U",
        "outputId": "0440a84f-e257-4cc2-d730-69aae90b0955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in tokenized:\n",
        "  if token.text not in zh_stopwords:\n",
        "    print(token.text)\n",
        "  else:\n",
        "    print(f\"-------  Skipping: {token.text}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新浪\n",
            "微博\n",
            "，\n",
            "-------  Skipping: 是\n",
            "一个\n",
            "-------  Skipping: 由\n",
            "新浪网\n",
            "推出\n",
            "，\n",
            "提供\n",
            "微\n",
            "博客\n",
            "-------  Skipping: 的\n",
            "社交\n",
            "媒体\n",
            "网站\n",
            "。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS554Fyhyxgx",
        "outputId": "6551c93d-132a-4909-ff03-f67de401eac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "# Let's create BOW features for our posts\n",
        "\n",
        "# Tokenize our posts using Spacy\n",
        "segmented_posts = []\n",
        "for post in zh_df[\"post\"]:\n",
        "    tokens = chinese_nlp(post)\n",
        "    spaced = \" \".join([x.text for x in tokens])\n",
        "    segmented_posts.append(spaced)\n",
        "\n",
        "# Get the unigrams from our posts and add our classification column\n",
        "column_names, zh_unigram_df = ngrams(segmented_posts, vocab_size = 1000, min_n=1, max_n=1)\n",
        "zh_unigram_df[\"sentiment\"] = zh_df[\"post_sentiment\"]\n",
        "\n",
        "# Preview our new DataFrame\n",
        "zh_unigram_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       20  90  一下  一个  一会  一切  一定  一把  一样  一点  ...  高调  高铁  魅力  鸭梨  麻将  麻烦  \\\n",
              "0       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "1       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "2       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "3       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "4       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "13268   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13269   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13270   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13271   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13272   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "\n",
              "       黑色  鼓励  鼻子  sentiment  \n",
              "0       0   0   0   Positive  \n",
              "1       0   0   0   Negative  \n",
              "2       0   0   0   Positive  \n",
              "3       0   0   0   Positive  \n",
              "4       0   0   0   Positive  \n",
              "...    ..  ..  ..        ...  \n",
              "13268   0   0   0   Negative  \n",
              "13269   0   0   0   Positive  \n",
              "13270   0   0   0   Negative  \n",
              "13271   0   0   0   Positive  \n",
              "13272   0   0   0   Positive  \n",
              "\n",
              "[13273 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-583d2428-db71-4a0e-869d-c3184df06367\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>20</th>\n",
              "      <th>90</th>\n",
              "      <th>一下</th>\n",
              "      <th>一个</th>\n",
              "      <th>一会</th>\n",
              "      <th>一切</th>\n",
              "      <th>一定</th>\n",
              "      <th>一把</th>\n",
              "      <th>一样</th>\n",
              "      <th>一点</th>\n",
              "      <th>...</th>\n",
              "      <th>高调</th>\n",
              "      <th>高铁</th>\n",
              "      <th>魅力</th>\n",
              "      <th>鸭梨</th>\n",
              "      <th>麻将</th>\n",
              "      <th>麻烦</th>\n",
              "      <th>黑色</th>\n",
              "      <th>鼓励</th>\n",
              "      <th>鼻子</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13268</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13269</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13270</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13271</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13272</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13273 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-583d2428-db71-4a0e-869d-c3184df06367')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-583d2428-db71-4a0e-869d-c3184df06367 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-583d2428-db71-4a0e-869d-c3184df06367');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyvjP4AszsVU",
        "outputId": "5a056d29-2946-4d86-f4ff-755071752d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "unigram_features = list(zh_unigram_df.columns[:-1])\n",
        "feature_set = unigram_features\n",
        "\n",
        "sorted_sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, zh_unigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.699\n",
            "-------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqiou2ap1YRU"
      },
      "source": [
        "**We can predict the sentiment of the replies as well!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0wS25761p7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef4d8da-bb4c-46c9-8f02-97ac4c9e0648"
      },
      "source": [
        "# Tokenize Replies\n",
        "segmented_replies = []\n",
        "for reply in zh_df[\"reply\"]:\n",
        "  tokens = chinese_nlp(reply)\n",
        "  spaced = \" \".join([x.text for x in tokens])\n",
        "  segmented_replies.append(spaced)\n",
        "\n",
        "# Prepare unigrams DataFrame\n",
        "column_names, zh_unigram_df = ngrams(segmented_replies, vocab_size = 1000, min_n=1, max_n=1)\n",
        "zh_unigram_df[\"sentiment\"] = zh_df[\"reply_sentiment\"]\n",
        "\n",
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "unigram_features = list(zh_unigram_df.columns[:-1])\n",
        "feature_set = unigram_features\n",
        "\n",
        "sorted_sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, zh_unigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.699\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.699.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvb13YdRoxii"
      },
      "source": [
        "### Hyperparameter: N-Grams in Chinese\n",
        "\n",
        "We can also use the same types of hyperparameters we used for english when we train models on Chinese text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnnNOp_Joekx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3dfedcc8-4b6b-4f13-a8d7-76e81c74ed44"
      },
      "source": [
        "# Tokenize Replies\n",
        "segmented_replies = []\n",
        "for reply in zh_df[\"reply\"]:\n",
        "  tokens = chinese_nlp(reply)\n",
        "  spaced = \" \".join([x.text for x in tokens])\n",
        "  segmented_replies.append(spaced)\n",
        "\n",
        "# Prepare ngrams DataFrame\n",
        "column_names, zh_bigram_df = ngrams(segmented_replies, vocab_size = 5000, min_n=1, max_n=2)\n",
        "zh_bigram_df[\"sentiment\"] = zh_df[\"reply_sentiment\"]\n",
        "\n",
        "zh_bigram_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       10  100  11  12  13  19  20  2011  2012  23  ...  黄牛  黄色  黑暗  黑色  默契  \\\n",
              "0       0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "1       0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "2       0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "3       0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "4       0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "...    ..  ...  ..  ..  ..  ..  ..   ...   ...  ..  ...  ..  ..  ..  ..  ..   \n",
              "13268   0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "13269   0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "13270   0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "13271   0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "13272   0    0   0   0   0   0   0     0     0   0  ...   0   0   0   0   0   \n",
              "\n",
              "       默默  鼓励  鼻子  鼻涕  sentiment  \n",
              "0       0   0   0   0   Positive  \n",
              "1       0   0   0   0   Negative  \n",
              "2       0   0   0   0   Negative  \n",
              "3       0   0   0   0   Negative  \n",
              "4       0   0   0   0   Positive  \n",
              "...    ..  ..  ..  ..        ...  \n",
              "13268   0   0   0   0   Negative  \n",
              "13269   0   0   0   0   Negative  \n",
              "13270   0   0   0   0   Positive  \n",
              "13271   0   0   0   0   Negative  \n",
              "13272   0   0   0   0   Positive  \n",
              "\n",
              "[13273 rows x 5001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84f8630f-2999-496e-a6ee-9f24d15e5a03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>23</th>\n",
              "      <th>...</th>\n",
              "      <th>黄牛</th>\n",
              "      <th>黄色</th>\n",
              "      <th>黑暗</th>\n",
              "      <th>黑色</th>\n",
              "      <th>默契</th>\n",
              "      <th>默默</th>\n",
              "      <th>鼓励</th>\n",
              "      <th>鼻子</th>\n",
              "      <th>鼻涕</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13268</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13269</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13270</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13271</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13272</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13273 rows × 5001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84f8630f-2999-496e-a6ee-9f24d15e5a03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84f8630f-2999-496e-a6ee-9f24d15e5a03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84f8630f-2999-496e-a6ee-9f24d15e5a03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mJ1ejgEByF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14adf88d-ba28-4923-8bab-02e8d93ab358"
      },
      "source": [
        "\n",
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "bigram_features = list(zh_bigram_df.columns[:-1])\n",
        "feature_set = bigram_features\n",
        "\n",
        "sorted_sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, zh_bigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet')\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.722\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.722.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFmwvRHdnchT"
      },
      "source": [
        "### Hyperparameter: Stopwords in Chinese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiD42TQOnbya"
      },
      "source": [
        "# Extract features for unigrams with no stopwords included.\n",
        "vectorizer = CountVectorizer(max_features=1000, ngram_range=(1,1), stop_words=zh_stopwords)\n",
        "X = vectorizer.fit_transform(segmented_replies)\n",
        "\n",
        "no_stopwords_df = pd.DataFrame(X.toarray())\n",
        "no_stopwords_columns = [str(i) for i in range(1000)]\n",
        "for k, v in vectorizer.vocabulary_.items():\n",
        "  no_stopwords_columns[v] = k\n",
        "no_stopwords_df.columns = no_stopwords_columns\n",
        "no_stopwords_df[\"sentiment\"] = zh_df[\"post_sentiment\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il2sAb8LoPQy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "594455fb-f9c4-48e6-a683-bf29339f6c4e"
      },
      "source": [
        "no_stopwords_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       10  20  一下  一个  一会  一向  一如既往  一定  一把  一点  ...  骂人  骄傲  骗人  骗子  高中  高兴  \\\n",
              "0       0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "1       0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "2       0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "3       0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "4       0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "...    ..  ..  ..  ..  ..  ..   ...  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "13268   0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13269   0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13270   0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13271   0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "13272   0   0   0   0   0   0     0   0   0   0  ...   0   0   0   0   0   0   \n",
              "\n",
              "       麻烦  默默  鼓励  sentiment  \n",
              "0       0   0   0   Positive  \n",
              "1       0   0   0   Negative  \n",
              "2       0   0   0   Positive  \n",
              "3       0   0   0   Positive  \n",
              "4       0   0   0   Positive  \n",
              "...    ..  ..  ..        ...  \n",
              "13268   0   0   0   Negative  \n",
              "13269   0   0   0   Positive  \n",
              "13270   0   0   0   Negative  \n",
              "13271   0   0   0   Positive  \n",
              "13272   0   0   0   Positive  \n",
              "\n",
              "[13273 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fde9d1c-4cdf-4067-9764-8bd5034ac594\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>一下</th>\n",
              "      <th>一个</th>\n",
              "      <th>一会</th>\n",
              "      <th>一向</th>\n",
              "      <th>一如既往</th>\n",
              "      <th>一定</th>\n",
              "      <th>一把</th>\n",
              "      <th>一点</th>\n",
              "      <th>...</th>\n",
              "      <th>骂人</th>\n",
              "      <th>骄傲</th>\n",
              "      <th>骗人</th>\n",
              "      <th>骗子</th>\n",
              "      <th>高中</th>\n",
              "      <th>高兴</th>\n",
              "      <th>麻烦</th>\n",
              "      <th>默默</th>\n",
              "      <th>鼓励</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13268</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13269</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13270</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13271</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13272</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13273 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fde9d1c-4cdf-4067-9764-8bd5034ac594')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9fde9d1c-4cdf-4067-9764-8bd5034ac594 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9fde9d1c-4cdf-4067-9764-8bd5034ac594');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij5HL2T6oDzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9108159-b65a-439d-ca7f-1d4fd261b433"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "unigram_features = list(no_stopwords_df.columns[:-1])\n",
        "feature_set = unigram_features\n",
        "\n",
        "sorted_sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, no_stopwords_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.161\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.161.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lhQbSZQB-wm"
      },
      "source": [
        "# Domain Transfer\n",
        "\n",
        "Notice that in our multilingual example, the task of predicting sentiment on replies and posts seem quite related. For example, it seems reasonable that a model that is good at predicting the sentiment of a post may also be good at predicting the sentiment of its replies. This kind of training is called Domain Transfer or **Transfer Learning**. \n",
        "\n",
        "This technique can be very useful if you have only a small amount of data for the task that you care about, but a lot of data for some related (but slighlty different) task. It can also often save us time (and $$$) by allowing us to reutilize things that we have already trained for our new tasks! We will also see that it is possible to start training a model on one (large, but not as interesting) dataset and then finish its training on a different (small, but very interesting) dataset to achieve much better performance than would be possible with just the small dataset alone.\n",
        "\n",
        "[Here is a resource on Domain Transfer for image recognition that thoroughly explains Transfer Learning](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjsScR-7-Wne"
      },
      "source": [
        "## Baseline -- Training on both Posts and Replies\n",
        "\n",
        "Let's start by training a model on both the posts and replies to set a baseline for what our performance could be!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "172LH3nzCBpB"
      },
      "source": [
        "combined_content = segmented_posts + segmented_replies\n",
        "column_names, combined_unigram_df = ngrams(combined_content, vocab_size = 1000, min_n=1, max_n=1)\n",
        "\n",
        "combined_labels = list(zh_df[\"post_sentiment\"]) + list(zh_df[\"reply_sentiment\"])\n",
        "combined_unigram_df[\"sentiment\"] = combined_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNLfgzgZ1BlS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "774dfa77-25ee-4c59-ec26-ed71f30eedbf"
      },
      "source": [
        "combined_unigram_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       10  20  90  一下  一个  一些  一会  一切  一向  一定  ...  骗子  高中  高兴  高铁  魅力  麻烦  \\\n",
              "0       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "1       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "2       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "3       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "4       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
              "26541   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "26542   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "26543   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "26544   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "26545   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
              "\n",
              "       黑色  鼓励  鼻子  sentiment  \n",
              "0       0   0   0   Positive  \n",
              "1       0   0   0   Negative  \n",
              "2       0   0   0   Positive  \n",
              "3       0   0   0   Positive  \n",
              "4       0   0   0   Positive  \n",
              "...    ..  ..  ..        ...  \n",
              "26541   0   0   0   Negative  \n",
              "26542   0   0   0   Negative  \n",
              "26543   0   0   0   Positive  \n",
              "26544   0   0   0   Negative  \n",
              "26545   0   0   0   Positive  \n",
              "\n",
              "[26546 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-444c4d5c-45c3-4fc0-b928-eb55d799d822\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>90</th>\n",
              "      <th>一下</th>\n",
              "      <th>一个</th>\n",
              "      <th>一些</th>\n",
              "      <th>一会</th>\n",
              "      <th>一切</th>\n",
              "      <th>一向</th>\n",
              "      <th>一定</th>\n",
              "      <th>...</th>\n",
              "      <th>骗子</th>\n",
              "      <th>高中</th>\n",
              "      <th>高兴</th>\n",
              "      <th>高铁</th>\n",
              "      <th>魅力</th>\n",
              "      <th>麻烦</th>\n",
              "      <th>黑色</th>\n",
              "      <th>鼓励</th>\n",
              "      <th>鼻子</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26541</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26542</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26543</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26544</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26545</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26546 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-444c4d5c-45c3-4fc0-b928-eb55d799d822')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-444c4d5c-45c3-4fc0-b928-eb55d799d822 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-444c4d5c-45c3-4fc0-b928-eb55d799d822');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p_dfIwRE_j_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8425b311-b6dd-429a-cc2a-a02d9fcbbf97"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Complement NB\": ComplementNB()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "unigram_features = list(combined_unigram_df.columns[:-2])\n",
        "feature_set = unigram_features\n",
        "\n",
        "sorted_sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, combined_unigram_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complement NB: Fold 0...1...2...3...4...5...6...7...8...9\n",
            "Average Kappa: 0.595\n",
            "-------------\n",
            "Best classifier is: Complement NB \n",
            "With K=0.595.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shig_bSD-iMz"
      },
      "source": [
        "## Training with Transfer Learning\n",
        "Now lets see what happens when we train on posts and test on replies, or train on replies and test on posts. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8nwb7urAJnH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "d2d3d2e5-9a31-46d6-d55e-a99235ef5368"
      },
      "source": [
        "posts_df = combined_unigram_df.iloc[:len(segmented_posts)]\n",
        "replies_df = combined_unigram_df.iloc[len(segmented_posts)+1:]\n",
        "\n",
        "# Train on posts, test on replies\n",
        "X_train = posts_df.loc[:, feature_set]\n",
        "X_train = pd.get_dummies(X_train)\n",
        "y_train = posts_df[\"sentiment\"]\n",
        "\n",
        "X_test = replies_df.loc[:, feature_set]\n",
        "X_test = pd.get_dummies(X_test)\n",
        "y_test = replies_df[\"sentiment\"]\n",
        "\n",
        "classifier = ComplementNB()\n",
        "# Train and Evaluate Model\n",
        "model = classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "conf_matrix, model_metrics = evaluate(y_pred, y_test, metrics, model_name = \"Naive Bayes\")\n",
        "\n",
        "print(f\"Train on posts, test on replies:\")\n",
        "ConfusionMatrixDisplay(conf_matrix).plot(values_format='.4g')\n",
        "plt.show()\n",
        "print(model_metrics)\n",
        "print(\"------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on posts, test on replies:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 84.29776974080771, 'Kappa': 0.6809039060580736}\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data using post messages are highly predictive of reply sentiments, given the model accuracy of 84%. Further, the model generated a cappa of 0.681, which is > the baseline model kappa of 0.595. THus, high confidence in this model. "
      ],
      "metadata": {
        "id": "arMYYBhsKWAI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-eRWbfZGkKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cda272f-8b87-45bf-af28-ce5c12ecc2cb"
      },
      "source": [
        "# Train on replies, test on posts\n",
        "X_train = replies_df.loc[:, feature_set]\n",
        "X_train = pd.get_dummies(X_train)\n",
        "y_train = replies_df[\"sentiment\"]\n",
        "\n",
        "X_test = posts_df.loc[:, feature_set]\n",
        "X_test = pd.get_dummies(X_test)\n",
        "y_test = posts_df[\"sentiment\"]\n",
        "\n",
        "classifier = ComplementNB()\n",
        "# Train and Evaluate Model\n",
        "model = classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "conf_matrix, model_metrics = evaluate(y_pred, y_test, metrics, model_name = \"Naive Bayes\")\n",
        "\n",
        "print(f\"Train on replies, test on posts:\")\n",
        "ConfusionMatrixDisplay(conf_matrix, sorted_sentiments).plot(values_format='.4g')\n",
        "plt.show()\n",
        "print(model_metrics)\n",
        "print(\"------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 74.41422436525276, 'Kappa': 0.48661295958223705}\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "74% vs. ~84% \n",
        "\n",
        "why does this model perform not as well as the prior?\n",
        "\n",
        "1. post --- > informs replies (84%)\n",
        "2. reply --> the post (74%) \n",
        "\n"
      ],
      "metadata": {
        "id": "ZnWFbGlxKqpQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgEAbfoJCRwj"
      },
      "source": [
        "Notice that our performance on our test sets is almost identical to our initial results. That is to say that the model trained on posts and the model trained on replies both perform similary well when tested on posts! In fact our model trained on replies actually performs better on the posts than our model trained on posts. This is the amazing power of transfer learning when our models are generalizing well. \n",
        "\n",
        "| Train   | Test    | Kappa          |\n",
        "|---------|---------|----------------|\n",
        "| Posts   | Posts   | 0.475          |\n",
        "| Replies | Posts   | 0.487 (+0.012) |\n",
        "| Replies | Replies | 0.699          |\n",
        "| Posts   | Replies | 0.681 (-0.018) |\n",
        "| Both    | Both    | 0.595          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8MKaqQaCLzE"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "The final word representation we will look at in class is \"word embeddings.\" These representations are currently considered the state of the art in natural language processing. The ones we will be looking at are relatively simple embeddings, but there are also much more sophisticated embedding techniques. The main idea behind word embeddings, is that we want to take a set of words and put them into a coordinate grid such that words that are close together tend to have similar meaning. T\n",
        "\n",
        "his way, when we look at the words in our sentence, we can have a more sophisticated representation of what ideas are contained in the sentence. For example, in a BOW type model like those we have used up until now, the words \"cat\" and \"dog\" are just as different as the words \"cat\" and \"car\". Using word embeddings, we can remedy this as we are able to put similar concepts like \"cat\" and \"dog\" closer together in the space than more differening concepts like \"cat\" and car\"\n",
        "\n",
        "![](https://www.ibm.com/blogs/research/wp-content/uploads/2018/10/WMEFig1.png)\n",
        "\n",
        "Let's see what the embeddings for a piece of text would look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Urlgt2OUanl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc3390d-aa21-4881-855d-2a93e9ccc7d4"
      },
      "source": [
        "# First lets embed all the sentences in our dataframe\n",
        "nlp = spacy.load('en_core_web_md', disable=[\"parser\", \"ner\"])\n",
        "%time all_tagged = df.apply(lambda x: tokenize(nlp, x), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.6 s, sys: 86.4 ms, total: 17.7 s\n",
            "Wall time: 17.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEkOZVRyXkqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51087680-6b63-4b2f-8106-791504dcb9ad"
      },
      "source": [
        "# Let's see what the embedding of a sentence looks like\n",
        "first_row = all_tagged.iloc[0]\n",
        "print(first_row)\n",
        "\n",
        "for token in first_row:\n",
        "    vector = \" \".join([f\"{x:.4f}\".rjust(8) for x in token.vector])\n",
        "    line = f\"{token.text.ljust(10)} {vector}\"\n",
        "    print(line)\n",
        "print(\"----\")\n",
        "row_vector = \" \".join([f\"{x:.4f}\".rjust(8) for x in first_row.vector])\n",
        "print(f\"{'Row:'.ljust(10)} {row_vector}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What did you think of the last couple elections?\n",
            "What        -0.0385   0.5425  -0.2184  -0.1885   0.0730   0.1318  -0.1040   0.1723  -0.0516   2.8646  -0.2513  -0.1915   0.0800   0.0729  -0.1321  -0.2297  -0.1727   0.8351  -0.3849  -0.3249   0.4668  -0.1568   0.1071  -0.1248  -0.1603  -0.0052   0.0152   0.1651   0.0980  -0.0919   0.0002   0.4425   0.1605   0.1221   0.1259   0.3200   0.2204   0.1687  -0.3893  -0.1735  -0.1316   0.0798  -0.0581  -0.0722   0.2803   0.0061  -0.3929   0.0006  -0.0334   0.0076  -0.0937   0.1893  -0.2254  -0.0181   0.2955  -0.1516  -0.1559  -0.2194   0.0883  -0.0655  -0.0630  -0.1999  -0.0049   0.2957   0.2733  -0.3621  -0.0405   0.2204   0.0847   0.0063   0.1691  -0.2004   0.5165  -0.1191   0.0787   0.2683   0.0670  -0.2512  -0.2414   0.4813   0.1545   0.1154  -0.0983  -0.0684   0.1667  -0.4169  -0.2254  -0.8746   0.3082   0.0900  -0.3689  -0.1738  -0.4174   0.2626   0.3596   0.1332   0.0128  -0.3858  -0.0295   0.1443  -0.1437  -0.0173   0.1627  -0.0708   0.1532  -0.9761   0.0283  -0.0176  -0.3347   0.1176  -0.0713  -0.3527   0.1614  -0.1937   0.1747   0.0803  -0.2298  -0.0520   0.1948  -0.1375   0.0976  -0.3326  -0.0643   0.1456   0.2016   0.0831  -0.2156  -0.5359   0.1485  -0.1851  -0.0900  -0.1106   0.1273   0.0768   0.1277   0.1017  -0.1150  -0.0629   0.2018  -0.1443  -1.9059   0.0524  -0.0024   0.2419   0.0150  -0.3489  -0.1043   0.3644  -0.3756   0.0360  -0.0107  -0.1961  -0.2270  -0.2476   0.1504  -0.0994  -0.1782  -0.0820  -0.3121   0.1589  -0.5210   0.4406  -0.1629  -0.1244   0.0748  -0.0500   0.1941   0.0009   0.2803  -0.0058  -0.2251  -0.1986   0.1392  -0.3518  -0.0380   0.1247  -0.1737   0.2380   0.0608   0.1350   0.2115  -0.1310   0.0481   0.0040  -0.0998   0.1858   0.0086  -0.1788   0.0899   0.2348   0.1664   0.1104  -0.2420  -0.2159  -0.0931   0.1888  -0.1083  -0.1414   0.2766   0.3234  -0.1408  -0.0246  -0.2017  -0.1864   0.0290  -0.0051   0.3512  -0.0121   0.2374   0.1133  -0.1799  -0.3357  -0.0934  -0.2122   0.0454   0.0496  -0.2172   0.0199  -0.2778  -0.2020   0.1225   0.2078  -0.1395   0.0665   0.1237   0.1749  -0.0373   0.2327  -0.0134   0.0198  -0.3271   0.1408  -0.0508   0.0912  -0.2337  -0.0998   0.2038   0.0263  -0.1251   0.4231   0.0734   0.0096   0.1203  -0.0096   0.2306  -0.2319   0.2072  -0.2347  -0.1143   0.1451   0.3921  -0.2747  -0.0485  -0.2938  -0.1733   0.2594   0.1662  -0.1104   0.2943   0.1519   0.1778   0.1129  -0.0202   0.0948   0.1293  -0.0636  -0.1058   0.2307   0.6661   0.3429  -0.0631   0.0655  -0.0446  -0.2665  -0.1860  -0.0661   0.1700   0.0206   0.0443   0.2551  -0.1321  -0.0651  -0.0631  -0.0930  -0.1483  -0.0666   0.2224  -0.2549   0.2124  -0.0231  -0.1561   0.0094  -0.0485  -0.0473   0.3489  -0.1201  -0.4057   0.1180   0.2459   0.2287\n",
            "did         -0.0689   0.3877  -0.2612  -0.1374  -0.2154   0.1658  -0.0572  -0.1818  -0.0914   3.0152   0.0080  -0.1468   0.5970   0.1385  -0.3847  -0.1823  -0.0481   0.1923  -0.3983  -0.0694   0.4431   0.0395   0.1225  -0.0096  -0.2765   0.0520  -0.2032  -0.2484   0.1810  -0.1460  -0.1889   0.2950   0.0332   0.0171  -0.0510  -0.1042  -0.0834  -0.0370  -0.3156  -0.2516  -0.0788   0.3288   0.0048  -0.1703   0.2523  -0.0439  -0.3515   0.0447   0.3054   0.0063  -0.1320  -0.0035   0.2359   0.0806   0.3226  -0.1158  -0.0798  -0.2116   0.0322  -0.0238  -0.0610  -0.2438   0.0928   0.5942   0.0503  -0.0766   0.0245   0.0634   0.5216   0.1461   0.3927   0.4053   0.1003  -0.0421   0.2265   0.1274  -0.0407  -0.2157  -0.0740   0.2061   0.0524  -0.0537  -0.0685  -0.1987   0.0328  -0.2159   0.2442  -0.8876   0.0797   0.1556  -0.1721  -0.1321  -0.2930   0.3066   0.6804  -0.1078   0.3552  -0.0405   0.0567   0.2351  -0.1862   0.3634   0.1102  -0.1939   0.1094  -0.6123   0.1075  -0.2737  -0.0572  -0.0144   0.0652   0.0404   0.0997  -0.2032   0.2475  -0.3864   0.4165  -0.0220   0.0285   0.0375   0.3015  -0.1955   0.2161  -0.0022  -0.0915   0.1305  -0.2567  -0.4182   0.0530   0.1238   0.1844   0.1325  -0.1496   0.1143   0.3248  -0.0697   0.1082   0.1311  -0.0184  -0.1202  -2.0446  -0.0064   0.1815  -0.0537   0.1800   0.0451  -0.4919   0.0718  -0.1336  -0.1568   0.0438   0.0356   0.0935   0.1150  -0.0709  -0.3731  -0.1670  -0.1722   0.2472   0.0586  -0.3815   0.0267  -0.3503  -0.1229  -0.3139  -0.0838  -0.1386  -0.1509   0.1795  -0.0426  -0.1230  -0.0674  -0.0171  -0.4689  -0.2708   0.0130  -0.0317   0.0770   0.0445  -0.3408  -0.1318  -0.1147  -0.4665  -0.0066   0.0741  -0.0287  -0.0840   0.1219   0.0848   0.1919   0.2907   0.1082  -0.4806  -0.0244   0.0806   0.1665   0.0704  -0.3451   0.1812   0.2564  -0.2028  -0.0139  -0.0510  -0.3456   0.2545   0.0756   0.2493  -0.2138   0.4252   0.3174   0.3478   0.1107  -0.0099  -0.1273   0.0853   0.0483  -0.1887  -0.2086  -0.0854   0.0105   0.2570   0.0986  -0.1566   0.1326  -0.0970   0.3729   0.0421   0.0015  -0.0868   0.0605  -0.2396   0.0802   0.0743   0.1583  -0.2059  -0.1787   0.2643  -0.1201   0.0562   0.1692  -0.1106  -0.0294  -0.0383   0.3230   0.1342  -0.3103  -0.1320  -0.0451  -0.4583   0.4171   0.1885  -0.1479  -0.3806  -0.2004   0.0494  -0.2728  -0.0972   0.0121   0.1053   0.1631   0.4171   0.2011  -0.0760   0.1109   0.1983   0.2892   0.1226   0.1584   0.1357   0.4910   0.5289   0.1957   0.2702  -0.1866  -0.2961   0.1265  -0.2061  -0.3081  -0.0876   0.3407   0.0238   0.1035   0.1505   0.2493  -0.1851  -0.0632   0.1456   0.2244   0.1684   0.0919  -0.2343   0.1956   0.1604   0.2012   0.3391  -0.2631  -0.1453   0.1930   0.3753   0.1458\n",
            "you         -0.1108   0.3079  -0.5198   0.0351   0.1037  -0.0525  -0.1802  -0.1184  -0.0543   2.4980  -0.3024   0.0432  -0.0959  -0.0935  -0.1982  -0.2660  -0.3470   1.4518  -0.4901   0.0416   0.1119  -0.0190  -0.1872  -0.1041  -0.4367   0.0736   0.0195  -0.1501   0.1850  -0.2436   0.2033   0.2892  -0.2169   0.2835  -0.1009  -0.0422  -0.0735   0.2733  -0.1290  -0.0594  -0.0733   0.0125  -0.2046  -0.4456   0.0409   0.2459  -0.2611  -0.0868   0.1363   0.1109  -0.1084   0.0099   0.1739   0.0065   0.2747  -0.0097   0.1656  -0.1698  -0.1256  -0.0717  -0.0568  -0.2863  -0.2423   0.2782   0.2411  -0.0091  -0.0536   0.4391   0.3900   0.1252  -0.0636   0.0581   0.5919  -0.1839   0.0902   0.1379   0.4105  -0.3903  -0.0717   0.3794   0.0313  -0.0036  -0.2577  -0.0486   0.1952  -0.2991   0.0472  -0.1358   0.6725  -0.0830  -0.1968   0.0741   0.1783   0.2010  -0.0364   0.0278  -0.3214  -0.2962  -0.1326   0.3038   0.0542   0.0700   0.1194   0.0467   0.3734  -0.6381   0.3387  -0.0919  -0.1264   0.0685   0.1198  -0.2251   0.5607  -0.0350   0.3647  -0.2688  -0.0048   0.0641  -0.2876  -0.0237   0.2135  -0.4122  -0.1296   0.0510   0.4208  -0.0863  -0.1003  -0.2602   0.0097   0.0643   0.1080  -0.0951  -0.1280   0.0550   0.0606  -0.0372  -0.1978  -0.1224  -0.1685  -0.0985  -1.8562   0.3119  -0.3085  -0.0988  -0.0020  -0.2941   0.0782   0.1801  -0.0279  -0.0496   0.0720   0.1679  -0.0331  -0.0797  -0.0977   0.2612   0.1159  -0.2564  -0.0890  -0.0248  -0.1081   0.2035  -0.2090   0.1804   0.3965  -0.1312   0.4669  -0.0531   0.0148   0.0591  -0.0846  -0.0586   0.3468  -0.2600   0.0523   0.1928  -0.2736  -0.1086  -0.0301   0.3508   0.2009   0.0874  -0.1240   0.0209   0.0416  -0.0267  -0.0253  -0.3498  -0.0780   0.1718  -0.0629  -0.0748   0.0458  -0.2733   0.2305   0.1906  -0.2064  -0.0392   0.3391   0.5225  -0.1086  -0.3047  -0.0533  -0.2677  -0.0043   0.2392   0.2228  -0.0533   0.2020  -0.0842   0.1037  -0.3509  -0.1996   0.0109   0.2632   0.3409  -0.0686   0.2058  -0.5276  -0.0848   0.1106   0.0213   0.0633   0.0942   0.2028  -0.1589  -0.0106   0.2577  -0.2323  -0.2373  -0.1544   0.1391   0.0863   0.3844  -0.2563   0.0318   0.0803  -0.4068  -0.5116   0.2698   0.4131   0.0571   0.0547  -0.0608   0.1947  -0.3826  -0.0441  -0.0367  -0.3972   0.5578   0.0699  -0.2152  -0.0911   0.0336  -0.1633   0.4209   0.0191  -0.2188   0.2753   0.2368   0.0942   0.0385   0.2238  -0.1199   0.2320  -0.0884  -0.0147   0.6575   0.5939   0.2457   0.0248  -0.3151  -0.1547   0.0006  -0.0423   0.0817   0.0301   0.0701   0.0871  -0.0796  -0.0083  -0.1440   0.0390  -0.0954   0.2760  -0.3907   0.4444  -0.3547   0.2331  -0.0068  -0.1889   0.2784  -0.3850  -0.1141   0.2819  -0.3095  -0.2188  -0.0591   0.4760   0.0566\n",
            "think       -0.2179   0.4413  -0.4320  -0.1980  -0.0028   0.2880   0.0806  -0.1464   0.0223   2.5941  -0.2596  -0.0842   0.4261   0.0088  -0.3384  -0.1781  -0.4216   0.3376  -0.3909  -0.0605   0.2952   0.1459   0.3285  -0.0581  -0.1998   0.1173  -0.3083  -0.2265   0.4743  -0.2441  -0.3018   0.6739   0.0660   0.0459  -0.0366   0.0999   0.1366   0.1636  -0.1711  -0.2456  -0.1254   0.2183  -0.1503   0.1334   0.3397   0.0941  -0.5132  -0.1582   0.0275  -0.0344  -0.0559   0.0696  -0.0123  -0.0518   0.2722  -0.1836  -0.2456  -0.3137   0.1562   0.0630  -0.3211  -0.5191  -0.1171   0.3682   0.0405  -0.4388  -0.0839   0.0951   0.3200   0.0521   0.2389  -0.0017   0.3196  -0.0687   0.1348   0.3289   0.0272  -0.1957  -0.1052   0.4354   0.0189  -0.0246   0.0950  -0.1018   0.2224  -0.4000   0.0773  -0.8712   0.3365  -0.2346  -0.1706  -0.1616  -0.2160   0.4320   0.2224   0.0542   0.2443   0.0836   0.0097   0.1631  -0.1786  -0.0785  -0.0326  -0.1327   0.4189  -0.7790  -0.2127  -0.2818  -0.3626   0.2797   0.0511  -0.4379  -0.0662  -0.2901   0.0989   0.0687  -0.1795  -0.2452   0.0624  -0.1834   0.2385  -0.3893   0.0146  -0.1501   0.4146   0.2352   0.1577  -0.4234  -0.0600  -0.0855  -0.1964   0.1624   0.0139   0.0359   0.1509  -0.1206   0.0025  -0.3290   0.1125  -0.1148  -2.2095   0.2136   0.0144   0.3308  -0.0732  -0.3316  -0.3412   0.1946  -0.2511  -0.2999  -0.0232  -0.0460  -0.0801   0.0891   0.0527  -0.0955   0.0203  -0.3470  -0.1308   0.0500  -0.3368   0.2743  -0.4586  -0.0509  -0.2458  -0.0996   0.2753  -0.2278   0.1167  -0.0929  -0.1319  -0.2056   0.0679  -0.4649   0.0898  -0.0165  -0.1485   0.1838   0.1978  -0.0860   0.0906  -0.0849  -0.3760  -0.1986  -0.0121   0.0128   0.0777  -0.1206   0.1135   0.2914   0.1085   0.1350  -0.2952  -0.3090   0.1116  -0.0411  -0.0768  -0.2687   0.0918   0.3364   0.1992  -0.1850  -0.1046  -0.3059   0.1587   0.0926   0.0212  -0.1878   0.2008   0.2451  -0.2270  -0.2114   0.0199  -0.4044   0.2558   0.2239  -0.2264  -0.0747  -0.2803  -0.1151   0.1274   0.1972   0.0319   0.0355   0.1659   0.1023   0.2490   0.1035  -0.0430  -0.0819  -0.4342   0.1039  -0.0168   0.1612   0.0743  -0.0993   0.1898  -0.1275  -0.0601   0.4901   0.1055  -0.0604   0.0202   0.5383  -0.0711  -0.1446   0.0864  -0.0520  -0.3214   0.4957   0.2908  -0.2832  -0.1619   0.0103  -0.3650  -0.0453  -0.1715  -0.0569   0.1699   0.1871   0.4005   0.2449   0.1218   0.3425   0.1589   0.0802  -0.1165   0.3386   0.4571   0.5096  -0.1744  -0.0119  -0.0942  -0.4201  -0.2294   0.0841   0.1892  -0.3554  -0.1774   0.3441  -0.1980  -0.2346   0.0237  -0.0427   0.0731  -0.0211   0.3032  -0.2912   0.0831   0.0348  -0.1508   0.0275  -0.2794   0.0385   0.2200   0.1821  -0.5075  -0.1647   0.3225   0.3058\n",
            "of           0.0602   0.2180  -0.0425  -0.3862  -0.1539   0.0346   0.2224   0.2172   0.0068   2.4375  -0.2742   0.1357   0.3109  -0.0632   0.0004  -0.1860  -0.1933   1.4447  -0.3854  -0.2855   0.0756  -0.0368  -0.4607  -0.0168   0.1982  -0.0927   0.1895  -0.0003  -0.1708   0.5036   0.4626   0.2690  -0.1226   0.2471   0.0693  -0.2078  -0.4456   0.3022  -0.0098   0.3277   0.1104   0.4127  -0.1585  -0.0570   0.3892  -0.2116  -0.1331   0.4041   0.1749   0.0539   0.1098  -0.1848  -0.0540   0.0401  -0.1018   0.1266   0.0697  -0.2407  -0.2100  -0.0514   0.2822   0.1860  -0.5018   0.2757  -0.1850  -0.1840   0.1570  -0.0384  -0.5224   0.2275   0.0487  -0.0788   0.0654   0.1840   0.4021  -0.1275  -0.1230   0.3107   0.0996   0.0360  -0.2595   0.3613   0.1275  -0.1867   0.1650  -0.3912  -0.6755   0.1129   0.0407   0.0350  -0.0409  -0.0398  -0.4054  -0.0159   0.1024   0.0469  -0.0828   0.0151  -0.1490  -0.2512   0.2524  -0.1185  -0.3413   0.0165   0.3040  -0.5410   0.3050   0.3907   0.4236  -0.4172  -0.0542  -0.2601  -0.1405  -0.1417  -0.0211   0.0508  -0.0781   0.4592   0.1760  -0.0157   0.0912   0.0343  -0.4999   0.0286   0.1207   0.1978  -0.0130  -0.2242   0.1250   0.1465  -0.2308   0.2199  -0.0593  -0.0882  -0.1252   0.0075  -0.2242   0.6214   0.2009  -0.0290  -0.6507   0.0054  -0.1207   0.2099  -0.1684   0.0418   0.0546   0.3525   0.2006   0.0319  -0.0533  -0.4401   0.2250  -0.3062  -0.3286  -0.0158  -0.1391   0.3431  -0.1357  -0.2228   0.1429   0.0550  -0.1062   0.2360  -0.2070  -0.3096   0.1353  -0.1614   0.2911   0.1230   0.2365  -0.2615   0.3102   0.2061  -0.1989   0.1097  -0.0018   0.1462   0.1518  -0.4468   0.0067  -0.0288   0.1382  -0.1657  -0.4552   0.0166   0.1070  -0.4840   0.0400   0.0496  -0.2645  -0.1468   0.1365   0.1526   0.0675   0.5041  -0.1885   0.1526  -0.2700   0.0556   0.0471  -0.1785  -0.3357  -0.0315   0.1911   0.1882   0.1878   0.1831  -0.3640  -0.0054  -0.1576   0.1639  -0.0848  -0.1984  -0.4045   0.4103  -0.4139   0.0298   0.1054  -0.1129  -0.0681  -0.2237  -0.1908  -0.0803  -0.3835   0.0647   0.2311   0.2141   0.2804   0.1422  -0.2070   0.0159  -0.1411   0.0899  -0.2153  -0.0201   0.2270   0.0834  -0.2958   0.0180   0.1989   0.1779   0.1369  -0.1030   0.0297   0.0513  -0.1479  -0.4182   0.0198  -0.2639  -0.0747  -0.0157   0.4809   0.1249  -0.1141   0.5813   0.0958  -0.0959  -0.0574   0.1388   0.1031   0.0814  -0.4669   0.5070   0.0217  -0.0716  -0.0638  -0.1115   0.6179  -0.5633   0.0236   0.1804  -0.2578  -0.5096   0.1474  -0.0333  -0.0371   0.2406   0.1264  -0.0271   0.4039  -0.0284  -0.0222  -0.1149  -0.2285  -0.0575   0.2952  -0.2191  -0.1331  -0.2365  -0.4248   0.1161   0.0048  -0.3963  -0.2682   0.3292  -0.1760   0.1171  -0.1669  -0.0941\n",
            "the          0.2720  -0.0620  -0.1884   0.0232  -0.0182   0.0067  -0.1388   0.1771   0.1771   2.5882  -0.3518  -0.1731   0.4329  -0.1071   0.1501  -0.1998  -0.1909   1.1871  -0.1621  -0.2354   0.0037  -0.1916  -0.0857   0.0392  -0.0664  -0.0421  -0.1912   0.0117  -0.3714   0.2189   0.0011   0.4319  -0.1420   0.3806   0.3065   0.0202  -0.1832  -0.0065  -0.0081  -0.1206   0.0275   0.2984  -0.2290  -0.2288   0.1467  -0.0763  -0.1268  -0.0067  -0.0528   0.1426   0.1561   0.0555  -0.1615   0.0963  -0.0765  -0.0500  -0.0102  -0.0476  -0.1668  -0.2394   0.0050  -0.0492   0.0133   0.4192  -0.1010   0.0151  -0.0777  -0.1347   0.1190   0.1080   0.2106  -0.0519   0.1853   0.1786   0.0413  -0.0144  -0.0826  -0.0355  -0.0762  -0.0454   0.0893   0.3367  -0.2210  -0.0067   0.2398  -0.2315  -0.8859   0.0913  -0.0121   0.0132  -0.2580  -0.0297   0.0168   0.0137   0.3238   0.0395   0.0421  -0.0882   0.3032   0.0877   0.1635  -0.4049  -0.0438  -0.0407   0.2094  -0.7779   0.2997   0.2334   0.1489  -0.3904  -0.0531   0.0629   0.0657  -0.1391   0.0942   0.1034  -0.2797   0.2891  -0.3216   0.0207   0.0633  -0.2326  -0.4352  -0.0170  -0.3274  -0.0471  -0.0751  -0.1879  -0.0150   0.0293  -0.3527  -0.0443  -0.1351  -0.1164  -0.1043   0.1392   0.0039   0.3760   0.0672  -0.3799  -1.1241  -0.0574  -0.1683   0.0394   0.2604  -0.0239   0.1796   0.1355   0.2139   0.0526  -0.2503  -0.1131   0.2223   0.0666  -0.1116   0.0624  -0.2797   0.1988  -0.3626  -0.0000  -0.1726   0.2917  -0.1572   0.0543   0.0610  -0.3916   0.2766   0.0578   0.3971   0.0252   0.2467  -0.0891   0.1568  -0.2096  -0.2220   0.0524  -0.0114   0.0504  -0.1402  -0.0428  -0.0319  -0.2134  -0.2040  -0.2327   0.0745   0.0882  -0.1106  -0.3353  -0.0140  -0.2943  -0.0869  -0.1321  -0.4362   0.2051   0.0079   0.4850   0.0642   0.1426  -0.4371   0.1278  -0.1311   0.2467  -0.2750   0.1590   0.4331   0.0903   0.2466   0.0665  -0.2010   0.1101   0.0364   0.1736  -0.1569  -0.0863  -0.1732   0.3697  -0.4032  -0.0648  -0.0342  -0.0138   0.0629  -0.1718  -0.1237  -0.0347  -0.2279  -0.2317   0.2390   0.2747   0.1533   0.1066  -0.0610  -0.0248  -0.1348   0.1793  -0.3737  -0.0289  -0.1114  -0.0839  -0.0559   0.0680  -0.1078   0.1465   0.0946  -0.0846   0.0674  -0.3291   0.0341  -0.1675  -0.2600  -0.2292   0.0202  -0.0276   0.1614  -0.1854   0.0377   0.5760   0.2068   0.2794   0.1648  -0.0188   0.1206   0.0696   0.0590  -0.2315   0.2410  -0.3471   0.0485  -0.0565   0.4157  -0.4319   0.4823  -0.0518  -0.2729  -0.2589   0.1655  -0.1831  -0.0673   0.4246   0.0103   0.1424   0.2594   0.1712  -0.1382  -0.0668   0.0160  -0.3019   0.0436  -0.0431   0.3503  -0.1968  -0.4281   0.1690   0.2251  -0.2856  -0.1028  -0.0182   0.1141   0.1302  -0.1832   0.1323\n",
            "last         0.0920   0.4174   0.1325  -0.0137  -0.0225  -0.1224  -0.1579  -0.1335   0.0362   2.8564  -0.1936   0.0260   0.3172  -0.2427  -0.1041   0.0780   0.0976   0.2815   0.1606   0.0734   0.0211   0.1629   0.4635   0.2277  -0.0305   0.3830  -0.4848  -0.2914  -0.0683   0.3640  -0.1672  -0.2608   0.1477  -0.0596  -0.1559   0.6140  -0.0105   0.0076  -0.0320  -0.0727  -0.0801   0.2308   0.1055   0.0036  -0.1056   0.2091  -0.3025  -0.0313   0.2894  -0.2737  -0.1484   0.1611   0.0939   0.0494  -0.0333   0.0874   0.1145   0.1595   0.3745  -0.2854   0.0107  -0.2455  -0.2448   0.4195   0.1171   0.0712  -0.0579  -0.1866   0.0807   0.4548   0.5481  -0.0154  -0.0317   0.1875   0.2598   0.2872   0.1329  -0.0467  -0.1975   0.2270   0.0966   0.3675  -0.0509  -0.2112  -0.1808   0.0094  -0.0409  -0.4576   0.3356   0.3834   0.2390   0.0556  -0.0664  -0.0431   0.1497  -0.0347   0.4463   0.3364   0.5153   0.1779  -0.0936   0.0487  -0.0323  -0.2397  -0.1961  -0.3308   0.3250  -0.1226   0.1796  -0.0907  -0.0299  -0.5452   0.1808   0.1979  -0.1994   0.0435  -0.1331   0.3913   0.3663  -0.1988   0.1635   0.2869  -0.1327   0.0115  -0.1144   0.0155  -0.3611  -0.2343  -0.0491   0.1707   0.1579  -0.0707   0.0994   0.2003   0.1054  -0.2827   0.1683   0.4700   0.0821  -0.1520  -1.6455   0.1276   0.1947   0.1686   0.2346  -0.0311  -0.6989   0.1355   0.0842   0.0782  -0.2294  -0.2114   0.0884   0.3263  -0.1559  -0.4763  -0.1442   0.3309   0.0131  -0.1061  -0.2513  -0.0339  -0.1459  -0.5911  -0.5296   0.1712  -0.1849   0.0856   0.2621   0.2178   0.0837   0.1497  -0.4371   0.1424  -0.5298   0.1170   0.1413  -0.2895  -0.1706   0.0542  -0.1488  -0.0818  -0.3482   0.0739   0.1702  -0.2490  -0.1347   0.2354  -0.0605  -0.2026   0.2007   0.5210  -0.0746   0.5103   0.3601   0.1665   0.0043  -0.1497  -0.3420   0.0238  -0.0440  -0.1594  -0.0576   0.3457   0.4554   0.0118  -0.1219  -0.0794  -0.1542   0.4502   0.0905  -0.0637   0.0323  -0.4822  -0.0793   0.0998   0.1495  -0.3588  -0.3266   0.2244   0.0732  -0.0999  -0.3019   0.3288  -0.2237   0.0450  -0.0597   0.1933   0.0073   0.2308   0.2851   0.4395   0.0415   0.1367  -0.3105  -0.5354  -0.2221  -0.0719  -0.1061  -0.3765  -0.3000  -0.2256  -0.1620   0.3241  -0.0886  -0.2525   0.1994   0.2862  -0.0270   0.0516  -0.3338   0.0655   0.0141  -0.1154   0.0882   0.2649  -0.0885   0.0339  -0.1873   0.0281   0.3669   0.2429  -0.3099   0.1823   0.0174  -0.3498   0.0367   0.0124   0.0084  -0.1732   0.4507  -0.1656  -0.0033  -0.2873  -0.2215   0.0478  -0.2157   0.0820   0.5613   0.2162   0.2691  -0.0802  -0.2137  -0.1160  -0.0321  -0.1647   0.0944  -0.2389   0.1638   0.4911  -0.0960   0.0775   0.1067  -0.0224   0.1512  -0.2359  -0.2954   0.1453  -0.0721  -0.0921\n",
            "couple       0.1355  -0.2540  -0.5733   0.0554   0.3350   0.0230  -0.3870  -0.5381   0.4621   2.4892  -0.1652   0.1263   0.2475  -0.4551  -0.4524   0.0781  -0.0635   0.5663   0.1744   0.3488  -0.4115  -0.0621  -0.1434  -0.2050  -0.0272  -0.0133  -0.2055  -0.1087   0.1963  -0.0986  -0.1700   0.1271   0.2951   0.1114   0.2614   0.1376   0.1840  -0.2525   0.0749  -0.1966  -0.0882  -0.0512   0.1848   0.1248  -0.2322   0.4550   0.2413  -0.1656   0.0508  -0.1321  -0.1835   0.0075  -0.0395  -0.1782  -0.6425  -0.1235   0.0211   0.0164   0.2668   0.1527   0.4117  -0.4165  -0.2840   0.4092   0.1043  -0.0530   0.0078   0.3292  -0.1154   0.3937   0.2151  -0.0176  -0.0786   0.4368   0.4403   0.0944   0.0095  -0.4255  -0.0231  -0.1233   0.1920  -0.1446  -0.1100  -0.2781  -0.3493   0.1938   0.1345   0.2910   0.3387   0.0575   0.0555  -0.1205  -0.1485  -0.3060   0.1218   0.3581   0.1536   0.0343   0.1343   0.1822  -0.2616   0.1702   0.1758   0.1340   0.2334  -0.6821   0.2459  -0.0156   0.1416  -0.0845   0.4149  -0.7191   0.0990   0.2849   0.1154  -0.1524   0.0317   0.3819   0.0228   0.3376   0.1049  -0.2555  -0.3302  -0.1738   0.3199   0.3892  -0.1229   0.1012  -0.0058   0.0361  -0.3812   0.4603   0.0127   0.0451   0.0978  -0.1206   0.1307   0.5538   0.0374   0.1586  -2.2195  -0.0973   0.3964   0.1407  -0.0832  -0.1652  -0.9317  -0.0035  -0.0335  -0.1950  -0.1848   0.1184  -0.3570  -0.0905  -0.3072  -0.3004   0.1253   0.4447  -0.1715  -0.1739  -0.2720   0.0344   0.0436  -0.2652  -0.2089  -0.0821  -0.3517   0.0803   0.2437   0.0097  -0.2925  -0.0120   0.0490   0.4210  -0.3406  -0.2956  -0.2426  -0.1935   0.3891  -0.2262  -0.0374  -0.1414  -0.0390  -0.0317  -0.1038  -0.0438  -0.3320  -0.2865  -0.0862  -0.0845   0.1078   0.2853  -0.1977   0.0922   0.1390  -0.0992  -0.5261   0.0245  -0.2260  -0.2567  -0.2022  -0.2880  -0.0556  -0.3241  -0.2744   0.1596  -0.1338  -0.0757   0.0377   0.2429  -0.1492  -0.0576  -0.1294  -0.2518  -0.3163   0.0275  -0.0886  -0.1160   0.1466  -0.0452  -0.0469  -0.1300   0.0675   0.4702   0.1662  -0.0511   0.2093  -0.3098  -0.0241   0.1114   0.2183   0.1248   0.3216   0.4278   0.6864  -0.4051   0.0495   0.3178   0.1517   0.2924   0.0153   0.1444  -0.1880   0.1268   0.1230   0.1001  -0.2068   0.1533   0.1587   0.2707  -0.2924  -0.1112  -0.0151   0.0826  -0.0228   0.1261   0.0385  -0.1154   0.1272   0.1104   0.4054   0.3568  -0.1011   0.1686   0.1243   0.2354   0.3775   0.1777  -0.2483  -0.0607  -0.5103  -0.1378  -0.2643  -0.4348  -0.1884   0.1400  -0.1551  -0.1736   0.1110   0.6227   0.0111   0.0086  -0.1412  -0.0704   0.1549   0.1526  -0.0206  -0.2914  -0.2155   0.3675  -0.3812  -0.1052   0.2463   0.0658   0.0505  -0.1823   0.0921  -0.4823   0.0475  -0.2436\n",
            "elections   -0.4253  -0.1441   0.9718   0.3372  -0.2717  -0.0269  -0.3967   0.4855   0.0547   3.1228  -0.4101   0.1067  -0.0650  -0.4062  -0.6370   0.1574  -0.1798  -0.3889  -0.1418   0.4404   0.4334  -0.2458   0.2582  -0.3101   0.5539  -0.1586  -0.7517   0.0303   0.0059  -0.0455   0.1484  -0.3834  -0.0828  -0.5359   0.1324   0.3890   0.2753  -0.1093  -0.3735  -0.2604  -0.1862   0.4324   0.3726   0.3456   0.0823  -0.0484   0.0928   0.1998  -0.1885  -0.6358  -0.0750   0.6415  -0.0952  -0.0908   0.0822   0.2916   0.2540   0.1334   0.1556  -0.1335  -0.3588   0.6862  -0.1599   0.0621   0.1268   0.7035  -0.5014  -0.1201  -0.0515  -0.3033   0.4466   0.1970   0.0299   0.0846   0.6168   0.1247  -0.5081   0.1176  -0.0692   0.3097  -0.2595   0.1454  -0.1231   0.1316  -0.1646   0.4767  -0.3178  -1.0790   0.4878   0.1901   0.4916   0.0829  -0.0490   0.4908   0.1312  -0.2392  -0.0664   0.2277  -0.2102  -0.1871   0.2353   0.1060   0.1577  -0.4981   0.2603  -1.4900  -0.2864  -0.3373  -0.0218   0.7122  -0.6065   0.1502  -0.3713   0.0214  -0.1846  -0.4050  -0.0158  -0.1372  -0.4164  -0.3266  -0.8965   0.3899  -0.2372   0.8688  -0.2776  -0.0346   0.9768   0.2734  -0.2922   0.3845  -0.4004   0.1840   0.4179  -0.7694   0.3684   0.4505   0.1986   0.6293   0.1101   0.3225   0.0032   0.1941   0.4030  -0.2071   0.6528  -0.0004  -0.3179   0.2432   0.1048   0.5810   0.3074  -0.2722  -0.4033   0.1579   0.3600   0.5781   0.3858  -0.0519  -0.2557   0.1723   0.1454   0.0228   0.1306   0.3227  -0.9707   0.0123  -0.1147  -0.3767   0.3091   0.0834   0.3790   0.2877  -0.0993   0.3179  -0.3195  -0.1922   0.0605  -0.2014   1.0059   0.2542  -0.0352  -0.1628  -0.5821  -0.6247   0.9594   0.3195   0.5092  -0.2240  -0.1378   0.3135   0.0825  -0.5075   0.3697  -0.1927   0.9747   0.2218  -0.3460   0.2159  -0.5310   0.4279   0.3401   0.9617   0.3919  -0.0915   0.3596  -0.2203  -0.6284  -0.1577   0.0864   0.4121   0.1553   0.2666  -0.2389   0.2041   0.3346   0.4741  -0.6016   0.0115  -0.0602   0.3206   0.4826   0.3525  -0.1885  -0.2008  -0.3388   0.6140   0.1020  -0.0793   0.5990  -0.1003   0.0955   0.3994   0.0116  -0.1112  -0.1096  -0.0018  -0.2238  -0.3740  -0.0039  -0.0055  -0.3992  -0.2869   0.0613   0.0735  -0.3154  -0.1126   1.1058   0.2880   0.0803  -0.0629   0.2090   0.2782  -0.0316  -0.8946   0.2074   0.7050  -0.2346  -0.1839  -0.4834  -0.0703   0.4363  -0.1687  -0.2063   0.5267  -0.0676  -0.6053  -0.4002  -0.4421   0.6508  -0.1215   0.1538   0.2386  -0.5220   0.5121   0.1618   0.7900   0.5419   0.2273  -0.0172  -0.2526   0.5470  -0.4682  -0.7840   0.5663   0.0145  -0.1577   0.4185   0.2600  -0.0352   0.2272  -0.0762   0.1487   0.4499  -0.1729   0.0071  -0.2691   0.2940  -0.2959   0.1800  -0.3799\n",
            "?           -0.0869   0.1916   0.1091  -0.3432   0.2037  -0.2478   0.4605  -0.3657  -0.1980   1.7379  -0.4351   0.0961   0.1560   0.2390  -0.4193  -0.0951   0.0443   1.2392   0.0112  -0.2252   0.3841  -0.1161  -0.0390   0.0361  -0.0005  -0.1215  -0.0569   0.4142   0.3825   0.2359  -0.0856   0.0851  -0.0380  -0.1611   0.4627   0.4568   0.1510   0.1155  -0.0059  -0.1496   0.1159  -0.1141  -0.1926  -0.0258   0.1685   0.0474  -0.4748  -0.1607  -0.0962   0.1819   0.1495   0.1213   0.0009  -0.5736  -0.1788  -0.1449   0.1116  -0.1839   0.3403   0.2180  -0.2649  -0.1167   0.6436   0.0095   0.0544  -0.2701  -0.4256   0.0188  -0.3041  -0.0354   0.1689  -0.0961   0.4858   0.2264   0.0868   0.3252   0.1020  -0.2139   0.1635   0.5704  -0.4883  -0.0297  -0.1253   0.1578  -0.1635   0.1076   0.6453  -0.8365   0.1350   0.2163  -0.3082  -0.1567   0.0271  -0.0464  -0.0404  -0.3126  -0.4496  -0.4751   0.0476  -0.1278  -0.1252   0.5105  -0.0825  -0.2961   0.0665   0.3970  -0.0164   0.1859  -0.0111   0.1364   0.1463  -0.7037   0.4921   0.0039   0.0682   0.4225   0.1292  -0.3235  -0.2035  -0.1111   0.1036   0.0482   0.1226  -0.0279  -0.1609   0.1347  -0.0782  -0.1173   0.3518  -0.2889   0.3436  -0.2610   0.1261   0.2781   0.1577   0.0183   0.1541   0.0738  -0.5720   0.1740  -1.4982   0.2234   0.2736   0.0093   0.0671   0.0240  -0.1118   0.3838  -0.4385   0.1515   0.2155   0.4530  -0.1852  -0.0202   0.2423  -0.2912  -0.0341  -0.2328   0.2150  -0.0221  -0.0456  -0.1273  -0.0975  -0.0976  -0.0706   0.1701  -0.3506  -0.2465   0.3098   0.7366  -0.0860  -0.2419  -0.1685   0.2210  -0.0614   0.1666   0.2273   0.1121   0.1346  -0.3486  -0.0847  -0.1060  -0.1133  -0.4790  -0.2299  -0.0703  -0.3302  -0.0546   0.1728  -0.0728   0.1472   0.3101  -0.1773  -0.2649   0.0887   0.0908  -0.2783  -0.0179   0.6554   0.4631  -0.0946   0.2405   0.2298  -0.1066  -0.1329  -0.1508   0.3042  -0.0876  -0.0494  -0.2001  -0.2397  -0.1810  -0.1282  -0.1090   0.1365  -0.2702  -0.0258   0.3121  -0.5649  -0.1227   0.1531   0.1077  -0.4954  -0.0094   0.2387   0.0372  -0.0662   0.1492  -0.1615  -0.2513  -0.4173  -0.5252   0.5863   0.0195  -0.1289  -0.1428   0.2544  -0.1235  -0.1683  -0.0772  -0.0454  -0.1685  -0.1175  -0.2059   0.1037  -0.5211   0.6461   0.0723  -0.2321   0.2960   0.4166  -0.0673  -0.2659   0.0409  -0.3284   0.1757  -0.1161   0.0457   0.0431  -0.0374  -0.2859  -0.4915   0.1618  -0.0153  -0.1799  -0.0683  -0.0674   0.0643   0.6730   0.3173  -0.0908   0.0712   0.0265  -0.1194  -0.5974   0.1514   0.1913  -0.3993   0.1711   0.5420   0.3849   0.1935  -0.0341  -0.3094   0.0997   0.0038   0.1642  -0.0123   0.0221   0.0094  -0.1662  -0.2630  -0.0446  -0.1330   0.4256   0.0711  -0.1282  -0.0152   0.1111   0.2065\n",
            "----\n",
            "Row:        -0.0388   0.2046  -0.1022  -0.0816   0.0031   0.0200  -0.0658  -0.0432   0.0364   2.6204  -0.2635  -0.0061   0.2407  -0.0909  -0.2516  -0.1024  -0.1475   0.7147  -0.2007  -0.0297   0.1823  -0.0480   0.0364  -0.0525  -0.0446   0.0192  -0.1977  -0.0404   0.0912   0.0453  -0.0098   0.1970   0.0100   0.0451   0.1014   0.1683   0.0171   0.0626  -0.1359  -0.1202  -0.0510   0.1848  -0.0325  -0.0392   0.1362   0.0677  -0.2222   0.0040   0.0613  -0.0573  -0.0381   0.1068  -0.0083  -0.0640   0.0214  -0.0273   0.0245  -0.1077   0.0912  -0.0437  -0.0416  -0.1205  -0.0805   0.3132   0.0722  -0.0604  -0.1051   0.0686   0.0523   0.1175   0.2375   0.0198   0.2184   0.0884   0.2377   0.1552  -0.0005  -0.1346  -0.0595   0.2477  -0.0372   0.1070  -0.0832  -0.0811   0.0164  -0.1167  -0.0997  -0.4647   0.2723   0.0823  -0.0729  -0.0602  -0.1373   0.1295   0.2014  -0.0034   0.0334  -0.0589   0.0546   0.0728  -0.0284   0.0650   0.0193  -0.1275   0.1932  -0.6430   0.1135  -0.0330  -0.0020   0.0317  -0.0018  -0.2990   0.1081  -0.0495   0.0758  -0.0443  -0.0343   0.0806  -0.0378  -0.0601   0.0481  -0.1058  -0.1476   0.0734   0.0506   0.1018  -0.0089  -0.2027   0.0266   0.0396  -0.0858   0.0577   0.0325  -0.0169   0.1164   0.0086   0.0230   0.2341   0.0053  -0.0384  -1.5151   0.0967   0.0864   0.0781   0.1083  -0.1084  -0.2685   0.2058  -0.0657   0.0230  -0.0113  -0.0504  -0.0656   0.0011  -0.0266  -0.0750  -0.0295   0.0175  -0.0982  -0.0110  -0.1801   0.1188  -0.1513  -0.0459  -0.2014  -0.0794   0.0208  -0.0992   0.2404   0.1114   0.0003  -0.0697   0.0348  -0.0447  -0.1839   0.0272  -0.0454   0.0015   0.1644  -0.0697   0.0040  -0.0977  -0.2067  -0.1640   0.0419   0.0204  -0.0314  -0.1676   0.0125   0.0599   0.0689   0.0609  -0.1352  -0.0320   0.1968   0.1874  -0.1592  -0.0426  -0.0262   0.2280  -0.0338   0.0295  -0.0513  -0.1155   0.1470   0.0481   0.0699  -0.0618   0.0421   0.1601  -0.0220  -0.0486  -0.0989  -0.1657   0.0147   0.1774  -0.2085  -0.0244  -0.1905  -0.0141   0.1274   0.0360  -0.1434   0.0803  -0.0374   0.0969   0.0899   0.1038   0.0479   0.0000  -0.1242   0.0894   0.0778   0.1537  -0.1073  -0.1480   0.0712  -0.0880  -0.1119   0.1271  -0.0157  -0.0235  -0.0018   0.0922   0.0408  -0.2133   0.1748  -0.0154  -0.1551   0.1678   0.0886  -0.0799  -0.0338  -0.1397  -0.0784   0.2791  -0.0181  -0.0410   0.0452   0.0890   0.2236   0.0688  -0.0614   0.1566   0.0875  -0.0989  -0.0183   0.1030   0.3970   0.0556   0.0825   0.0069  -0.1317  -0.1970  -0.1286   0.1139   0.0441  -0.0171   0.0829   0.2104   0.1561  -0.0544  -0.1183  -0.0093   0.0040  -0.1067   0.2111  -0.1221   0.0849   0.0759  -0.2303   0.0654   0.0436  -0.0866   0.1453  -0.0816  -0.1377  -0.0314   0.1336   0.0266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_zbEIT8On8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8cd701-2630-4fcb-8317-c878ca5a9327"
      },
      "source": [
        "# How are row vectors calculated? Sum and take the average\n",
        "dimensions = 300\n",
        "\n",
        "document_vectors = []\n",
        "for row in all_tagged[0:2]:\n",
        "  total_vector = [0]*dimensions\n",
        "  print(f\"----------------------------\")\n",
        "  for token in row:\n",
        "    print(f\"+ {token.text.ljust(15)} {token.vector[0:5]}\")\n",
        "    total_vector += token.vector\n",
        "  print(f\"= {total_vector[0:5]}\")\n",
        "  total_vector /= len(row)\n",
        "  print(f\"= {total_vector[0:5]} (after normalizing)\")\n",
        "  document_vectors.append(total_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "+ What            [-0.038548  0.54252  -0.21843  -0.18855   0.073   ]\n",
            "+ did             [-0.068894  0.38769  -0.2612   -0.13737  -0.2154  ]\n",
            "+ you             [-0.11076   0.30786  -0.5198    0.035138  0.10368 ]\n",
            "+ think           [-0.21788    0.44128   -0.43204   -0.19803   -0.0027968]\n",
            "+ of              [ 0.060216  0.21799  -0.04249  -0.38618  -0.15388 ]\n",
            "+ the             [ 0.27204  -0.06203  -0.1884    0.023225 -0.018158]\n",
            "+ last            [ 0.092025  0.41743   0.1325   -0.01374  -0.022543]\n",
            "+ couple          [ 0.13549  -0.25399  -0.57326   0.055446  0.33505 ]\n",
            "+ elections       [-0.42528 -0.14411  0.97183  0.33724 -0.27166]\n",
            "+ ?               [-0.086864  0.19161   0.10915  -0.34321   0.20368 ]\n",
            "= [-0.388455    2.04625    -1.02214003 -0.81603101  0.03097218]\n",
            "= [-0.0388455   0.204625   -0.102214   -0.0816031   0.00309722] (after normalizing)\n",
            "----------------------------\n",
            "+ I               [ 0.18733   0.40595  -0.51174  -0.55482   0.039716]\n",
            "+ think           [-0.21788    0.44128   -0.43204   -0.19803   -0.0027968]\n",
            "+ it              [ 0.0013629  0.35653   -0.055497  -0.16607    0.0031402]\n",
            "+ has             [ 0.08552   0.50152   0.11266  -0.18826   0.031677]\n",
            "+ been            [ 0.04122  0.12696 -0.14441 -0.36391 -0.13867]\n",
            "+ great           [-0.093846  0.58296  -0.019271 -0.070072  0.18095 ]\n",
            "+ for             [-0.17224   0.18234  -0.27847  -0.084666  0.25442 ]\n",
            "+ the             [ 0.27204  -0.06203  -0.1884    0.023225 -0.018158]\n",
            "+ country         [ 0.073677  0.52156   0.31504  -0.25743   0.63185 ]\n",
            "+ .               [ 0.012001  0.20751  -0.12578  -0.59325   0.12525 ]\n",
            "+ people          [-0.19686  0.11579 -0.41091 -0.46998 -0.29972]\n",
            "+ have            [ 3.5670e-02  1.8560e-01 -3.0552e-01 -2.5120e-01 -2.2419e-04]\n",
            "+ come            [-0.053725  0.047882 -0.18955  -0.12466   0.35035 ]\n",
            "+ to              [ 0.31924   0.06316  -0.27858   0.2612    0.079248]\n",
            "+ realize         [-0.25233   0.15795  -0.27283  -0.036143 -0.23502 ]\n",
            "+ the             [ 0.27204  -0.06203  -0.1884    0.023225 -0.018158]\n",
            "+ power           [-0.33833  0.55261  1.088    0.17769 -0.35534]\n",
            "+ of              [ 0.060216  0.21799  -0.04249  -0.38618  -0.15388 ]\n",
            "+ the             [ 0.27204  -0.06203  -0.1884    0.023225 -0.018158]\n",
            "+ vote            [-0.20875  -0.074236  0.34248   0.33933  -0.32003 ]\n",
            "+ .               [ 0.012001  0.20751  -0.12578  -0.59325   0.12525 ]\n",
            "= [ 0.11039692  4.61477599 -1.89988802 -3.49002594  0.26169623]\n",
            "= [ 0.005257    0.21975124 -0.09047086 -0.16619171  0.01246173] (after normalizing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M33vWAfceUo"
      },
      "source": [
        "## Learning from Embeddings\n",
        "\n",
        "Just like with the other representations, you can train models on top of these word embeddings. Let's put our sentence vectors into a dataframe and train a logistic regression model on top of it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_I2wUCVcqtp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "560a94b6-1485-4f1c-d2a6-45c40c9907ea"
      },
      "source": [
        "# Put sentence vectors into a dataframe\n",
        "dimensions = 300\n",
        "\n",
        "X_dict = {\n",
        "    f\"D{i}\":[] for i in range(dimensions)\n",
        "}\n",
        "\n",
        "for row in all_tagged:\n",
        "  vector = row.vector\n",
        "  for i in range(len(vector)):\n",
        "    key = f\"D{i}\"\n",
        "    X_dict[key].append(vector[i])\n",
        "\n",
        "embedding_df = pd.DataFrame(X_dict)\n",
        "embedding_df[\"text\"] = [x.text for x in all_tagged]\n",
        "embedding_df[\"sentiment\"] = df[\"sentiment_simple\"]\n",
        "print(embedding_df.shape)\n",
        "embedding_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3745, 302)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            D0        D1        D2        D3        D4        D5        D6  \\\n",
              "0    -0.038845  0.204625 -0.102214 -0.081603  0.003097  0.020046 -0.065827   \n",
              "1     0.005257  0.219751 -0.090471 -0.166192  0.012462  0.023725  0.048690   \n",
              "2    -0.111540  0.280104 -0.078013 -0.137122  0.106891 -0.033119 -0.014925   \n",
              "3     0.039401  0.050128 -0.052970 -0.073588 -0.048978  0.000354 -0.003387   \n",
              "4    -0.005060  0.229996 -0.317093 -0.139681  0.065246  0.061050  0.047159   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3740  0.087661  0.174323 -0.107225 -0.009744  0.181552  0.021950  0.002454   \n",
              "3741 -0.096926  0.142365 -0.095713 -0.100488  0.079319 -0.042209  0.113485   \n",
              "3742  0.007629  0.200592 -0.158732 -0.119624  0.124181 -0.038861 -0.056483   \n",
              "3743  0.102269  0.111211 -0.227828 -0.039845  0.090072 -0.024324 -0.093978   \n",
              "3744 -0.153821  0.335095 -0.270157 -0.208473 -0.083806 -0.007815  0.013994   \n",
              "\n",
              "            D7        D8        D9  ...      D292      D293      D294  \\\n",
              "0    -0.043192  0.036400  2.620390  ...  0.043580 -0.086610  0.145320   \n",
              "1    -0.031379 -0.016375  2.513524  ... -0.008162 -0.160242  0.041420   \n",
              "2    -0.037978  0.007112  2.272809  ...  0.049699 -0.091552  0.085002   \n",
              "3     0.000408 -0.016485  2.476137  ...  0.075287 -0.198787 -0.054578   \n",
              "4    -0.132655 -0.075138  2.353038  ... -0.191882 -0.068501  0.157432   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3740 -0.112620  0.080725  2.255513  ... -0.010577 -0.058543  0.068404   \n",
              "3741 -0.154705 -0.011170  2.260691  ... -0.052820 -0.110195  0.097739   \n",
              "3742 -0.179276  0.000686  2.349874  ...  0.033565 -0.052446  0.074603   \n",
              "3743 -0.090061 -0.002398  2.324288  ... -0.052344 -0.050162  0.070100   \n",
              "3744 -0.164755 -0.059213  2.553766  ... -0.041968 -0.033186  0.049901   \n",
              "\n",
              "          D295      D296      D297      D298      D299  \\\n",
              "0    -0.081584 -0.137654 -0.031360  0.133605  0.026609   \n",
              "1    -0.006411 -0.044762 -0.007427 -0.046328  0.105702   \n",
              "2    -0.117639 -0.134387 -0.074143  0.082113  0.063143   \n",
              "3     0.048062 -0.014210 -0.045367  0.022904  0.035422   \n",
              "4    -0.049075 -0.127514  0.002488  0.204164  0.182843   \n",
              "...        ...       ...       ...       ...       ...   \n",
              "3740 -0.036753 -0.055164  0.077700 -0.000172  0.058947   \n",
              "3741 -0.025900  0.045328 -0.125580  0.126615  0.070564   \n",
              "3742  0.062765 -0.054296 -0.026015  0.012083  0.082824   \n",
              "3743 -0.037556 -0.022461  0.098480  0.014038  0.024836   \n",
              "3744  0.051434 -0.117965 -0.199378  0.106431  0.122747   \n",
              "\n",
              "                                                   text  \\\n",
              "0      What did you think of the last couple elections?   \n",
              "1     I think it has been great for the country. peo...   \n",
              "2     That is a great point. I want to keep seeing m...   \n",
              "3     the vote should be mandatory. then people woul...   \n",
              "4     I agree, I am sure other countries do that. I ...   \n",
              "...                                                 ...   \n",
              "3740  Wow, I guess football wasnt that popular back ...   \n",
              "3741  The guy must have had incredible hands or spec...   \n",
              "3742  I bet he was, probably worth a few points, did...   \n",
              "3743  I guess they're hoping to psych out the opposi...   \n",
              "3744                     Think that could be effective.   \n",
              "\n",
              "                   sentiment  \n",
              "0     Curious to dive deeper  \n",
              "1                    Neutral  \n",
              "2     Curious to dive deeper  \n",
              "3                    Neutral  \n",
              "4     Curious to dive deeper  \n",
              "...                      ...  \n",
              "3740  Curious to dive deeper  \n",
              "3741                 Neutral  \n",
              "3742  Curious to dive deeper  \n",
              "3743                 Neutral  \n",
              "3744  Curious to dive deeper  \n",
              "\n",
              "[3745 rows x 302 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb740d6e-afba-407d-9eb1-6bfd6016ec2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D0</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D292</th>\n",
              "      <th>D293</th>\n",
              "      <th>D294</th>\n",
              "      <th>D295</th>\n",
              "      <th>D296</th>\n",
              "      <th>D297</th>\n",
              "      <th>D298</th>\n",
              "      <th>D299</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.038845</td>\n",
              "      <td>0.204625</td>\n",
              "      <td>-0.102214</td>\n",
              "      <td>-0.081603</td>\n",
              "      <td>0.003097</td>\n",
              "      <td>0.020046</td>\n",
              "      <td>-0.065827</td>\n",
              "      <td>-0.043192</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>2.620390</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043580</td>\n",
              "      <td>-0.086610</td>\n",
              "      <td>0.145320</td>\n",
              "      <td>-0.081584</td>\n",
              "      <td>-0.137654</td>\n",
              "      <td>-0.031360</td>\n",
              "      <td>0.133605</td>\n",
              "      <td>0.026609</td>\n",
              "      <td>What did you think of the last couple elections?</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005257</td>\n",
              "      <td>0.219751</td>\n",
              "      <td>-0.090471</td>\n",
              "      <td>-0.166192</td>\n",
              "      <td>0.012462</td>\n",
              "      <td>0.023725</td>\n",
              "      <td>0.048690</td>\n",
              "      <td>-0.031379</td>\n",
              "      <td>-0.016375</td>\n",
              "      <td>2.513524</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008162</td>\n",
              "      <td>-0.160242</td>\n",
              "      <td>0.041420</td>\n",
              "      <td>-0.006411</td>\n",
              "      <td>-0.044762</td>\n",
              "      <td>-0.007427</td>\n",
              "      <td>-0.046328</td>\n",
              "      <td>0.105702</td>\n",
              "      <td>I think it has been great for the country. peo...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.111540</td>\n",
              "      <td>0.280104</td>\n",
              "      <td>-0.078013</td>\n",
              "      <td>-0.137122</td>\n",
              "      <td>0.106891</td>\n",
              "      <td>-0.033119</td>\n",
              "      <td>-0.014925</td>\n",
              "      <td>-0.037978</td>\n",
              "      <td>0.007112</td>\n",
              "      <td>2.272809</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049699</td>\n",
              "      <td>-0.091552</td>\n",
              "      <td>0.085002</td>\n",
              "      <td>-0.117639</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.074143</td>\n",
              "      <td>0.082113</td>\n",
              "      <td>0.063143</td>\n",
              "      <td>That is a great point. I want to keep seeing m...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039401</td>\n",
              "      <td>0.050128</td>\n",
              "      <td>-0.052970</td>\n",
              "      <td>-0.073588</td>\n",
              "      <td>-0.048978</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>-0.003387</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>-0.016485</td>\n",
              "      <td>2.476137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075287</td>\n",
              "      <td>-0.198787</td>\n",
              "      <td>-0.054578</td>\n",
              "      <td>0.048062</td>\n",
              "      <td>-0.014210</td>\n",
              "      <td>-0.045367</td>\n",
              "      <td>0.022904</td>\n",
              "      <td>0.035422</td>\n",
              "      <td>the vote should be mandatory. then people woul...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.005060</td>\n",
              "      <td>0.229996</td>\n",
              "      <td>-0.317093</td>\n",
              "      <td>-0.139681</td>\n",
              "      <td>0.065246</td>\n",
              "      <td>0.061050</td>\n",
              "      <td>0.047159</td>\n",
              "      <td>-0.132655</td>\n",
              "      <td>-0.075138</td>\n",
              "      <td>2.353038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.191882</td>\n",
              "      <td>-0.068501</td>\n",
              "      <td>0.157432</td>\n",
              "      <td>-0.049075</td>\n",
              "      <td>-0.127514</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>0.204164</td>\n",
              "      <td>0.182843</td>\n",
              "      <td>I agree, I am sure other countries do that. I ...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3740</th>\n",
              "      <td>0.087661</td>\n",
              "      <td>0.174323</td>\n",
              "      <td>-0.107225</td>\n",
              "      <td>-0.009744</td>\n",
              "      <td>0.181552</td>\n",
              "      <td>0.021950</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>-0.112620</td>\n",
              "      <td>0.080725</td>\n",
              "      <td>2.255513</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010577</td>\n",
              "      <td>-0.058543</td>\n",
              "      <td>0.068404</td>\n",
              "      <td>-0.036753</td>\n",
              "      <td>-0.055164</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>-0.000172</td>\n",
              "      <td>0.058947</td>\n",
              "      <td>Wow, I guess football wasnt that popular back ...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3741</th>\n",
              "      <td>-0.096926</td>\n",
              "      <td>0.142365</td>\n",
              "      <td>-0.095713</td>\n",
              "      <td>-0.100488</td>\n",
              "      <td>0.079319</td>\n",
              "      <td>-0.042209</td>\n",
              "      <td>0.113485</td>\n",
              "      <td>-0.154705</td>\n",
              "      <td>-0.011170</td>\n",
              "      <td>2.260691</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052820</td>\n",
              "      <td>-0.110195</td>\n",
              "      <td>0.097739</td>\n",
              "      <td>-0.025900</td>\n",
              "      <td>0.045328</td>\n",
              "      <td>-0.125580</td>\n",
              "      <td>0.126615</td>\n",
              "      <td>0.070564</td>\n",
              "      <td>The guy must have had incredible hands or spec...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3742</th>\n",
              "      <td>0.007629</td>\n",
              "      <td>0.200592</td>\n",
              "      <td>-0.158732</td>\n",
              "      <td>-0.119624</td>\n",
              "      <td>0.124181</td>\n",
              "      <td>-0.038861</td>\n",
              "      <td>-0.056483</td>\n",
              "      <td>-0.179276</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>2.349874</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033565</td>\n",
              "      <td>-0.052446</td>\n",
              "      <td>0.074603</td>\n",
              "      <td>0.062765</td>\n",
              "      <td>-0.054296</td>\n",
              "      <td>-0.026015</td>\n",
              "      <td>0.012083</td>\n",
              "      <td>0.082824</td>\n",
              "      <td>I bet he was, probably worth a few points, did...</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3743</th>\n",
              "      <td>0.102269</td>\n",
              "      <td>0.111211</td>\n",
              "      <td>-0.227828</td>\n",
              "      <td>-0.039845</td>\n",
              "      <td>0.090072</td>\n",
              "      <td>-0.024324</td>\n",
              "      <td>-0.093978</td>\n",
              "      <td>-0.090061</td>\n",
              "      <td>-0.002398</td>\n",
              "      <td>2.324288</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052344</td>\n",
              "      <td>-0.050162</td>\n",
              "      <td>0.070100</td>\n",
              "      <td>-0.037556</td>\n",
              "      <td>-0.022461</td>\n",
              "      <td>0.098480</td>\n",
              "      <td>0.014038</td>\n",
              "      <td>0.024836</td>\n",
              "      <td>I guess they're hoping to psych out the opposi...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3744</th>\n",
              "      <td>-0.153821</td>\n",
              "      <td>0.335095</td>\n",
              "      <td>-0.270157</td>\n",
              "      <td>-0.208473</td>\n",
              "      <td>-0.083806</td>\n",
              "      <td>-0.007815</td>\n",
              "      <td>0.013994</td>\n",
              "      <td>-0.164755</td>\n",
              "      <td>-0.059213</td>\n",
              "      <td>2.553766</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041968</td>\n",
              "      <td>-0.033186</td>\n",
              "      <td>0.049901</td>\n",
              "      <td>0.051434</td>\n",
              "      <td>-0.117965</td>\n",
              "      <td>-0.199378</td>\n",
              "      <td>0.106431</td>\n",
              "      <td>0.122747</td>\n",
              "      <td>Think that could be effective.</td>\n",
              "      <td>Curious to dive deeper</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3745 rows × 302 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb740d6e-afba-407d-9eb1-6bfd6016ec2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb740d6e-afba-407d-9eb1-6bfd6016ec2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb740d6e-afba-407d-9eb1-6bfd6016ec2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV3TEHnVcfbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8eabc73-82a4-4d49-acf4-52c642439260"
      },
      "source": [
        "# Pick Classifiers to Compare\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Kappa'\n",
        "\n",
        "# Pick features to use\n",
        "feature_set = X_dict.keys()\n",
        "\n",
        "sorted_sentiments = [\"Curious to dive deeper\", \"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "# Compare models and display final result\n",
        "best, best_name, classifier_comparison = compare_classifiers(classifiers, metrics, metric_to_optimize, embedding_df, feature_set, \"sentiment\", labels=sorted_sentiments, noisy = 'quiet',)\n",
        "\n",
        "print(f\"Best classifier is: {best_name} \\nWith K={best:.3f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Fold 0"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...1"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...2"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...3"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...4"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...6"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...7"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...8...9\n",
            "Average Kappa: 0.253\n",
            "-------------\n",
            "Best classifier is: Logistic Regression \n",
            "With K=0.253.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    }
  ]
}